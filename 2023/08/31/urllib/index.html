<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>urllib | 竹间小客</title><meta name="author" content="Bamboo,YT000000X@163.com"><meta name="copyright" content="Bamboo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="一、导模块import urllib.request as req    二、整页抓取# 使用urllib获取百度首页源码import urllib.request# 访问网站url &#x3D; &amp;#x27;http:&#x2F;&#x2F;www.baidu.com&amp;#x27;# 对服务器发送请求 response响应response &#x3D; urllib.request.urlopen(url)# 获取响应中的页面源码con">
<meta property="og:type" content="article">
<meta property="og:title" content="urllib">
<meta property="og:url" content="http://blog.dragonbamboo.com/2023/08/31/urllib/index.html">
<meta property="og:site_name" content="竹间小客">
<meta property="og:description" content="一、导模块import urllib.request as req    二、整页抓取# 使用urllib获取百度首页源码import urllib.request# 访问网站url &#x3D; &amp;#x27;http:&#x2F;&#x2F;www.baidu.com&amp;#x27;# 对服务器发送请求 response响应response &#x3D; urllib.request.urlopen(url)# 获取响应中的页面源码con">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://blog.dragonbamboo.com/img/ava.jpg">
<meta property="article:published_time" content="2023-08-31T06:19:19.000Z">
<meta property="article:modified_time" content="2023-08-31T06:19:52.711Z">
<meta property="article:author" content="Bamboo">
<meta property="article:tag" content="python">
<meta property="article:tag" content="爬虫">
<meta property="article:tag" content="urllib">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://blog.dragonbamboo.com/img/ava.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://blog.dragonbamboo.com/2023/08/31/urllib/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'urllib',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-08-31 14:19:52'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/ava.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">33</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标题</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/description.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="竹间小客"><span class="site-name">竹间小客</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标题</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">urllib</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-08-31T06:19:19.000Z" title="发表于 2023-08-31 14:19:19">2023-08-31</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-08-31T06:19:52.711Z" title="更新于 2023-08-31 14:19:52">2023-08-31</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%88%AC%E8%99%AB%E6%95%99%E7%A8%8B/">爬虫教程</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="urllib"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="一、导模块"><a href="#一、导模块" class="headerlink" title="一、导模块"></a>一、导模块</h1><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request <span class="keyword">as</span> req</span><br></pre></td></tr></table></figure>



<h1 id="二、整页抓取"><a href="#二、整页抓取" class="headerlink" title="二、整页抓取"></a>二、整页抓取</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用urllib获取百度首页源码</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="comment"># 访问网站</span></span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对服务器发送请求 response响应</span></span><br><span class="line">response = urllib.request.urlopen(url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取响应中的页面源码</span></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印数据</span></span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<h1 id="三、HTTPResponse类型与方法"><a href="#三、HTTPResponse类型与方法" class="headerlink" title="三、HTTPResponse类型与方法"></a>三、HTTPResponse类型与方法</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;http://www.baidu.com&#x27;</span></span><br><span class="line">response = urllib.request.urlopen(url)</span><br><span class="line"><span class="comment"># &lt;class &#x27;http.client.HTTPResponse&#x27;&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>读写方式</strong></p>
<ul>
<li>read()</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 按照一个字节一个字节进行读</span></span><br><span class="line">content = response.read()</span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<ul>
<li>read(n)</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 读五个字节</span></span><br><span class="line">content = response.read(<span class="number">5</span>)</span><br><span class="line"><span class="comment"># b&#x27;&lt;!DOC&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<ul>
<li>readline()</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 读取一行</span></span><br><span class="line">content = response.readline()</span><br></pre></td></tr></table></figure>

<ul>
<li>readlines()</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 以行为单位读取响应页面，组成list</span></span><br><span class="line">content = response.readlines()</span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<p><strong>头消息返回</strong></p>
<ul>
<li>getcode()</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 返回状态码</span></span><br><span class="line"><span class="comment"># 200</span></span><br><span class="line"><span class="built_in">print</span>(response.getcode())</span><br></pre></td></tr></table></figure>

<ul>
<li>geturl()</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 返回地址</span></span><br><span class="line"><span class="comment"># http://www.baidu.com</span></span><br><span class="line"><span class="built_in">print</span>(response.geturl())</span><br></pre></td></tr></table></figure>

<ul>
<li>getheaders()</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取状态信息</span></span><br><span class="line"><span class="comment"># [(&#x27;Connection&#x27;, &#x27;close&#x27;), (&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;), (&#x27;Bdpagetype&#x27;, &#x27;1&#x27;), (&#x27;Bdqid&#x27;, &#x27;0xdee6206e000947e5&#x27;), (&#x27;Content-Security-Policy&#x27;, &quot;frame-ancestors &#x27;self&#x27; https://chat.baidu.com http://mirror-chat.baidu.com https://fj-chat.baidu.com https://hba-chat.baidu.com https://hbe-chat.baidu.com https://njjs-chat.baidu.com https://nj-chat.baidu.com https://hna-chat.baidu.com https://hnb-chat.baidu.com http://debug.baidu-int.com;&quot;), (&#x27;Content-Type&#x27;, &#x27;text/html; charset=utf-8&#x27;), (&#x27;Date&#x27;, &#x27;Sun, 25 Jun 2023 07:43:20 GMT&#x27;), (&#x27;P3p&#x27;, &#x27;CP=&quot; OTI DSP COR IVA OUR IND COM &quot;&#x27;), (&#x27;P3p&#x27;, &#x27;CP=&quot; OTI DSP COR IVA OUR IND COM &quot;&#x27;), (&#x27;Server&#x27;, &#x27;BWS/1.1&#x27;), (&#x27;Set-Cookie&#x27;, &#x27;BAIDUID=8F8527EF736D370F80FA1FE3708A6D99:FG=1; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com&#x27;), (&#x27;Set-Cookie&#x27;, &#x27;BIDUPSID=8F8527EF736D370F80FA1FE3708A6D99; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com&#x27;), (&#x27;Set-Cookie&#x27;, &#x27;PSTM=1687679000; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com&#x27;), (&#x27;Set-Cookie&#x27;, &#x27;BAIDUID=8F8527EF736D370FAA8B1A78468BD03D:FG=1; max-age=31536000; expires=Mon, 24-Jun-24 07:43:20 GMT; domain=.baidu.com; path=/; version=1; comment=bd&#x27;), (&#x27;Set-Cookie&#x27;, &#x27;BDSVRTM=0; path=/&#x27;), (&#x27;Set-Cookie&#x27;, &#x27;BD_HOME=1; path=/&#x27;), (&#x27;Set-Cookie&#x27;, &#x27;H_PS_PSSID=38516_36560_38687_38858_38796_38903_38842_38577_38813_38639_26350; path=/; domain=.baidu.com&#x27;), (&#x27;Traceid&#x27;, &#x27;1687679000282143540216061560777882552293&#x27;), (&#x27;Vary&#x27;, &#x27;Accept-Encoding&#x27;), (&#x27;X-Ua-Compatible&#x27;, &#x27;IE=Edge,chrome=1&#x27;)]</span></span><br><span class="line"><span class="built_in">print</span>(response.getheaders())</span><br></pre></td></tr></table></figure>

<h1 id="四、下载资源"><a href="#四、下载资源" class="headerlink" title="四、下载资源"></a>四、下载资源</h1><h2 id="4-1-普通模式"><a href="#4-1-普通模式" class="headerlink" title="4.1 普通模式"></a>4.1 普通模式</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载网页</span></span><br><span class="line">url_page = <span class="string">&#x27;http://www.baidu.com&#x27;</span></span><br><span class="line"><span class="comment"># url表示下载路径，filename表示文件名</span></span><br><span class="line"><span class="comment"># 1.调用urlretrieve(url,filename)此方法针对非反爬虫程序</span></span><br><span class="line">urllib.request.urlretrieve(url_page,<span class="string">&#x27;baidu.html&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>注：此方法可获取任何不具备反爬能力网站的资源，仅需修改filename参数后缀即可</p>
<h2 id="4-2-反反爬模式"><a href="#4-2-反反爬模式" class="headerlink" title="4.2 反反爬模式"></a>4.2 反反爬模式</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载图片</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 反爬措施(头信息)反制：</span></span><br><span class="line">headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图片资源地址</span></span><br><span class="line">url_picture = <span class="string">&#x27;https://w.wallhaven.cc/full/l8/wallhaven-l8krdq.png&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取图片资源地址并封入反爬headers反制</span></span><br><span class="line">req = urllib.request.Request(url_picture)</span><br><span class="line">req.add_header(<span class="string">&#x27;User-Agent&#x27;</span>,headers[<span class="string">&#x27;User-Agent&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 访问资源路径获取响应</span></span><br><span class="line">response = urllib.request.urlopen(req)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文件写入至img.png</span></span><br><span class="line"><span class="comment"># with作用为在文件使用结束后自动关闭文件</span></span><br><span class="line"><span class="comment"># as f为open方法的返回值</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;img.png&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(response.read())</span><br></pre></td></tr></table></figure>

<h1 id="五、反爬反制"><a href="#五、反爬反制" class="headerlink" title="五、反爬反制"></a>五、反爬反制</h1><h2 id="5-1-反爬手段"><a href="#5-1-反爬手段" class="headerlink" title="5.1 反爬手段"></a>5.1 反爬手段</h2><ol>
<li>User-Agent反爬</li>
<li>Cookie反爬</li>
</ol>
<h2 id="5-2-请求头UA定制-反制1"><a href="#5-2-请求头UA定制-反制1" class="headerlink" title="5.2 请求头UA定制(反制1)"></a>5.2 请求头UA定制(反制1)</h2><p><strong>UA介绍</strong>：User Agent中文名用户代理，特殊字符串头，使服务器能够识别客户使用的操作系统及版本、CPU类型、浏览器及版本。。。</p>
<p><strong>定制headers</strong>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于urlopen方法可传递str或Request对象，创建Request进行定制UA</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line">headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;见上&#x27;</span>&#125;</span><br><span class="line"><span class="comment"># 参数顺序问题，需要显式设置参数类型</span></span><br><span class="line">req = urllib.request.Request(url=url,headers=headers)</span><br><span class="line"><span class="comment"># 可分散书写</span></span><br><span class="line"><span class="comment"># req = urllib.request.Request(url)</span></span><br><span class="line"><span class="comment"># req.add_header(&#x27;User-Agent&#x27;,headers[&#x27;User-Agent&#x27;])</span></span><br><span class="line">resp = urllib.request.urlopen(req)</span><br><span class="line">content = resp.read().decode(<span class="string">&#x27;utf8&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="5-3-GET请求"><a href="#5-3-GET请求" class="headerlink" title="5.3 GET请求"></a>5.3 GET请求</h2><p>参数Unicode编码：<a target="_blank" rel="noopener" href="https://cn.bing.com/search?q=%E5%91%A8%E6%9D%B0%E4%BC%A6">https://cn.bing.com/search?q=%E5%91%A8%E6%9D%B0%E4%BC%A6</a></p>
<ul>
<li>quote（单参数）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse <span class="keyword">as</span> parse</span><br><span class="line"></span><br><span class="line">msg = parse.quote(<span class="string">&#x27;周杰伦&#x27;</span>) <span class="comment"># 获取编码格式</span></span><br><span class="line">url = <span class="string">&#x27;https://cn.bing.com/search?q=&#x27;</span> + msg</span><br><span class="line"></span><br><span class="line"><span class="comment"># https://cn.bing.com/search?q=%E5%91%A8%E6%9D%B0%E4%BC%A6</span></span><br></pre></td></tr></table></figure>

<ul>
<li>url（多参数）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 解决多参数情况</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib.parse <span class="keyword">as</span> parse</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;q&#x27;</span>: <span class="string">&#x27;周杰伦&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sex&#x27;</span>: <span class="string">&#x27;男&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">data_en = parse.urlencode(data)</span><br><span class="line">url = <span class="string">&#x27;https://cn.bing.com/search?q=&#x27;</span> + data_en</span><br><span class="line"></span><br><span class="line"><span class="comment"># https://cn.bing.com/search?q=%E5%91%A8%E6%9D%B0%E4%BC%A6&amp;sex=%E7%94%B7</span></span><br></pre></td></tr></table></figure>

<h2 id="5-4-POST请求"><a href="#5-4-POST请求" class="headerlink" title="5.4 POST请求"></a>5.4 POST请求</h2><h3 id="5-4-1-请求deep获取翻译"><a href="#5-4-1-请求deep获取翻译" class="headerlink" title="5.4.1 请求deep获取翻译"></a>5.4.1 请求deep获取翻译</h3><ol>
<li>设置url</li>
<li>设置data，此data数据为post参数，需要进行encode编码为unicode</li>
<li>调Request获取请求</li>
<li>使用urlopen进行访问</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.</span></span><br><span class="line">base_url = <span class="string">&#x27;https://dict.deepl.com/english-chinese/search?&#x27;</span></span><br><span class="line">param = &#123;</span><br><span class="line">    <span class="string">&#x27;ajax&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;english&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;onlyDictEntries&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">&#x27;translator&#x27;</span>: <span class="string">&#x27;dnsof7h3k2lgh3gda&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;kind&#x27;</span>: <span class="string">&#x27;full&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;eventkind&#x27;</span>: <span class="string">&#x27;change&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;forleftside&#x27;</span>: <span class="string">&#x27;true&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;il&#x27;</span>: <span class="string">&#x27;zh&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;query&#x27;</span>: <span class="string">&#x27;person&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.</span></span><br><span class="line">param = urllib.parse.urlencode(param)</span><br><span class="line"><span class="comment"># post请求需要进行unicode编码，否则报错</span></span><br><span class="line">data = urllib.parse.urlencode(data).encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">url = base_url + param</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.post提交</span></span><br><span class="line">request = urllib.request.Request(url=url, data=data, headers=headers)</span><br><span class="line"><span class="comment"># print(request)</span></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;deep.html&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">&#x27;&lt;!doctype html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;meta name=&quot;viewport&quot;content=&quot;width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0&quot;&gt;&lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt;&lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&#x27;</span>)</span><br><span class="line">    f.write(response.read().decode(<span class="string">&#x27;utf8&#x27;</span>))</span><br><span class="line">    f.write(<span class="string">&#x27;&lt;/body&gt;&lt;/html&gt;&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;end...&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="5-4-2-请求百度翻译-反制2"><a href="#5-4-2-请求百度翻译-反制2" class="headerlink" title="5.4.2 请求百度翻译(反制2)"></a>5.4.2 请求百度翻译(反制2)</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://fanyi.baidu.com/v2transapi?from=en&amp;to=zh&#x27;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="comment"># &#x27;Accept&#x27;: &#x27;*/*&#x27;,</span></span><br><span class="line">    <span class="comment"># 爬虫编写时注释掉此接收编码</span></span><br><span class="line">    <span class="comment"># &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate, br&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Accept-Language&#x27;: &#x27;zh-CN,zh;q=0.9&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Acs-Token&#x27;: &#x27;1687699004668_1687699004103_kLE706Zo9A39/QzZ9HtVYm/vdl0Zj1TfusbR0BJ5sTasxvycLvABkoc+1b6TbiysG8nnXLixN16AH5z42O8H7U4R3Z388JLQ5mGcMqNr8MnJR13mnuLIgltWgB4XcG57Cp/jQXUo4KA1iF5pha+EYgtHAYoTrUKQ4EiCeBzj66Ibabwxe1YHKprcKQm7GahCMQ/iWEpgSmI1XZPlUGRzHN/eNId4tARiNvADUSmAOA5Re8i6v5ptXWuXPhyDh5d0ij465bTSNd5FJLZkQ699l+ZfFz0tZiyAp6SzkWwKtGOJkUVEdXFXWB/L/F3B1z+4BNliD3v1Uy65Ec/+sMj6R+x95Qsdn/3MXGsxkROFmdXr/tQQIgTFv3TVB48BybZNCsAH2RZUCUFszHU+xANONueA0S5WxlvQoGn80I4+msg3autEzT26nZ3lMmi2UTgP3LYA85ArluKINkmBXd7uJlRpTjfFKSQMKT3qPuA1r5GxEcCfd+n5JSQafy5bxr2H&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Connection&#x27;: &#x27;keep-alive&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Content-Length&#x27;: &#x27;134&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded; charset=UTF-8&#x27;,</span></span><br><span class="line">    <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;BIDUPSID=06131A5CB3B3012812267B71938D92FF; PSTM=1679290628; BDUSS=XFtamFsanNsZWJWTFdoMUhTSXNKWXJxMnNGeVVqblIxTnVUd05zNlc3S0NrbnBrRVFBQUFBJCQAAAAAAAAAAAEAAADiwVCv0uCzvl~csgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIIFU2SCBVNkM; BDUSS_BFESS=XFtamFsanNsZWJWTFdoMUhTSXNKWXJxMnNGeVVqblIxTnVUd05zNlc3S0NrbnBrRVFBQUFBJCQAAAAAAAAAAAEAAADiwVCv0uCzvl~csgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIIFU2SCBVNkM; BAIDUID=4E8EC46552D9E18C72A862024180E013:SL=0:NR=10:FG=1; MCITY=-%3A; H_PS_PSSID=38516_36553_38687_38857_38795_38792_38844_38832_38920_38806_26350; BDORZ=B490B5EBF6F3CD402E515D22BCDA1598; BAIDUID_BFESS=4E8EC46552D9E18C72A862024180E013:SL=0:NR=10:FG=1; BA_HECTOR=8081al21a5a520248g8k8g231i9ga951o; ZFY=RLvEJ42vWfs6Nn1toRsSDPvUf6qUev:BbcKE8XtMjilw:C; PSINO=5; delPer=0; BDRCVFR[feWj1Vr5u3D]=mk3SLVN4HKm; REALTIME_TRANS_SWITCH=1; FANYI_WORD_SWITCH=1; HISTORY_SWITCH=1; SOUND_SPD_SWITCH=1; SOUND_PREFER_SWITCH=1; ab_sr=1.0.1_ZDllODk0MGIwMDljMDY0ZGNlNWY4OWYyZTljZjBiODY0ZDcyM2U1MjYyZDIyNDFkODE3ZTJiYTIwMDI0ZGFmNjk3M2JjZDU2NzZjMjc4N2VkNmY3NzlmOTY5M2ZiZDU3NjU5NzViOTQyODQ5OGQ1ODgxZTcxZmM5ZDJjMGYxMTg2OTEzNTJhN2Y2NTgxNjI3MzM0OGJlMmExZDVkOTRmNWI5YTkxNTMyZjk5YWZjNWIwNWE4Mzk3ODk3ODlhYTgz&#x27;</span>,</span><br><span class="line">    <span class="comment"># &#x27;Host&#x27;: &#x27;fanyi.baidu.com&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Origin&#x27;: &#x27;https://fanyi.baidu.com&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Referer&#x27;: &#x27;https://fanyi.baidu.com/&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Sec-Fetch-Dest&#x27;: &#x27;empty&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Sec-Fetch-Mode&#x27;: &#x27;cors&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Sec-Fetch-Site&#x27;: &#x27;same-origin&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;X-Requested-With&#x27;: &#x27;XMLHttpRequest&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;sec-ch-ua&#x27;: &#x27;&quot;Chromium&quot;;v=&quot;116&quot;, &quot;Not)A;Brand&quot;;v=&quot;24&quot;, &quot;Google Chrome&quot;;v=&quot;116&quot;&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;sec-ch-ua-mobile&#x27;: &#x27;?0&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;sec-ch-ua-platform&#x27;: &#x27;&quot;Windows&quot;&#x27;,</span></span><br><span class="line">&#125;</span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;from&#x27;</span>: <span class="string">&#x27;en&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;to&#x27;</span>: <span class="string">&#x27;zh&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;query&#x27;</span>: <span class="string">&#x27;spider&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;simple_means_flag&#x27;</span>: <span class="string">&#x27;3&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sign&#x27;</span>: <span class="string">&#x27;63766.268839&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;token&#x27;</span>: <span class="string">&#x27;05fb9f025ae9f430c5c6be7f1556f3ea&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;domain&#x27;</span>: <span class="string">&#x27;common&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;ts&#x27;</span>: <span class="string">&#x27;1687699004079&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># post请求参数编码</span></span><br><span class="line">data = urllib.parse.urlencode(data).encode(<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求对象定制</span></span><br><span class="line">request = urllib.request.Request(url=url, data=data, headers=headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟浏览器发送数据</span></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取响应数据</span></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">obj = json.loads(content)</span><br><span class="line"><span class="built_in">print</span>(obj)</span><br></pre></td></tr></table></figure>

<p>百度翻译隐藏接口：<a target="_blank" rel="noopener" href="https://fanyi.baidu.com/sug?kw=eye">https://fanyi.baidu.com/sug?kw=eye</a></p>
<h3 id="5-4-3-POST数据正则替换"><a href="#5-4-3-POST数据正则替换" class="headerlink" title="5.4.3 POST数据正则替换"></a>5.4.3 POST数据正则替换</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">notepad++</span><br><span class="line">查找目标：(.*): (.*)</span><br><span class="line">替换为：&#x27;\1&#x27;:&#x27;\2&#x27;,</span><br></pre></td></tr></table></figure>

<p>html源数据</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from: en</span><br><span class="line">to: zh</span><br><span class="line">query: spider</span><br><span class="line">simple_means_flag: 3</span><br><span class="line">sign: 63766.268839</span><br><span class="line">token: 05fb9f025ae9f430c5c6be7f1556f3ea</span><br><span class="line">domain: common</span><br><span class="line">ts: 1687699004079</span><br></pre></td></tr></table></figure>

<p>正则替换后</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#x27;from&#x27;:&#x27;en&#x27;,</span><br><span class="line">&#x27;to&#x27;:&#x27;zh&#x27;,</span><br><span class="line">&#x27;query&#x27;:&#x27;spider&#x27;,</span><br><span class="line">&#x27;simple_means_flag&#x27;:&#x27;3&#x27;,</span><br><span class="line">&#x27;sign&#x27;:&#x27;63766.268839&#x27;,</span><br><span class="line">&#x27;token&#x27;:&#x27;05fb9f025ae9f430c5c6be7f1556f3ea&#x27;,</span><br><span class="line">&#x27;domain&#x27;:&#x27;common&#x27;,</span><br><span class="line">&#x27;ts&#x27;:&#x27;1687699004079&#x27;,</span><br></pre></td></tr></table></figure>

<h2 id="5-5-ajax"><a href="#5-5-ajax" class="headerlink" title="5.5 ajax"></a>5.5 ajax</h2><h3 id="5-5-1-get"><a href="#5-5-1-get" class="headerlink" title="5.5.1 get"></a>5.5.1 get</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_request</span>(<span class="params">page</span>):</span><br><span class="line">    <span class="comment"># 创建基础url</span></span><br><span class="line">    base_url = <span class="string">&#x27;https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;&#x27;</span></span><br><span class="line">	</span><br><span class="line">    <span class="comment"># 创建header头信息</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建url参数信息</span></span><br><span class="line">    param = &#123;</span><br><span class="line">        <span class="string">&#x27;start&#x27;</span>: (page-<span class="number">1</span>)*<span class="number">20</span>,</span><br><span class="line">        <span class="string">&#x27;limit&#x27;</span>: <span class="number">20</span>,</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment"># 将url信息进行解析&amp;拼接</span></span><br><span class="line">    param = urllib.parse.urlencode(param)</span><br><span class="line">	</span><br><span class="line">    <span class="comment"># 拼接url</span></span><br><span class="line">    url = base_url+param</span><br><span class="line">	</span><br><span class="line">    <span class="comment"># 获取get请求的request对象</span></span><br><span class="line">    request = urllib.request.Request(url=url,headers=headers)</span><br><span class="line">    <span class="keyword">return</span> request</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_content</span>(<span class="params">request</span>):</span><br><span class="line">    <span class="comment"># 请求网页返回响应数据</span></span><br><span class="line">    response = urllib.request.urlopen(request)</span><br><span class="line">    <span class="comment"># 将响应数据接收并解码</span></span><br><span class="line">    content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> content</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">downloads</span>(<span class="params">page, content</span>):</span><br><span class="line">    <span class="comment"># 写出爬取的数据</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;.\\douban\\douban_&#x27;</span>+<span class="built_in">str</span>(page)+<span class="string">&#x27;.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;豆瓣网抓取&#x27;</span>)</span><br><span class="line">    start_page = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入起始页码：&#x27;</span>))</span><br><span class="line">    end_page = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入结束页码：&#x27;</span>))</span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(start_page, end_page + <span class="number">1</span>):</span><br><span class="line">        request = create_request(page)</span><br><span class="line">        content = get_content(request)</span><br><span class="line">        downloads(page,content)</span><br></pre></td></tr></table></figure>

<h3 id="5-5-2-post"><a href="#5-5-2-post" class="headerlink" title="5.5.2 post"></a>5.5.2 post</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_request</span>(<span class="params">page</span>):</span><br><span class="line">    <span class="comment"># 设置基础url</span></span><br><span class="line">    url = <span class="string">&#x27;https://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=cname&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置header</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置post参数</span></span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;cname&#x27;</span>: <span class="string">&#x27;北京&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;pid&#x27;</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;pageIndex&#x27;</span>: page,</span><br><span class="line">        <span class="string">&#x27;pageSize&#x27;</span>: <span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 将post参数进行编码</span></span><br><span class="line">    data = urllib.parse.urlencode(data).encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取并返回request请求对象</span></span><br><span class="line">    request = urllib.request.Request(url=url, data=data, headers=headers)</span><br><span class="line">    <span class="keyword">return</span> request</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_content</span>(<span class="params">request</span>):</span><br><span class="line">    <span class="comment"># 请求网页获取数据</span></span><br><span class="line">    response = urllib.request.urlopen(request)</span><br><span class="line">    <span class="comment"># 将获取的数据进行读取并解码</span></span><br><span class="line">    content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> content</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">download</span>(<span class="params">page,content</span>):</span><br><span class="line">    <span class="comment"># 下载数据到kfc文件中</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;.\\kfc\\kfc_&#x27;</span>+<span class="built_in">str</span>(page)+<span class="string">&#x27;.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;肯德基区域店面抓取&#x27;</span>)</span><br><span class="line">    start_page = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入起始页码：&#x27;</span>))</span><br><span class="line">    end_page = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入结束页码：&#x27;</span>))</span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(start_page, end_page + <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 创建request对象</span></span><br><span class="line">        requset = create_request(page)</span><br><span class="line">        <span class="comment"># 获取响应数据</span></span><br><span class="line">        content = get_content(requset)</span><br><span class="line">        <span class="comment"># 下载数据到本地</span></span><br><span class="line">        download(page,content)</span><br><span class="line">        <span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<h1 id="六、爬虫异常"><a href="#六、爬虫异常" class="headerlink" title="六、爬虫异常"></a>六、爬虫异常</h1><h2 id="6-1-导入模块"><a href="#6-1-导入模块" class="headerlink" title="6.1 导入模块"></a>6.1 导入模块</h2><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.error</span><br></pre></td></tr></table></figure>



<h2 id="6-2-HTTPError"><a href="#6-2-HTTPError" class="headerlink" title="6.2 HTTPError"></a>6.2 HTTPError</h2><p>路径错误 : 错误的url，解决报错异常</p>
<h2 id="6-3-URLError"><a href="#6-3-URLError" class="headerlink" title="6.3 URLError"></a>6.3 URLError</h2><p>服务器或端口错误 : 错误的url，解决报错异常</p>
<h2 id="6-4-捕获异常"><a href="#6-4-捕获异常" class="headerlink" title="6.4 捕获异常"></a>6.4 捕获异常</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">	...</span><br><span class="line"><span class="keyword">except</span> urllib.error.HTTPError:</span><br><span class="line">	...</span><br></pre></td></tr></table></figure>

<h2 id="6-5-案例"><a href="#6-5-案例" class="headerlink" title="6.5 案例"></a>6.5 案例</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># _*_ coding : utf-8 _*_</span></span><br><span class="line"><span class="comment"># @Time : 2023/6/30 7:43</span></span><br><span class="line"><span class="comment"># @Author : bamboo</span></span><br><span class="line"><span class="comment"># @File : urllib_except_csdn</span></span><br><span class="line"><span class="comment"># @Project : py-pro</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正确的url</span></span><br><span class="line"><span class="comment"># url = &#x27;https://blog.csdn.net/csdnnews/article/details/131427781&#x27;</span></span><br><span class="line"><span class="comment"># 路径错误 : 错误的url，解决报错异常</span></span><br><span class="line"><span class="comment"># url = &#x27;https://blog.csdn.net/csdnnews/article/details/1314277811&#x27;</span></span><br><span class="line"><span class="comment"># 服务器或端口错误 : 错误的url，解决报错异常</span></span><br><span class="line">url = <span class="string">&#x27;http://www.goudan111.com&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span> : <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    request = urllib.request.Request(url=url,headers=headers)</span><br><span class="line"></span><br><span class="line">    response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line">    content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(content)</span><br><span class="line"><span class="comment"># 路径错误</span></span><br><span class="line"><span class="keyword">except</span> urllib.error.HTTPError:</span><br><span class="line">    <span class="comment"># 实际上报错，掩盖意图</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;系统正在升级...&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主机地址或地址出错</span></span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;第二种升级方案...&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="七、Cookie登录"><a href="#七、Cookie登录" class="headerlink" title="七、Cookie登录"></a>七、Cookie登录</h1><p><strong>绕过页面登录抓取数据</strong></p>
<p>场景分析：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># _*_ coding : utf-8 _*_</span></span><br><span class="line"><span class="comment"># @Time : 2023/6/30 8:07</span></span><br><span class="line"><span class="comment"># @Author : bamboo</span></span><br><span class="line"><span class="comment"># @File : urllib_cookie_login_weibo</span></span><br><span class="line"><span class="comment"># @Project : py-pro</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://weibo.com/u/7074461820&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url=url,headers=headers)</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(content)</span><br><span class="line"><span class="comment"># UnicodeDecodeError: &#x27;utf-8&#x27; codec can&#x27;t decode byte 0xca in position 339: invalid continuation byte</span></span><br></pre></td></tr></table></figure>

<p><strong>报错原因</strong>：此用户页面是utf-8编码，但未登录会跳转到登录页，登录页的编码不是utf-8</p>
<h2 id="7-1-错误更正"><a href="#7-1-错误更正" class="headerlink" title="7.1 错误更正"></a>7.1 错误更正</h2><p><strong>修改response接收的编码格式</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">content = response.read().decode(&#x27;gb2312&#x27;)</span><br></pre></td></tr></table></figure>

<p><strong>异常</strong>：发现获取到的数据是登录页面的</p>
<p><strong>访问失败原因</strong>：请求头信息不够，无法正确访问</p>
<h2 id="7-2-正确修改"><a href="#7-2-正确修改" class="headerlink" title="7.2 正确修改"></a>7.2 正确修改</h2><p><strong>添加Cookie信息</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Cookie:</span><br><span class="line">SINAGLOBAL=6664999447883.047.1685427483001; ULV=1685427483097:1:1:1:6664999447883.047.1685427483001:; XSRF-TOKEN=fixtHOwhdlfU4ShqjmpCjMAz; SUB=_2A25JmmvSDeRhGeFO7FYV9i_EyTyIHXVq7toarDV8PUNbmtANLWzDkW9NQUR46RjEnGZiDiVKFwdERkwUGCyDr3pR; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9W5lDnHA1MVrHu_3_ljBSdRy5JpX5KzhUgL.FoM7S0BXSo2Reo52dJLoI7f2MJ8rdc4kBJ8_qJva; ALF=1719619330; SSOLoginState=1688083330; WBPSESS=VUh1dQeaNE_DJ6H7aSNQDBgox7Vik0e5-Iwx3WN-nk01w7SoOcEhzwg5oULcHibaNwgdibVmopSq389wc5bSyv-8bcP8qSHgm98oqg_e-RMoiAj25rHZBCRDNbcLkDBRGlJDSuD9Rhv9kaNSE-zdpw==</span><br></pre></td></tr></table></figure>

<p><strong>代码</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># _*_ coding : utf-8 _*_</span></span><br><span class="line"><span class="comment"># @Time : 2023/6/30 8:07</span></span><br><span class="line"><span class="comment"># @Author : bamboo</span></span><br><span class="line"><span class="comment"># @File : urllib_cookie_login_weibo</span></span><br><span class="line"><span class="comment"># @Project : py-pro</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://weibo.com/u/7074461820&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Cookie&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;SINAGLOBAL=6664999447883.047.1685427483001; ULV=1685427483097:1:1:1:6664999447883.047.1685427483001:; XSRF-TOKEN=fixtHOwhdlfU4ShqjmpCjMAz; SUB=_2A25JmmvSDeRhGeFO7FYV9i_EyTyIHXVq7toarDV8PUNbmtANLWzDkW9NQUR46RjEnGZiDiVKFwdERkwUGCyDr3pR; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9W5lDnHA1MVrHu_3_ljBSdRy5JpX5KzhUgL.FoM7S0BXSo2Reo52dJLoI7f2MJ8rdc4kBJ8_qJva; ALF=1719619330; SSOLoginState=1688083330; WBPSESS=VUh1dQeaNE_DJ6H7aSNQDBgox7Vik0e5-Iwx3WN-nk01w7SoOcEhzwg5oULcHibaNwgdibVmopSq389wc5bSyv-8bcP8qSHgm98oqg_e-RMoiAj25rHZBCRDNbcLkDBRGlJDSuD9Rhv9kaNSE-zdpw==&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<p><strong>原因</strong>：cookie中携带了登录信息，有了登录之后的cookie才能携带cookie进入到任何页面</p>
<h1 id="八、handler处理器"><a href="#八、handler处理器" class="headerlink" title="八、handler处理器"></a>八、handler处理器</h1><p>urllib.request.urlopen(url) : 不能定制请求头</p>
<p>urllib.request.Request(url,headers,data) : 可以定制请求头</p>
<p><strong>handler</strong> : 定制更高级的请求头</p>
<ul>
<li>动态cookie</li>
<li>代理</li>
</ul>
<p><strong>使用</strong> ：</p>
<ol>
<li>获取handler对象 handler &#x3D; urllib.request.HTTPHandler()</li>
<li>获取opener对象 opener &#x3D; urllib.request.build_opener(handler)</li>
<li>调用open对象 response &#x3D; opener.open(request)</li>
</ol>
<p>案例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># _*_ coding : utf-8 _*_</span></span><br><span class="line"><span class="comment"># @Time : 2023/7/1 12:59</span></span><br><span class="line"><span class="comment"># @Author : bamboo</span></span><br><span class="line"><span class="comment"># @File : urllib_handler</span></span><br><span class="line"><span class="comment"># @Project : py-pro</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建handler</span></span><br><span class="line"><span class="comment"># 1.获取handler对象</span></span><br><span class="line">handler = urllib.request.HTTPHandler()</span><br><span class="line"><span class="comment"># 2.获取opener对象</span></span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line"><span class="comment"># 3.调用open对象</span></span><br><span class="line">response = opener.<span class="built_in">open</span>(request)</span><br><span class="line"></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<h1 id="九、代理"><a href="#九、代理" class="headerlink" title="九、代理"></a>九、代理</h1><ol>
<li>突破自身IP访问显示，访问外网</li>
<li>访问一些单位或团体内部资源</li>
<li>提高访问速度</li>
<li>隐藏真实IP，免受攻击</li>
</ol>
<p><strong>步骤</strong></p>
<ol>
<li><p>request &#x3D; urllib.request.Request(url&#x3D;url, headers&#x3D;headers)</p>
</li>
<li><p>设置proxies字典</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">proxies = &#123;</span><br><span class="line">    &#x27;http&#x27;: &#x27;182.139.110.14:9000&#x27;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用处理器 handler &#x3D; urllib.request.ProxyHandler(proxies&#x3D;proxies)</p>
</li>
<li><p>opener &#x3D; urllib.request.build_opener(handler)</p>
</li>
<li><p>response &#x3D; opener.open(request)</p>
</li>
</ol>
<p><strong>案例</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># _*_ coding : utf-8 _*_</span></span><br><span class="line"><span class="comment"># @Time : 2023/7/1 14:00</span></span><br><span class="line"><span class="comment"># @Author : bamboo</span></span><br><span class="line"><span class="comment"># @File : urllib_proxy</span></span><br><span class="line"><span class="comment"># @Project : py-pro</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com/s?wd=ip&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Cookie&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;BIDUPSID=06131A5CB3B3012812267B71938D92FF; PSTM=1679290628; BDUSS=XFtamFsanNsZWJWTFdoMUhTSXNKWXJxMnNGeVVqblIxTnVUd05zNlc3S0NrbnBrRVFBQUFBJCQAAAAAAAAAAAEAAADiwVCv0uCzvl~csgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIIFU2SCBVNkM; BDUSS_BFESS=XFtamFsanNsZWJWTFdoMUhTSXNKWXJxMnNGeVVqblIxTnVUd05zNlc3S0NrbnBrRVFBQUFBJCQAAAAAAAAAAAEAAADiwVCv0uCzvl~csgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIIFU2SCBVNkM; BAIDUID=4E8EC46552D9E18C72A862024180E013:SL=0:NR=10:FG=1; BD_HOME=1; H_PS_PSSID=36553_38857_38795_38958_38955_38832_38920_38806_38989_26350; BD_UPN=12314753; BA_HECTOR=ah018k040l8g018h80a18g8b1i9vg631o; BAIDUID_BFESS=4E8EC46552D9E18C72A862024180E013:SL=0:NR=10:FG=1; ZFY=BXOBRbhZzq3:AgQrE2UdwmoKEVxRJv4XVrrWQOLZv9lE:C; BDRCVFR[feWj1Vr5u3D]=I67x6TjHwwYf0; BD_CK_SAM=1; PSINO=5; delPer=0; BDORZ=B490B5EBF6F3CD402E515D22BCDA1598; baikeVisitId=a33ef4a5-bd67-4b3a-ac66-6f07ca3fee30; B64_BOT=1; sug=3; sugstore=0; ORIGIN=2; bdime=0; H_PS_645EC=74e2BAm6baEmykvFdTDJUKuT698Uocc37KZSVsBfg2KJ3c0eUvWu9sHBIXU&#x27;</span>,</span><br><span class="line">    <span class="comment"># &#x27;Referer&#x27;:</span></span><br><span class="line">    <span class="comment">#     &#x27;http://www.baidu.com/s?wd=ip&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 代理ip</span></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;182.139.110.14:9000&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line"></span><br><span class="line">handler = urllib.request.ProxyHandler(proxies=proxies)</span><br><span class="line"></span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line"></span><br><span class="line">response = opener.<span class="built_in">open</span>(request)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;proxy/proxy01.html&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(content)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="9-1-代理池创建"><a href="#9-1-代理池创建" class="headerlink" title="9.1 代理池创建"></a>9.1 代理池创建</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 代理池创建</span></span><br><span class="line">proxies_pool = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;182.139.110.14:9000&#x27;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;182.139.110.14:9001&#x27;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;182.139.110.14:9002&#x27;</span></span><br><span class="line">    &#125;, &#123;</span><br><span class="line">        <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;182.139.110.14:9003&#x27;</span></span><br><span class="line">    &#125;, &#123;</span><br><span class="line">        <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;182.139.110.14:9004&#x27;</span></span><br><span class="line">    &#125;, &#123;</span><br><span class="line">        <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;182.139.110.14:9005&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"><span class="comment"># 随机代理</span></span><br><span class="line">proxies = random.choice(proxies_pool)</span><br><span class="line"><span class="comment"># print(proxies)</span></span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com/s?wd=ip&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Cookie&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;BIDUPSID=06131A5CB3B3012812267B71938D92FF; PSTM=1679290628; BDUSS=XFtamFsanNsZWJWTFdoMUhTSXNKWXJxMnNGeVVqblIxTnVUd05zNlc3S0NrbnBrRVFBQUFBJCQAAAAAAAAAAAEAAADiwVCv0uCzvl~csgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIIFU2SCBVNkM; BDUSS_BFESS=XFtamFsanNsZWJWTFdoMUhTSXNKWXJxMnNGeVVqblIxTnVUd05zNlc3S0NrbnBrRVFBQUFBJCQAAAAAAAAAAAEAAADiwVCv0uCzvl~csgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIIFU2SCBVNkM; BAIDUID=4E8EC46552D9E18C72A862024180E013:SL=0:NR=10:FG=1; BD_HOME=1; H_PS_PSSID=36553_38857_38795_38958_38955_38832_38920_38806_38989_26350; BD_UPN=12314753; BA_HECTOR=ah018k040l8g018h80a18g8b1i9vg631o; BAIDUID_BFESS=4E8EC46552D9E18C72A862024180E013:SL=0:NR=10:FG=1; ZFY=BXOBRbhZzq3:AgQrE2UdwmoKEVxRJv4XVrrWQOLZv9lE:C; BDRCVFR[feWj1Vr5u3D]=I67x6TjHwwYf0; BD_CK_SAM=1; PSINO=5; delPer=0; BDORZ=B490B5EBF6F3CD402E515D22BCDA1598; baikeVisitId=a33ef4a5-bd67-4b3a-ac66-6f07ca3fee30; B64_BOT=1; sug=3; sugstore=0; ORIGIN=2; bdime=0; H_PS_645EC=74e2BAm6baEmykvFdTDJUKuT698Uocc37KZSVsBfg2KJ3c0eUvWu9sHBIXU&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url=url,headers=headers)</span><br><span class="line"></span><br><span class="line">handler = urllib.request.ProxyHandler(proxies)</span><br><span class="line"></span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line"></span><br><span class="line">response = opener.<span class="built_in">open</span>(request)</span><br><span class="line"></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="十、获取网页部分源码手段"><a href="#十、获取网页部分源码手段" class="headerlink" title="十、获取网页部分源码手段"></a>十、获取网页部分源码手段</h1><h2 id="10-1-xpath"><a href="#10-1-xpath" class="headerlink" title="10.1 xpath"></a>10.1 xpath</h2><ol>
<li>浏览器添加XPath Helper.crx插件<ul>
<li>浏览器不支持crx文件时直接修改后缀为zip重新拖拽</li>
<li>使用方式：网页ctrl+shift+x出现小黑框</li>
<li>此插件用于在网页写xpath语法来验证自己需要获取的数据是否正确</li>
</ul>
</li>
<li>安装lxml库<ul>
<li>pip install lxml [-i <a target="_blank" rel="noopener" href="https://pypi.douban.com/simple]">https://pypi.douban.com/simple]</a></li>
</ul>
</li>
<li>导入etree包<ul>
<li>from lxml import etree</li>
</ul>
</li>
<li>xpath解析<ul>
<li>本地文件 html_tree &#x3D; etree.parse(‘xxx.html’)</li>
<li>服务器响应数据html_tree &#x3D; etree.HTML(response.read().decode(‘utf-8’))</li>
</ul>
</li>
<li>获取数据<ul>
<li>html_tree.xpath(xpath路径)</li>
</ul>
</li>
<li>xpath基本语法<ol>
<li>路径查询<ul>
<li>&#x2F;&#x2F; : 查找所有子孙节点，不考虑层级关系</li>
<li>&#x2F; : 找直接子节点</li>
</ul>
</li>
<li>谓语查询<ul>
<li>&#x2F;&#x2F;div[@id]</li>
<li>&#x2F;&#x2F;div[@id&#x3D;”maincontent”]</li>
</ul>
</li>
<li>属性查询 &#x2F;@class 也可以是别的属性<ul>
<li>&#x2F;&#x2F;@class</li>
</ul>
</li>
<li>模糊查询<ul>
<li>&#x2F;&#x2F;div[contains(@id,”he”)]</li>
<li>&#x2F;&#x2F;div[starts-with(@id,”he”)]</li>
</ul>
</li>
<li>内容查询 &#x2F;text()<ul>
<li>这个text()可以获取html标签中的innerText数据</li>
<li>&#x2F;&#x2F;div&#x2F;h1&#x2F;text()</li>
</ul>
</li>
<li>逻辑运算<ul>
<li>&#x2F;&#x2F;div[@id&#x3D;”head” and @class&#x3D;”s_down”]</li>
<li>title | &#x2F;&#x2F;price</li>
</ul>
</li>
</ol>
</li>
</ol>
<h3 id="10-1-1-xpath语法使用"><a href="#10-1-1-xpath语法使用" class="headerlink" title="10.1.1 xpath语法使用"></a>10.1.1 xpath语法使用</h3><ol>
<li><p>获取该网页下class为newsbody下的class为nbody的文本</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nbodys = tree.xpath(<span class="string">&#x27;//div[@class=&quot;newsbody&quot;]//div[@class=&quot;nbodys&quot;]/text()&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取class</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nbodys_class = tree.xpath(<span class="string">&#x27;//div[@class=&quot;newsbody&quot;]//div[@class=&quot;nbodys&quot;]/@class&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="10-1-2-示例"><a href="#10-1-2-示例" class="headerlink" title="10.1.2 示例"></a>10.1.2 示例</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># _*_ coding : utf-8 _*_</span></span><br><span class="line"><span class="comment"># @Time : 2023/7/1 16:32</span></span><br><span class="line"><span class="comment"># @Author : bamboo</span></span><br><span class="line"><span class="comment"># @File : use</span></span><br><span class="line"><span class="comment"># @Project : py-pro</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://www.bbiquge.net/book/133303/&#x27;</span></span><br><span class="line">page = <span class="string">&#x27;index_1.html&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="comment"># &#x27;Cookie&#x27;:</span></span><br><span class="line">    <span class="comment">#     &#x27;BIDUPSID=06131A5CB3B3012812267B71938D92FF; PSTM=1679290628; BDUSS=XFtamFsanNsZWJWTFdoMUhTSXNKWXJxMnNGeVVqblIxTnVUd05zNlc3S0NrbnBrRVFBQUFBJCQAAAAAAAAAAAEAAADiwVCv0uCzvl~csgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIIFU2SCBVNkM; BDUSS_BFESS=XFtamFsanNsZWJWTFdoMUhTSXNKWXJxMnNGeVVqblIxTnVUd05zNlc3S0NrbnBrRVFBQUFBJCQAAAAAAAAAAAEAAADiwVCv0uCzvl~csgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIIFU2SCBVNkM; BAIDUID=4E8EC46552D9E18C72A862024180E013:SL=0:NR=10:FG=1; BD_HOME=1; H_PS_PSSID=36553_38857_38795_38958_38955_38832_38920_38806_38989_26350; BD_UPN=12314753; BA_HECTOR=ah018k040l8g018h80a18g8b1i9vg631o; BAIDUID_BFESS=4E8EC46552D9E18C72A862024180E013:SL=0:NR=10:FG=1; ZFY=BXOBRbhZzq3:AgQrE2UdwmoKEVxRJv4XVrrWQOLZv9lE:C; BDRCVFR[feWj1Vr5u3D]=I67x6TjHwwYf0; BD_CK_SAM=1; PSINO=5; delPer=0; BDORZ=B490B5EBF6F3CD402E515D22BCDA1598; baikeVisitId=a33ef4a5-bd67-4b3a-ac66-6f07ca3fee30; B64_BOT=1; sug=3; sugstore=0; ORIGIN=2; bdime=0; H_PS_645EC=74e2BAm6baEmykvFdTDJUKuT698Uocc37KZSVsBfg2KJ3c0eUvWu9sHBIXU&#x27;,</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url=url+page,headers=headers)</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;gbk&#x27;</span>)</span><br><span class="line"></span><br><span class="line">tree = etree.HTML(content)</span><br><span class="line"><span class="built_in">print</span>(tree)</span><br><span class="line">hrefs = tree.xpath(<span class="string">&#x27;//div[@class=&quot;zjbox&quot;]/dl[@class=&quot;zjlist&quot;]/dd/a/@href&#x27;</span>)</span><br><span class="line"></span><br><span class="line">urls = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(hrefs)):</span><br><span class="line">    urls.append(url+<span class="string">&#x27;/&#x27;</span>+hrefs[i])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">    <span class="built_in">print</span>(url)</span><br></pre></td></tr></table></figure>

<h3 id="10-1-3-大型xpath抓取下载至本地"><a href="#10-1-3-大型xpath抓取下载至本地" class="headerlink" title="10.1.3 大型xpath抓取下载至本地"></a>10.1.3 大型xpath抓取下载至本地</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># _*_ coding : utf-8 _*_</span></span><br><span class="line"><span class="comment"># @Time : 2023/7/1 21:06</span></span><br><span class="line"><span class="comment"># @Author : bamboo</span></span><br><span class="line"><span class="comment"># @File : urllib</span></span><br><span class="line"><span class="comment"># @Project : py-pro</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_request</span>(<span class="params">page</span>):</span><br><span class="line">    <span class="keyword">if</span> page == <span class="number">1</span>:</span><br><span class="line">        url = <span class="string">&#x27;https://sc.chinaz.com/tupian/meinvxiezhen.html&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        url = <span class="string">&#x27;https://sc.chinaz.com/tupian/meinvxiezhen_&#x27;</span> + <span class="built_in">str</span>(page) + <span class="string">&#x27;.html&#x27;</span></span><br><span class="line">    <span class="comment"># 设置请求头</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 请求对象定制</span></span><br><span class="line">    request = urllib.request.Request(url=url,headers=headers)</span><br><span class="line">    <span class="keyword">return</span> request</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_content</span>(<span class="params">request</span>):</span><br><span class="line">    response = urllib.request.urlopen(request)</span><br><span class="line">    content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> content</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">down_load</span>(<span class="params">content</span>):</span><br><span class="line">    <span class="comment"># 下载图片</span></span><br><span class="line">    <span class="comment"># urllib.request.urlretrieve(&#x27;图片地址&#x27;,&#x27;文件名&#x27;)</span></span><br><span class="line">    tree = etree.HTML(content)</span><br><span class="line">    name_list = tree.xpath(<span class="string">&#x27;//div[@class=&quot;container&quot;]//div/img/@alt&#x27;</span>)</span><br><span class="line">    src_list = tree.xpath(<span class="string">&#x27;//div[@class=&quot;container&quot;]//div/img/@data-original&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(name_list)):</span><br><span class="line">        name = name_list[i]</span><br><span class="line">        src = src_list[i]</span><br><span class="line">        url = <span class="string">&#x27;http:&#x27;</span>+src</span><br><span class="line">        urllib.request.urlretrieve(url=url,filename=<span class="string">&#x27;img/&#x27;</span>+name+<span class="string">&#x27;.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    start_page = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入起始页码：&#x27;</span>))</span><br><span class="line">    end_page = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入结束页码：&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(start_page, end_page + <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 请求对象定制</span></span><br><span class="line">        request = create_request(page)</span><br><span class="line">        <span class="comment"># 获取网页源码</span></span><br><span class="line">        content = get_content(request)</span><br><span class="line">        <span class="comment"># 下载</span></span><br><span class="line">        down_load(content)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;第&#x27;</span>+<span class="built_in">str</span>(page)+<span class="string">&#x27;下载完成&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="10-2-JsonPath"><a href="#10-2-JsonPath" class="headerlink" title="10.2 JsonPath"></a>10.2 JsonPath</h2><ol>
<li><p>pip安装</p>
<ul>
<li>pip install jsonpath</li>
</ul>
</li>
<li><p>使用说明(获取json对象)</p>
<ol>
<li>本地json文件获取对象</li>
</ol>
<ul>
<li>obj &#x3D; json.load(open(‘json文件’,’r’,encoding&#x3D;’utf-8’))</li>
<li>import json</li>
<li>如果是网络资源的json保存到本地再使用</li>
</ul>
  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">obj = json.load(<span class="built_in">open</span>(<span class="string">&#x27;jsonpath.json&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>))</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>使用jsonpath</li>
</ol>
<ul>
<li>ret &#x3D; jsonpath.jsonpath(obj,’jsonpath语法’)</li>
<li>import jsonpath</li>
</ul>
</li>
</ol>
<p><strong>案例</strong>：获取淘票票所有城市</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># _*_ coding : utf-8 _*_</span></span><br><span class="line"><span class="comment"># @Time : 2023/7/2 15:18</span></span><br><span class="line"><span class="comment"># @Author : bamboo</span></span><br><span class="line"><span class="comment"># @File : urllib_jsonpath_taopiaopiao</span></span><br><span class="line"><span class="comment"># @Project : py-pro</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> jsonpath</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://dianying.taobao.com/cityAction.json?activityId&amp;_ksTS=1688282177270_108&amp;jsoncallback=jsonp109&amp;action=cityAction&amp;n_s=new&amp;event_submit_doGetAllRegion=true&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/javascript, application/javascript, application/ecmascript, application/x-ecmascript, */*; q=0.01&#x27;</span>,</span><br><span class="line">    <span class="comment"># &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate, br&#x27;,</span></span><br><span class="line">    <span class="string">&#x27;Accept-Language&#x27;</span>: <span class="string">&#x27;zh-CN,zh;q=0.9&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Bx-V&#x27;</span>: <span class="string">&#x27;2.5.0&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;cna=6zKQHGg562ACATswb40Y5qgs; t=62bc0d82720dc60b137ad4f1304cd5ee; xlly_s=1; cookie2=13f702bb8b29a0ea7a1f19121af7e5b6; v=0; _tb_token_=5e8d43fe773f; tfstk=dDSp3DYxg5VhsMe8xBUg4DXIxpwgoMBUK6WjqQAnP1COg6eer2bhybdOhJR3zy5RW_1w-BsRU0p5F_yeZJzGL9-yVSVc2oXFLWTiX3BS59nVR3N0io0iCePHVg2TeLIMBfn_gPofcgvQPLKrgYK4FpYpGOUqq0oHCjAAd4ijDGQ9JOyAmiER2jAvE2wTB4uyRdPvO88C.; l=fBO47mseN_qPmZjaBO5CFurza77OmQRb8sPzaNbMiIEGa1mctFsHZNC1c_XMSdtjgTfURexyVhmX9dEplCUd_giMW_N-1NKcFYJ6-bpU-L5..; isg=BOjoROdYGCr4czQ8JTX6KMlNudb6EUwbtnsuNKIbqWNW_YlnSCcPq1Bz9ZUNTQTz&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Referer&#x27;</span>: <span class="string">&#x27;https://dianying.taobao.com/&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Sec-Ch-Ua&#x27;</span>: <span class="string">&#x27;&quot;Chromium&quot;;v=&quot;116&quot;, &quot;Not)A;Brand&quot;;v=&quot;24&quot;, &quot;Google Chrome&quot;;v=&quot;116&quot;&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Sec-Ch-Ua-Mobile&#x27;</span>: <span class="string">&#x27;?0&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Sec-Ch-Ua-Platform&#x27;</span>: <span class="string">&#x27;&quot;Windows&quot;&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Sec-Fetch-Dest&#x27;</span>: <span class="string">&#x27;empty&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Sec-Fetch-Mode&#x27;</span>: <span class="string">&#x27;cors&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Sec-Fetch-Site&#x27;</span>: <span class="string">&#x27;same-origin&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;X-Requested-With&#x27;</span>: <span class="string">&#x27;XMLHttpRequest&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">result = content.split(<span class="string">&#x27;(&#x27;</span>)[<span class="number">1</span>][:-<span class="number">2</span>]</span><br><span class="line"><span class="comment"># print(result)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 存json文件</span></span><br><span class="line"><span class="comment"># with open(&#x27;taopiaopiao.json&#x27;,&#x27;w&#x27;,encoding=&#x27;utf-8&#x27;) as fp:</span></span><br><span class="line"><span class="comment">#     fp.write(result)</span></span><br><span class="line"></span><br><span class="line">obj = json.load(<span class="built_in">open</span>(<span class="string">&#x27;taopiaopiao.json&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">region_names = jsonpath.jsonpath(obj,<span class="string">&#x27;$..regionName&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(region_names)</span><br></pre></td></tr></table></figure>



<h2 id="10-3-BeautifulSoup"><a href="#10-3-BeautifulSoup" class="headerlink" title="10.3 BeautifulSoup"></a>10.3 BeautifulSoup</h2><p>缺点：没有lxml效率高</p>
<p>优点：使用方便</p>
<ol>
<li><p>安装 pip install bs4</p>
</li>
<li><p>导入 from bs4 import BeautifulSoup</p>
</li>
<li><p>创建对象</p>
<ul>
<li>服务器响应文件</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">soup = BeautifulSoup(response.read().decode(), <span class="string">&#x27;lxml&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>本地文件</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">soup = BeautifulSoup(<span class="built_in">open</span>(<span class="string">&#x27;1.html&#x27;</span>), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="comment"># 注：默认打开文件编码gbk，需要指定打开编码格式</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="10-3-1-节点定位"><a href="#10-3-1-节点定位" class="headerlink" title="10.3.1 节点定位"></a>10.3.1 节点定位</h3><ol>
<li><p>根据标签名查找节点</p>
<ul>
<li>soup.a<ul>
<li>只能找到第一个a，后面加属性名可以获取它的值</li>
<li>soup.a.name</li>
<li>soup.a.attrs</li>
</ul>
</li>
</ul>
</li>
<li><p>函数</p>
<ol>
<li><p>.find(返回一个对象)</p>
<ul>
<li>find(‘a’) : 只找到第一个a标签</li>
<li>find(‘a’, title&#x3D;’名字’)</li>
<li>find(‘a’, class_&#x3D;’名字’)<ul>
<li>class属性只能写成class_</li>
</ul>
</li>
</ul>
</li>
<li><p>.find_all(返回一个列表)</p>
<ul>
<li>find_all(‘a’) : 查到所有的a</li>
<li>find_all([‘a’, ‘span’]) : 返回所有的a和span</li>
<li>fnd_all(‘a’, limit&#x3D;2) : 只查找前两个a</li>
</ul>
</li>
<li><p>.select(根据选择器得到节点对象) 【推荐】</p>
<ol>
<li><p>element</p>
<ul>
<li>eg:p</li>
<li>返回的是一个列表，并且会返回多个数据</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">soup.select(&#x27;a&#x27;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>.class</p>
<ul>
<li>eg:.firstname</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">soup.select(&#x27;.a1&#x27;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>#id</p>
<ul>
<li>eg:#firstname</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">soup.select(&#x27;#l1&#x27;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>属性选择器</p>
<ul>
<li>查找li中有id属性的标签</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">soup.select(&#x27;li[id]&#x27;)</span><br></pre></td></tr></table></figure>

<ul>
<li>查找li中id&#x3D;l2的标签</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">soup.select(&#x27;li[id=&quot;l2&quot;]&#x27;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>层级选择器</p>
<ul>
<li>后代 element element</li>
<li>子代 element&gt;element</li>
<li>同级 element,element</li>
</ul>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="10-3-2-节点信息"><a href="#10-3-2-节点信息" class="headerlink" title="10.3.2 节点信息"></a>10.3.2 节点信息</h3><ol>
<li><p>获取节点内容</p>
<ol>
<li>obj.string</li>
<li>obj.get_text() 【推荐】</li>
</ol>
</li>
<li><p>节点的属性</p>
<ol>
<li><p>tag.name 获取标签名</p>
<p>eg:tag &#x3D; find(‘li’)</p>
<p>​	print(tag.name)</p>
</li>
<li><p>tag.attrs将属性值作为一个字典返回</p>
</li>
</ol>
</li>
<li><p>获取节点属性</p>
<ol>
<li>obj.attrs.get(‘title’) 【常用】</li>
<li>obj.get(‘title’)</li>
<li>obj[‘title’]</li>
</ol>
</li>
</ol>
<h1 id="十一、反扒手段统计"><a href="#十一、反扒手段统计" class="headerlink" title="十一、反扒手段统计"></a>十一、反扒手段统计</h1><h2 id="11-1-header反爬"><a href="#11-1-header反爬" class="headerlink" title="11.1 header反爬"></a>11.1 header反爬</h2><p>验证浏览器信息</p>
<h2 id="11-2-cookie反爬"><a href="#11-2-cookie反爬" class="headerlink" title="11.2 cookie反爬"></a>11.2 cookie反爬</h2><p>验证登录信息</p>
<h2 id="11-3-referer反爬"><a href="#11-3-referer反爬" class="headerlink" title="11.3 referer反爬"></a>11.3 referer反爬</h2><p>判断是否由某网站跳转，一般情况做图片防盗链</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://blog.dragonbamboo.com">Bamboo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://blog.dragonbamboo.com/2023/08/31/urllib/">http://blog.dragonbamboo.com/2023/08/31/urllib/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://blog.dragonbamboo.com" target="_blank">竹间小客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/python/">python</a><a class="post-meta__tags" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a><a class="post-meta__tags" href="/tags/urllib/">urllib</a></div><div class="post_share"><div class="social-share" data-image="/img/ava.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2023/08/31/selenium/" title="selenium"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">selenium</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/08/31/requests/" title="requests"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-31</div><div class="title">requests</div></div></a></div><div><a href="/2023/08/31/selenium/" title="selenium"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-31</div><div class="title">selenium</div></div></a></div><div><a href="/2023/08/31/scrapy/" title="scrapy"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-31</div><div class="title">scrapy</div></div></a></div><div><a href="/2023/08/30/python/" title="python"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-30</div><div class="title">python</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/ava.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Bamboo</div><div class="author-info__description">所有随风而逝的都是属于昨天的，所有历经风雨留下来的才是面向未来的。</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">33</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/dragonBamboo"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的竹间小客</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%AF%BC%E6%A8%A1%E5%9D%97"><span class="toc-number">1.</span> <span class="toc-text">一、导模块</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%95%B4%E9%A1%B5%E6%8A%93%E5%8F%96"><span class="toc-number">2.</span> <span class="toc-text">二、整页抓取</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81HTTPResponse%E7%B1%BB%E5%9E%8B%E4%B8%8E%E6%96%B9%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">三、HTTPResponse类型与方法</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E4%B8%8B%E8%BD%BD%E8%B5%84%E6%BA%90"><span class="toc-number">4.</span> <span class="toc-text">四、下载资源</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-%E6%99%AE%E9%80%9A%E6%A8%A1%E5%BC%8F"><span class="toc-number">4.1.</span> <span class="toc-text">4.1 普通模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-%E5%8F%8D%E5%8F%8D%E7%88%AC%E6%A8%A1%E5%BC%8F"><span class="toc-number">4.2.</span> <span class="toc-text">4.2 反反爬模式</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%8F%8D%E7%88%AC%E5%8F%8D%E5%88%B6"><span class="toc-number">5.</span> <span class="toc-text">五、反爬反制</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5"><span class="toc-number">5.1.</span> <span class="toc-text">5.1 反爬手段</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-%E8%AF%B7%E6%B1%82%E5%A4%B4UA%E5%AE%9A%E5%88%B6-%E5%8F%8D%E5%88%B61"><span class="toc-number">5.2.</span> <span class="toc-text">5.2 请求头UA定制(反制1)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3-GET%E8%AF%B7%E6%B1%82"><span class="toc-number">5.3.</span> <span class="toc-text">5.3 GET请求</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-4-POST%E8%AF%B7%E6%B1%82"><span class="toc-number">5.4.</span> <span class="toc-text">5.4 POST请求</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-1-%E8%AF%B7%E6%B1%82deep%E8%8E%B7%E5%8F%96%E7%BF%BB%E8%AF%91"><span class="toc-number">5.4.1.</span> <span class="toc-text">5.4.1 请求deep获取翻译</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-2-%E8%AF%B7%E6%B1%82%E7%99%BE%E5%BA%A6%E7%BF%BB%E8%AF%91-%E5%8F%8D%E5%88%B62"><span class="toc-number">5.4.2.</span> <span class="toc-text">5.4.2 请求百度翻译(反制2)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-3-POST%E6%95%B0%E6%8D%AE%E6%AD%A3%E5%88%99%E6%9B%BF%E6%8D%A2"><span class="toc-number">5.4.3.</span> <span class="toc-text">5.4.3 POST数据正则替换</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-5-ajax"><span class="toc-number">5.5.</span> <span class="toc-text">5.5 ajax</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-1-get"><span class="toc-number">5.5.1.</span> <span class="toc-text">5.5.1 get</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-2-post"><span class="toc-number">5.5.2.</span> <span class="toc-text">5.5.2 post</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E7%88%AC%E8%99%AB%E5%BC%82%E5%B8%B8"><span class="toc-number">6.</span> <span class="toc-text">六、爬虫异常</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#6-1-%E5%AF%BC%E5%85%A5%E6%A8%A1%E5%9D%97"><span class="toc-number">6.1.</span> <span class="toc-text">6.1 导入模块</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-2-HTTPError"><span class="toc-number">6.2.</span> <span class="toc-text">6.2 HTTPError</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-3-URLError"><span class="toc-number">6.3.</span> <span class="toc-text">6.3 URLError</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-4-%E6%8D%95%E8%8E%B7%E5%BC%82%E5%B8%B8"><span class="toc-number">6.4.</span> <span class="toc-text">6.4 捕获异常</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-5-%E6%A1%88%E4%BE%8B"><span class="toc-number">6.5.</span> <span class="toc-text">6.5 案例</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%83%E3%80%81Cookie%E7%99%BB%E5%BD%95"><span class="toc-number">7.</span> <span class="toc-text">七、Cookie登录</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#7-1-%E9%94%99%E8%AF%AF%E6%9B%B4%E6%AD%A3"><span class="toc-number">7.1.</span> <span class="toc-text">7.1 错误更正</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-2-%E6%AD%A3%E7%A1%AE%E4%BF%AE%E6%94%B9"><span class="toc-number">7.2.</span> <span class="toc-text">7.2 正确修改</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AB%E3%80%81handler%E5%A4%84%E7%90%86%E5%99%A8"><span class="toc-number">8.</span> <span class="toc-text">八、handler处理器</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B9%9D%E3%80%81%E4%BB%A3%E7%90%86"><span class="toc-number">9.</span> <span class="toc-text">九、代理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#9-1-%E4%BB%A3%E7%90%86%E6%B1%A0%E5%88%9B%E5%BB%BA"><span class="toc-number">9.1.</span> <span class="toc-text">9.1 代理池创建</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E3%80%81%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5%E9%83%A8%E5%88%86%E6%BA%90%E7%A0%81%E6%89%8B%E6%AE%B5"><span class="toc-number">10.</span> <span class="toc-text">十、获取网页部分源码手段</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#10-1-xpath"><span class="toc-number">10.1.</span> <span class="toc-text">10.1 xpath</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-1-1-xpath%E8%AF%AD%E6%B3%95%E4%BD%BF%E7%94%A8"><span class="toc-number">10.1.1.</span> <span class="toc-text">10.1.1 xpath语法使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-1-2-%E7%A4%BA%E4%BE%8B"><span class="toc-number">10.1.2.</span> <span class="toc-text">10.1.2 示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-1-3-%E5%A4%A7%E5%9E%8Bxpath%E6%8A%93%E5%8F%96%E4%B8%8B%E8%BD%BD%E8%87%B3%E6%9C%AC%E5%9C%B0"><span class="toc-number">10.1.3.</span> <span class="toc-text">10.1.3 大型xpath抓取下载至本地</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-2-JsonPath"><span class="toc-number">10.2.</span> <span class="toc-text">10.2 JsonPath</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-3-BeautifulSoup"><span class="toc-number">10.3.</span> <span class="toc-text">10.3 BeautifulSoup</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-3-1-%E8%8A%82%E7%82%B9%E5%AE%9A%E4%BD%8D"><span class="toc-number">10.3.1.</span> <span class="toc-text">10.3.1 节点定位</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-3-2-%E8%8A%82%E7%82%B9%E4%BF%A1%E6%81%AF"><span class="toc-number">10.3.2.</span> <span class="toc-text">10.3.2 节点信息</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E4%B8%80%E3%80%81%E5%8F%8D%E6%89%92%E6%89%8B%E6%AE%B5%E7%BB%9F%E8%AE%A1"><span class="toc-number">11.</span> <span class="toc-text">十一、反扒手段统计</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#11-1-header%E5%8F%8D%E7%88%AC"><span class="toc-number">11.1.</span> <span class="toc-text">11.1 header反爬</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-2-cookie%E5%8F%8D%E7%88%AC"><span class="toc-number">11.2.</span> <span class="toc-text">11.2 cookie反爬</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-3-referer%E5%8F%8D%E7%88%AC"><span class="toc-number">11.3.</span> <span class="toc-text">11.3 referer反爬</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/08/31/urllib/" title="urllib">urllib</a><time datetime="2023-08-31T06:19:19.000Z" title="发表于 2023-08-31 14:19:19">2023-08-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/08/31/selenium/" title="selenium">selenium</a><time datetime="2023-08-31T06:18:40.000Z" title="发表于 2023-08-31 14:18:40">2023-08-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/08/31/scrapy/" title="scrapy">scrapy</a><time datetime="2023-08-31T06:17:18.000Z" title="发表于 2023-08-31 14:17:18">2023-08-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/08/31/requests/" title="requests">requests</a><time datetime="2023-08-31T06:16:27.000Z" title="发表于 2023-08-31 14:16:27">2023-08-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/08/31/swagger/" title="swagger">swagger</a><time datetime="2023-08-31T05:59:45.000Z" title="发表于 2023-08-31 13:59:45">2023-08-31</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Bamboo</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat-btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script>(() => {
  const isChatBtn = true
  const isChatHideShow = true

  if (isChatBtn) {
    const close = () => {
      Chatra('minimizeWidget')
      Chatra('hide')
    }

    const open = () => {
      Chatra('openChat', true)
      Chatra('show')
    }

    window.ChatraSetup = {
      startHidden: true
    }
  
    window.chatBtnFn = () => {
      const isShow = document.getElementById('chatra').classList.contains('chatra--expanded')
      isShow ? close() : open()
    }
  } else if (isChatHideShow) {
    window.chatBtn = {
      hide: () => {
        Chatra('hide')
      },
      show: () => {
        Chatra('show')
      }
    }
  }

  (function(d, w, c) {
    w.ChatraID = 'mBkDBN8SKJcbca8bm'
    var s = d.createElement('script')
    w[c] = w[c] || function() {
        (w[c].q = w[c].q || []).push(arguments)
    }
    s.async = true
    s.src = 'https://call.chatra.io/chatra.js'
    if (d.head) d.head.appendChild(s)
  })(document, window, 'Chatra')

})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>