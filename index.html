
<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <title>竹客</title>
        <meta name="author" content="Bamboo" />
        <meta name="description" content="所有随风而逝的都是属于昨天的，所有历经风雨留下来的才是面向未来的。" />
        <meta name="keywords" content="" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
        <link rel="icon" href="/images/avatar.jpg" />
        <script src="https://cdn.staticfile.org/vue/3.3.4/vue.global.prod.min.js"></script>
<link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/6.4.0/css/all.min.css" />
<link rel="stylesheet" href="/css/fonts.min.css" />
<script> const mixins = {}; </script>

<script src="https://polyfill.io/v3/polyfill.min.js?features=default"></script>


<script src="https://cdn.staticfile.org/highlight.js/11.8.0/highlight.min.js"></script>
<script src="https://cdn.staticfile.org/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>
<link
    rel="stylesheet"
    href="https://cdn.staticfile.org/highlight.js/11.8.0/styles/github.min.css"
/>
<script src="/js/lib/highlight.js"></script>



<script src="/js/lib/preview.js"></script>





<script src="/js/lib/home.js"></script>

<link rel="stylesheet" href="/css/main.css" />

    <meta name="generator" content="Hexo 6.3.0"></head>
    <body>
        <div id="layout">
            <transition name="fade">
                <div id="loading" v-show="loading">
                    <div id="loading-circle">
                        <h2>LOADING</h2>
                        <p>加载过慢请开启缓存 浏览器默认开启</p>
                        <img src="/images/loading.gif" />
                    </div>
                </div>
            </transition>
            <div id="menu" :class="{ hidden: hiddenMenu, 'menu-color': menuColor}">
    <nav id="desktop-menu">
        <a class="title" href="/">
            <span>竹客</span>
        </a>
        
        <a href="/">
            <i class="fa-solid fa-house fa-fw"></i>
            <span>&ensp;Home</span>
        </a>
        
        <a href="/about">
            <i class="fa-solid fa-id-card fa-fw"></i>
            <span>&ensp;About</span>
        </a>
        
        <a href="/archives">
            <i class="fa-solid fa-box-archive fa-fw"></i>
            <span>&ensp;Archives</span>
        </a>
        
        <a href="/categories">
            <i class="fa-solid fa-bookmark fa-fw"></i>
            <span>&ensp;Categories</span>
        </a>
        
        <a href="/tags">
            <i class="fa-solid fa-tags fa-fw"></i>
            <span>&ensp;Tags</span>
        </a>
        
    </nav>
    <nav id="mobile-menu">
        <div class="title" @click="showMenuItems = !showMenuItems">
            <i class="fa-solid fa-bars fa-fw"></i>
            <span>&emsp;竹客</span>
        </div>
        <transition name="slide">
            <div class="items" v-show="showMenuItems">
                
                <a href="/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-house fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Home</div>
                    </div>
                </a>
                
                <a href="/about">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-id-card fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">About</div>
                    </div>
                </a>
                
                <a href="/archives">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-box-archive fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Archives</div>
                    </div>
                </a>
                
                <a href="/categories">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-bookmark fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Categories</div>
                    </div>
                </a>
                
                <a href="/tags">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-tags fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Tags</div>
                    </div>
                </a>
                
            </div>
        </transition>
    </nav>
</div>
<transition name="fade">
    <div id="menu-curtain" @click="showMenuItems = !showMenuItems" v-show="showMenuItems"></div>
</transition>

            <div id="main" :class="loading ? 'into-enter-from': 'into-enter-active'">
                <div id="home-head">
    <div id="home-background" ref="homeBackground" data-images="/images/background.jpg"></div>
    <div id="home-info" @click="homeClick">
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="info">
            <div class="wrap">
                <h1>竹客</h1>
                <h3></h3>
                <h5>所有随风而逝的都是属于昨天的，所有历经风雨留下来的才是面向未来的。</h5>
            </div>
        </span>
    </div>
</div>
<div id="home-posts-wrap" true ref="homePostsWrap">
    <div id="home-posts">
        

<div class="post">
    <a href="/2023/08/30/mybatis/">
        <h2 class="post-title">mybatis</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/8/30
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <p>[TOC]</p>
<hr>
<h1 id="一、基本部署"><a href="#一、基本部署" class="headerlink" title="一、基本部署"></a>一、基本部署</h1><h2 id="1-1-xml部署"><a href="#1-1-xml部署" class="headerlink" title="1.1 xml部署"></a>1.1 xml部署</h2><h3 id="1-1-1-依赖"><a href="#1-1-1-依赖" class="headerlink" title="1.1.1 依赖"></a>1.1.1 依赖</h3><pre><code class="xml">&lt;dependency&gt;
 &lt;groupId&gt;org.mybatis&lt;/groupId&gt;
 &lt;artifactId&gt;mybatis&lt;/artifactId&gt;
 &lt;version&gt;x.x.x&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<h3 id="1-1-2-业务代码"><a href="#1-1-2-业务代码" class="headerlink" title="1.1.2 业务代码"></a>1.1.2 业务代码</h3><pre><code class="java">String resource = &quot;mybatis-config.xml&quot;;
//读取流
InputStream inputStream = 		
    Resources.getResourceAsStream(resource);
//获取SqlSessionFactoryBuilder
SqlSessionFactoryBuilder sqlSessionFactoryBuilder = 
    new SqlSessionFactoryBuilder();
//获取SqlSessionFactory
SqlSessionFactory sqlSessionFactory=
    sqlSessionFactoryBuilder.build(inputStream);
//获取SqlSession：代表java程序和数据库之间的会话（自动提交）
SqlSession sqlSession = sqlSessionFactory.openSession(true);
//手动提交事务时不填写参数
//SqlSession sqlSession = sqlSessionFactory.openSession();
//获取mapper接口对象
UserMapper mapper = sqlSession.getMapper(UserMapper.class);
使用...
//手动提交事务
//sqlSession.commit();
//关闭sqlSession
sqlSession.close();
</code></pre>
<h3 id="1-1-3-mybatis-config-xml"><a href="#1-1-3-mybatis-config-xml" class="headerlink" title="1.1.3 mybatis-config.xml"></a>1.1.3 mybatis-config.xml</h3><pre><code class="xml">&lt;!--mybatis-config.xml--&gt;
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE configuration
 PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;
 &quot;https://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;
&lt;configuration&gt;
 &lt;environments default=&quot;development&quot;&gt;
 &lt;environment id=&quot;development&quot;&gt;
 &lt;transactionManager type=&quot;JDBC&quot;/&gt;
 &lt;dataSource type=&quot;POOLED&quot;&gt;
 &lt;property name=&quot;driver&quot; value=&quot;$&#123;driver&#125;&quot;/&gt;
 &lt;property name=&quot;url&quot; value=&quot;$&#123;url&#125;&quot;/&gt;
 &lt;property name=&quot;username&quot; value=&quot;$&#123;username&#125;&quot;/&gt;
 &lt;property name=&quot;password&quot; value=&quot;$&#123;password&#125;&quot;/&gt;
 &lt;/dataSource&gt;
 &lt;/environment&gt;
 &lt;/environments&gt;
 &lt;mappers&gt;
     &lt;!--配置package模式后，mapper接口和映射文件必须在同一级才能生效--&gt;
     &lt;package name=&quot;com.bamboo.mapper&quot;/&gt;
 &lt;/mappers&gt;
&lt;/configuration&gt;
</code></pre>
<h3 id="1-1-4-mapper-xml"><a href="#1-1-4-mapper-xml" class="headerlink" title="1.1.4 mapper.xml"></a>1.1.4 mapper.xml</h3><pre><code class="xml">&lt;!--UserMapper.xml--&gt;
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE mapper
 PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;
 &quot;https://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;
&lt;mapper namespace=&quot;org.mybatis.example.BlogMapper&quot;&gt;
 &lt;select id=&quot;selectBlog&quot; resultType=&quot;Blog&quot;&gt;
 select * from Blog where id = #&#123;id&#125;
 &lt;/select&gt;
&lt;/mapper&gt;
</code></pre>
<h2 id="1-2-springboot部署"><a href="#1-2-springboot部署" class="headerlink" title="1.2 springboot部署"></a>1.2 springboot部署</h2><h3 id="1-2-1-依赖"><a href="#1-2-1-依赖" class="headerlink" title="1.2.1 依赖"></a>1.2.1 依赖</h3><pre><code class="xml">        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;2.3.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>
<h3 id="1-2-2-yml配置"><a href="#1-2-2-yml配置" class="headerlink" title="1.2.2 yml配置"></a>1.2.2 yml配置</h3><pre><code class="yml">spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/fruitdb?useSSL=false
    username: root
    password: root
mybatis:
  mapper-locations: classpath:mapper/*.xml
  type-aliases-package: com.bamboo.model
</code></pre>
<h2 id="1-3-Mapper-java-和-Mapper-xml映射关系"><a href="#1-3-Mapper-java-和-Mapper-xml映射关系" class="headerlink" title="1.3 Mapper.java 和 Mapper.xml映射关系"></a>1.3 Mapper.java 和 Mapper.xml映射关系</h2><pre><code class="xml">&lt;!--mapper.xml--&gt;
&lt;insert id=&quot;insertUser&quot;&gt;
    insert into ...
&lt;/insert&gt;
</code></pre>
<pre><code class="java">//mapper.java
public interface UserMapper&#123;
    int insertUser(); //int为影响行数
&#125;
</code></pre>
<p>*映射关系使用id进行绑定mapper.java中的方法名</p>
<h1 id="二、属性"><a href="#二、属性" class="headerlink" title="二、属性"></a>二、属性</h1><h2 id="2-1-返回集"><a href="#2-1-返回集" class="headerlink" title="2.1 返回集"></a>2.1 返回集</h2><p>集合的返回集也是Bean，自动装配只设置类型就好</p>
<p>resultType: 设置默认的映射关系</p>
<p>resultMap: 设置自定义的映射关系</p>
<p>注意：</p>
<ol>
<li>查询的标签select必须设置属性resultType或resultMap，用于设置实体类和数据库表的映射关系<ul>
<li>resultType：自动映射，用于属性名和表中字段名一致的情况</li>
<li>resultMap：自定义映射，用于一对多或多对一或字段名和属性名不一致的情况</li>
</ul>
</li>
<li>当查询的数据为多条时，不能使用实体类作为返回值，只能使用集合，否则会抛出异常 TooManyResultsException；</li>
<li>但是若查询的数据只有一条，可以使用实体类或集合作为返回值</li>
</ol>
<h2 id="2-2-别名"><a href="#2-2-别名" class="headerlink" title="2.2 别名"></a>2.2 别名</h2><p>*<strong>typeAliases</strong>:写在config.xml中设置类型别名，只能别名javabean，如果不填写type设置别名，那么该类型拥有默认的别名，即类名不区分大小写</p>
<p><strong>项目使用</strong></p>
<pre><code>&lt;package name=&quot;包名&quot;/&gt;
</code></pre>
<p>包内所有Bean都被设置别名，且类名不区分大小写</p>
<h2 id="2-3-mappers配置"><a href="#2-3-mappers配置" class="headerlink" title="2.3 mappers配置"></a>2.3 mappers配置</h2><pre><code>&lt;package name=&quot;包名&quot;/&gt;
</code></pre>
<p>mapper接口所在的包要和映射文件所在包<strong>位置</strong>一致</p>
<p>mapper接口所在的包要和映射文件所在包<strong>名字</strong>一致</p>
<h2 id="2-4-MyBatis获取参数值"><a href="#2-4-MyBatis获取参数值" class="headerlink" title="2.4 MyBatis获取参数值*"></a>2.4 MyBatis获取参数值*</h2><p>两种方式：${} #{}</p>
<p>传值是按照顺序来进行的，与参数名无关</p>
<p>${} 字符串拼接方法，相当于createstatement，会导致SQL注入，使用需要<strong>增加引号</strong>‘${param}’</p>
<p>#{} 占位符赋值 方法，相当于preparedstatement，安全</p>
<p><strong>使用</strong>：**#{}**</p>
<ul>
<li>${}使用字符串拼接的方式拼接sql，若为字符串类型或日期类型的字段进行赋值时，需要手动加单引号</li>
<li>#{}使用占位符赋值的方式拼接sql，此时为字符串类型或日期类型的字段进行赋值时，可以自动添加单引号</li>
</ul>
<h2 id="2-5-mapper多参数传递"><a href="#2-5-mapper多参数传递" class="headerlink" title="2.5 mapper多参数传递"></a>2.5 mapper多参数传递</h2><p>*<strong>单参数</strong>时以任意的名称获取参数的值#{ }</p>
<ol>
<li><p>方式一【map集合】</p>
<ul>
<li><p>#{arg0} #{arg1}</p>
</li>
<li><p>#{param1} #{param2}</p>
<p>两者可混用</p>
</li>
</ul>
</li>
<li><p>Map手动设置</p>
<ul>
<li><p>Map传数据，#{username} #{password}传递</p>
<p>注：Map中<strong>key</strong>为#{}例如#{username}，<strong>value</strong>是传递的值</p>
</li>
</ul>
</li>
<li><p>实体类类型</p>
<ul>
<li><p>#{实体类属性名}</p>
<p>属性：#{username}指代的不是成员变量，是对应的get,set方法名，如getUserName()，写法就是#{userName}</p>
</li>
</ul>
</li>
<li><p>命名参数@Param</p>
<ul>
<li><p>传参时用@Param(“username”) String username进行绑定</p>
</li>
<li><p>@Param对象示例</p>
<pre><code>public interface UserMapper &#123;
    List&lt;User&gt; getUsersByCriteria(@Param(&quot;criteria&quot;) UserCriteria criteria);
&#125;

&lt;select id=&quot;getUsersByCriteria&quot; resultType=&quot;User&quot;&gt;
    SELECT * FROM users
    WHERE age = #&#123;criteria.age&#125;
    AND gender = #&#123;criteria.gender&#125;
&lt;/select&gt;
</code></pre>
</li>
</ul>
</li>
</ol>
<h2 id="2-6-resultType注意事项"><a href="#2-6-resultType注意事项" class="headerlink" title="2.6 resultType注意事项"></a>2.6 resultType注意事项</h2><h3 id="2-6-1-常用规范"><a href="#2-6-1-常用规范" class="headerlink" title="2.6.1 常用规范"></a>2.6.1 常用规范</h3><p>在resultType&#x3D;”Person”中，person类型别名不区分大小写</p>
<p>它的值可以是实体类，集合，Map(单实体)</p>
<p>List&lt;Map&lt;String,Object&gt;&gt;接收多个实体为Map集合</p>
<p>@MapKey(“id”) + Map&lt;String,Object&gt; 查多条，key为id</p>
<p><strong>Mybatis的Java常用类型别名</strong></p>
<ul>
<li>java.lang.Integer –&gt; int | integer</li>
<li>int –&gt; _int | _integer</li>
<li>Map –&gt; map , List –&gt; list</li>
</ul>
<h3 id="2-6-2-查多条map集合"><a href="#2-6-2-查多条map集合" class="headerlink" title="2.6.2 查多条map集合"></a>2.6.2 查多条map集合</h3><p>方式一：</p>
<pre><code class="java">/**
* 查询所有用户信息为map集合
* @return
* 将表中的数据以map集合的方式查询，一条数据对应一个map；若有多条数据，就会产生多个map集合，此时可以将这些map放在一个list集合中获取
*/
List&lt;Map&lt;String, Object&gt;&gt; getAllUserToMap();
</code></pre>
<pre><code class="xml">&lt;!--Map&lt;String, Object&gt; getAllUserToMap();--&gt;
&lt;select id=&quot;getAllUserToMap&quot; resultType=&quot;map&quot;&gt;
    select * from t_user
&lt;/select&gt;
</code></pre>
<p>方式二【返回值无法转换，直接输出map查看即可】：</p>
<pre><code class="java">/**
* 查询所有用户信息为map集合
* @return
* 将表中的数据以map集合的方式查询，一条数据对应一个map；若有多条数据，就会产生多个map集合，并
且最终要以一个map的方式返回数据，此时需要通过@MapKey注解设置map集合的键，值是每条数据所对应的
map集合
*/
@MapKey(&quot;id&quot;)
Map&lt;String, Object&gt; getAllUserToMap();
</code></pre>
<pre><code class="xml">&lt;!--Map&lt;String, Object&gt; getAllUserToMap();--&gt;
&lt;select id=&quot;getAllUserToMap&quot; resultType=&quot;map&quot;&gt;
select * from t_user
&lt;/select&gt;
结果：
&lt;!--
&#123;
1=&#123;password=123456, sex=男, id=1, age=23, username=admin&#125;,
2=&#123;password=123456, sex=男, id=2, age=23, username=张三&#125;,
3=&#123;password=123456, sex=男, id=3, age=23, username=张三&#125;
&#125;
--&gt;
</code></pre>
<h2 id="2-7-特殊SQL"><a href="#2-7-特殊SQL" class="headerlink" title="2.7 特殊SQL"></a>2.7 特殊SQL</h2><p><strong>模糊查询</strong></p>
<ul>
<li>like ‘%#{param}%’ &#x2F;&#x2F; 错误使用</li>
<li>like ‘%${param}%’</li>
<li>like concat(‘%’,#{param},’%’)</li>
<li>like “%”#{param}”%” &#x2F;&#x2F; 建议使用</li>
</ul>
<p><strong>批量删除</strong></p>
<ul>
<li><code>delete from table in ($&#123;ids&#125;)</code> &#x2F;&#x2F; ids &#x3D; ‘1,2,3’ ,类型是string，这样传递过来的数据没有单引号包围</li>
</ul>
<p><strong>动态表名</strong></p>
<ul>
<li><p>@Param(“tableName”)</p>
</li>
<li><p>写在类上，替换表名，动态设置表名，使用${tableName}，不能使用#{}</p>
</li>
</ul>
<p><strong>获取添加功能自增的主键</strong></p>
<ul>
<li>mapper.xml中useGeneratedKeys&#x3D;’true’ keyProperty&#x3D;’id’</li>
<li>其中useGeneratedKeys为开启主键自增，keyProperty将自增主键的值传递到映射文件中的某个属性(这里指定id属性)</li>
<li>例：传递User(id:null,…) 数据进行添加操作后，User对象的id为自增主键值</li>
</ul>
<h2 id="2-8-自定义映射resultMap"><a href="#2-8-自定义映射resultMap" class="headerlink" title="2.8 自定义映射resultMap"></a>2.8 自定义映射resultMap</h2><p>用于处理字段名和属性名不一致问题</p>
<p>例：emp_name	empName</p>
<p>不一一对应会导致赋值失败，null</p>
<ol>
<li><p>字段名起别名：emp_name as empName</p>
</li>
<li><p>全局配置 config.xml</p>
<pre><code class="xml">&lt;settings&gt;
      &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot;&gt;
&lt;/settings&gt;
</code></pre>
</li>
<li><p>resultMap 自定义映射关系(处理多对一，一对一)</p>
<pre><code class="xml">&lt;resultMap id=&#39;xxxResultMap&#39; type=&#39;pojo&#39;&gt;
      &lt;id property=&#39;id&#39; column=&#39;eid&#39; /&gt;
      &lt;result property=&#39;name&#39; column=&#39;fname&#39; /&gt;
  ...
  &lt;!--都需要进行设置，property是属性名，column是字段名--&gt;
&lt;/resultMap&gt;
&lt;!--使用--&gt;
&lt;select id=&#39;methodName&#39; resultMap=&#39;xxxResultMap&#39;&gt;
    ....
&lt;/select&gt;
</code></pre>
</li>
</ol>
<h3 id="2-8-1-resultMap处理字段和属性的映射关系"><a href="#2-8-1-resultMap处理字段和属性的映射关系" class="headerlink" title="2.8.1 resultMap处理字段和属性的映射关系"></a>2.8.1 resultMap处理字段和属性的映射关系</h3><p>若字段名和实体类中的属性名不一致，则可以通过resultMap设置自定义映射</p>
<pre><code class="xml">    &lt;!--
    resultMap：设置自定义映射
    属性：
        id：表示自定义映射的唯一标识
        type：查询的数据要映射的实体类的类型
    子标签：
        id：设置主键的映射关系
        result：设置普通字段的映射关系
        association：设置多对一的映射关系
        collection：设置一对多的映射关系
    属性：
        property：设置映射关系中实体类中的属性名
        column：设置映射关系中表中的字段名
    --&gt;
    &lt;resultMap id=&quot;userMap&quot; type=&quot;User&quot;&gt;
        &lt;id property=&quot;id&quot; column=&quot;id&quot;&gt;&lt;/id&gt;
        &lt;result property=&quot;userName&quot; column=&quot;user_name&quot;&gt;&lt;/result&gt;
        &lt;result property=&quot;password&quot; column=&quot;password&quot;&gt;&lt;/result&gt;
        &lt;result property=&quot;age&quot; column=&quot;age&quot;&gt;&lt;/result&gt;
        &lt;result property=&quot;sex&quot; column=&quot;sex&quot;&gt;&lt;/result&gt;
    &lt;/resultMap&gt;
    &lt;!--List&lt;User&gt; testMohu(@Param(&quot;mohu&quot;) String mohu);--&gt;
    &lt;select id=&quot;testMohu&quot; resultMap=&quot;userMap&quot;&gt;
        &lt;!--select * from t_user where username like &#39;%$&#123;mohu&#125;%&#39;--&gt;
        select id,user_name,password,age,sex from t_user where user_name like
        concat(&#39;%&#39;,#&#123;mohu&#125;,&#39;%&#39;)
    &lt;/select&gt;
</code></pre>
<h3 id="2-8-2-多对一映射处理"><a href="#2-8-2-多对一映射处理" class="headerlink" title="2.8.2 多对一映射处理"></a>2.8.2 多对一映射处理</h3><p>例：查询员工信息以及员工所对应的部门信息</p>
<h4 id="①-级联方式处理映射关系"><a href="#①-级联方式处理映射关系" class="headerlink" title="① 级联方式处理映射关系"></a>① 级联方式处理映射关系</h4><ul>
<li>property&#x3D;”dept.dname”的方式嵌套类，低级</li>
</ul>
<pre><code class="xml">    &lt;resultMap id=&quot;empDeptMap&quot; type=&quot;Emp&quot;&gt;
        &lt;id column=&quot;eid&quot; property=&quot;eid&quot;&gt;&lt;/id&gt;
        &lt;result column=&quot;ename&quot; property=&quot;ename&quot;&gt;&lt;/result&gt;
        &lt;result column=&quot;age&quot; property=&quot;age&quot;&gt;&lt;/result&gt;
        &lt;result column=&quot;sex&quot; property=&quot;sex&quot;&gt;&lt;/result&gt;
        &lt;result column=&quot;did&quot; property=&quot;dept.did&quot;&gt;&lt;/result&gt;
        &lt;result column=&quot;dname&quot; property=&quot;dept.dname&quot;&gt;&lt;/result&gt;
    &lt;/resultMap&gt;
    &lt;!--Emp getEmpAndDeptByEid(@Param(&quot;eid&quot;) int eid);--&gt;
    &lt;select id=&quot;getEmpAndDeptByEid&quot; resultMap=&quot;empDeptMap&quot;&gt;
        select emp.*,dept.* from t_emp emp left join t_dept dept on emp.did =
        dept.did where emp.eid = #&#123;eid&#125;
    &lt;/select&gt;
</code></pre>
<h4 id="②-使用association处理映射关系"><a href="#②-使用association处理映射关系" class="headerlink" title="② 使用association处理映射关系"></a>② 使用association处理映射关系</h4><ul>
<li>通过association子标签设置</li>
</ul>
<pre><code class="xml">    &lt;resultMap id=&quot;empDeptMap&quot; type=&quot;Emp&quot;&gt;
        &lt;id column=&quot;eid&quot; property=&quot;eid&quot;&gt;&lt;/id&gt;
        &lt;result column=&quot;ename&quot; property=&quot;ename&quot;&gt;&lt;/result&gt;
        &lt;result column=&quot;age&quot; property=&quot;age&quot;&gt;&lt;/result&gt;
        &lt;result column=&quot;sex&quot; property=&quot;sex&quot;&gt;&lt;/result&gt;
        &lt;association property=&quot;dept&quot; javaType=&quot;Dept&quot;&gt;
            &lt;id column=&quot;did&quot; property=&quot;did&quot;&gt;&lt;/id&gt;
            &lt;result column=&quot;dname&quot; property=&quot;dname&quot;&gt;&lt;/result&gt;
        &lt;/association&gt;
    &lt;/resultMap&gt;
    &lt;!--Emp getEmpAndDeptByEid(@Param(&quot;eid&quot;) int eid);--&gt;
    &lt;select id=&quot;getEmpAndDeptByEid&quot; resultMap=&quot;empDeptMap&quot;&gt;
        select emp.*,dept.* from t_emp emp left join t_dept dept on emp.did =
        dept.did where emp.eid = #&#123;eid&#125;
    &lt;/select&gt;
</code></pre>
<h4 id="③-分布查询"><a href="#③-分布查询" class="headerlink" title="③ 分布查询"></a>③ 分布查询</h4><ol>
<li>先根据id查员工信息</li>
<li>再根据员工信息的部门id查部门信息</li>
</ol>
<h3 id="2-8-3-一对多映射处理"><a href="#2-8-3-一对多映射处理" class="headerlink" title="2.8.3 一对多映射处理"></a>2.8.3 一对多映射处理</h3><p>例：根据部门id查新部门以及部门中的员工信息</p>
<h4 id="①-collection"><a href="#①-collection" class="headerlink" title="① collection"></a>① collection</h4><pre><code class="xml">&lt;!--Dept getDeptEmpByDid(@Param(&quot;did&quot;) int did);--&gt;

    &lt;resultMap id=&quot;deptEmpMap&quot; type=&quot;Dept&quot;&gt;
        &lt;id property=&quot;did&quot; column=&quot;did&quot;&gt;&lt;/id&gt;
        &lt;result property=&quot;dname&quot; column=&quot;dname&quot;&gt;&lt;/result&gt;
        &lt;!--
        ofType：设置collection标签所处理的集合属性中存储数据的类型
        --&gt;
        &lt;collection property=&quot;emps&quot; ofType=&quot;Emp&quot;&gt;
            &lt;id property=&quot;eid&quot; column=&quot;eid&quot;&gt;&lt;/id&gt;
            &lt;result property=&quot;ename&quot; column=&quot;ename&quot;&gt;&lt;/result&gt;
            &lt;result property=&quot;age&quot; column=&quot;age&quot;&gt;&lt;/result&gt;
            &lt;result property=&quot;sex&quot; column=&quot;sex&quot;&gt;&lt;/result&gt;
        &lt;/collection&gt;
    &lt;/resultMap&gt;
    &lt;!--Dept getDeptEmpByDid(@Param(&quot;did&quot;) int did);--&gt;
    &lt;select id=&quot;getDeptEmpByDid&quot; resultMap=&quot;deptEmpMap&quot;&gt;
        select dept.*,emp.* from t_dept dept left join t_emp emp on dept.did =
        emp.did where dept.did = #&#123;did&#125;
    &lt;/select&gt;
</code></pre>
<h4 id="②-分布查询"><a href="#②-分布查询" class="headerlink" title="② 分布查询"></a>② 分布查询</h4><ol>
<li>查询部门信息</li>
<li>根据部门id查询部门中的所有员工</li>
</ol>
<ul>
<li>分步查询的优点：可以实现延迟加载，但是必须在核心配置文件中设置全局配置信息</li>
<li>lazyLoadingEnabled：延迟加载的全局开关。当开启时，所有关联对象都会延迟加载</li>
<li>aggressiveLazyLoading：当开启时，任何方法的调用都会加载该对象的所有属性。 否则，每个属性会按需加载</li>
<li>此时就可以实现按需加载，获取的数据是什么，就只会执行相应的sql。此时可通过association和 collection中的fetchType属性设置当前的分步查询是否使用延迟加载，fetchType&#x3D;”lazy(延迟加 载)|eager(立即加载)”</li>
</ul>
<h1 id="三、核心配置详解"><a href="#三、核心配置详解" class="headerlink" title="三、核心配置详解"></a>三、核心配置详解</h1><p>核心配置文件中的标签必须按照固定的顺序： </p>
<ul>
<li>properties</li>
<li>settings</li>
<li>typeAliases</li>
<li>typeHandlers</li>
<li>objectFactory</li>
<li>objectWrapperFactory</li>
<li>reflectorFactory</li>
<li>plugins</li>
<li>environments</li>
<li>databaseIdProvider</li>
<li>mappers</li>
</ul>
<pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE configuration
        PUBLIC &quot;-//MyBatis.org//DTD Config 3.0//EN&quot;
        &quot;http://MyBatis.org/dtd/MyBatis-3-config.dtd&quot;&gt;
&lt;configuration&gt;
    &lt;!--引入properties文件，此时就可以$&#123;属性名&#125;的方式访问属性值--&gt;
    &lt;properties resource=&quot;jdbc.properties&quot;&gt;&lt;/properties&gt;
    &lt;settings&gt;
        &lt;!--将表中字段的下划线自动转换为驼峰--&gt;
        &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot;/&gt;
        &lt;!--开启延迟加载--&gt;
        &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt;
    &lt;/settings&gt;
    &lt;typeAliases&gt;
        &lt;!--
        typeAlias：设置某个具体的类型的别名
        属性：
        type：需要设置别名的类型的全类名
        alias：设置此类型的别名，若不设置此属性，该类型拥有默认的别名，即类名且不区分大小
        写
        若设置此属性，此时该类型的别名只能使用alias所设置的值
        --&gt;
        &lt;!--&lt;typeAlias type=&quot;com.atguigu.mybatis.bean.User&quot;&gt;&lt;/typeAlias&gt;--&gt;
        &lt;!--&lt;typeAlias type=&quot;com.atguigu.mybatis.bean.User&quot; alias=&quot;abc&quot;&gt;
        &lt;/typeAlias&gt;--&gt;
        &lt;!--以包为单位，设置改包下所有的类型都拥有默认的别名，即类名且不区分大小写--&gt;
        &lt;package name=&quot;com.atguigu.mybatis.bean&quot;/&gt;
    &lt;/typeAliases&gt;
    &lt;!--
    environments：设置多个连接数据库的环境
    属性：
    default：设置默认使用的环境的id
    --&gt;
    &lt;environments default=&quot;mysql_test&quot;&gt;
        &lt;!--
        environment：设置具体的连接数据库的环境信息
        属性：
        id：设置环境的唯一标识，可通过environments标签中的default设置某一个环境的id，
        表示默认使用的环境
        --&gt;
        &lt;environment id=&quot;mysql_test&quot;&gt;
            &lt;!--
            transactionManager：设置事务管理方式
            属性：
                type：设置事务管理方式，type=&quot;JDBC|MANAGED&quot;
                type=&quot;JDBC&quot;：设置当前环境的事务管理都必须手动处理
                type=&quot;MANAGED&quot;：设置事务被管理，例如spring中的AOP
            --&gt;
            &lt;transactionManager type=&quot;JDBC&quot;/&gt;
            &lt;!--
            dataSource：设置数据源
            属性：
                type：设置数据源的类型，type=&quot;POOLED|UNPOOLED|JNDI&quot;
                type=&quot;POOLED&quot;：使用数据库连接池，即会将创建的连接进行缓存，下次使用可以从
                缓存中直接获取，不需要重新创建
                type=&quot;UNPOOLED&quot;：不使用数据库连接池，即每次使用连接都需要重新创建
                type=&quot;JNDI&quot;：调用上下文中的数据源
            --&gt;
            &lt;dataSource type=&quot;POOLED&quot;&gt;
                &lt;!--设置驱动类的全类名--&gt;
                &lt;property name=&quot;driver&quot; value=&quot;$&#123;jdbc.driver&#125;&quot;/&gt;
                &lt;!--设置连接数据库的连接地址--&gt;
                &lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url&#125;&quot;/&gt;
                &lt;!--设置连接数据库的用户名--&gt;
                &lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username&#125;&quot;/&gt;
                &lt;!--设置连接数据库的密码--&gt;
                &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot;/&gt;
            &lt;/dataSource&gt;
        &lt;/environment&gt;
    &lt;/environments&gt;
    &lt;!--引入映射文件--&gt;
    &lt;mappers&gt;
        &lt;mapper resource=&quot;UserMapper.xml&quot;/&gt;
        &lt;!--
        以包为单位，将包下所有的映射文件引入核心配置文件
        注意：此方式必须保证mapper接口和mapper映射文件必须在相同的包下
        --&gt;
        &lt;package name=&quot;com.atguigu.mybatis.mapper&quot;/&gt;
    &lt;/mappers&gt;
&lt;/configuration&gt;
</code></pre>
<h1 id="四、动态SQL"><a href="#四、动态SQL" class="headerlink" title="四、动态SQL"></a>四、动态SQL</h1><p>Mybatis框架的动态SQL技术是一种根据特定条件动态拼装SQL语句的功能，它存在的意义是为了解决 拼接SQL语句字符串时的痛点问题。</p>
<h2 id="4-1-if"><a href="#4-1-if" class="headerlink" title="4.1 if"></a>4.1 if</h2><p>if标签可通过test属性的表达式进行判断，若表达式的结果为true，则标签中的内容会执行；反之标签中的内容不会执行</p>
<pre><code class="xml">    &lt;!--List&lt;Emp&gt; getEmpListByMoreTJ(Emp emp);--&gt;
    &lt;select id=&quot;getEmpListByMoreTJ&quot; resultType=&quot;Emp&quot;&gt;
        select * from t_emp where 1=1
        &lt;if test=&quot;ename != &#39;&#39; and ename != null&quot;&gt;
            and ename = #&#123;ename&#125;
        &lt;/if&gt;
        &lt;if test=&quot;age != &#39;&#39; and age != null&quot;&gt;
            and age = #&#123;age&#125;
        &lt;/if&gt;
        &lt;if test=&quot;sex != &#39;&#39; and sex != null&quot;&gt;
            and sex = #&#123;sex&#125;
        &lt;/if&gt;
    &lt;/select&gt;
</code></pre>
<h2 id="4-2-where"><a href="#4-2-where" class="headerlink" title="4.2 where"></a>4.2 where</h2><pre><code class="xml">    &lt;select id=&quot;getEmpListByMoreTJ2&quot; resultType=&quot;Emp&quot;&gt;
        select * from t_emp
        &lt;where&gt;
            &lt;if test=&quot;ename != &#39;&#39; and ename != null&quot;&gt;
                ename = #&#123;ename&#125;
            &lt;/if&gt;
            &lt;if test=&quot;age != &#39;&#39; and age != null&quot;&gt;
                and age = #&#123;age&#125;
            &lt;/if&gt;
            &lt;if test=&quot;sex != &#39;&#39; and sex != null&quot;&gt;
                and sex = #&#123;sex&#125;
            &lt;/if&gt;
        &lt;/where&gt;
    &lt;/select&gt;
</code></pre>
<p>where和if一般结合使用：</p>
<ul>
<li>若where标签中的if条件都不满足，则where标签没有任何功能，即不会添加where关键字</li>
<li>若where标签中的if条件满足，则where标签会自动添加where关键字，并将条件<strong>最前方多余的and去掉</strong></li>
<li>注意：where标签<strong>不能去掉</strong>条件<strong>最后多余的and</strong></li>
</ul>
<h2 id="4-3-trim"><a href="#4-3-trim" class="headerlink" title="4.3 trim"></a>4.3 trim</h2><pre><code class="xml">    &lt;select id=&quot;getEmpListByMoreTJ&quot; resultType=&quot;Emp&quot;&gt;
        select * from t_emp
        &lt;trim prefix=&quot;where&quot; suffixOverrides=&quot;and&quot;&gt;
            &lt;if test=&quot;ename != &#39;&#39; and ename != null&quot;&gt;
                ename = #&#123;ename&#125; and
            &lt;/if&gt;
            &lt;if test=&quot;age != &#39;&#39; and age != null&quot;&gt;
                age = #&#123;age&#125; and
            &lt;/if&gt;
            &lt;if test=&quot;sex != &#39;&#39; and sex != null&quot;&gt;
                sex = #&#123;sex&#125;
            &lt;/if&gt;
        &lt;/trim&gt;
    &lt;/select&gt;
</code></pre>
<p>trim用于去掉或添加标签中的内容，常用属性：</p>
<ul>
<li>prefix：在trim标签中的内容的前面添加某些内容</li>
<li>prefixOverrides：在trim标签中的内容的前面去掉某些内容</li>
<li>suffix：在trim标签中的内容的后面添加某些内容</li>
<li>suffixOverrides：在trim标签中的内容的后面去掉某些内容</li>
</ul>
<h2 id="4-4-choose、when、otherwise"><a href="#4-4-choose、when、otherwise" class="headerlink" title="4.4 choose、when、otherwise"></a>4.4 choose、when、otherwise</h2><p>多条件<strong>选其一</strong></p>
<p>choose、when、otherwise相当于<strong>if…else if..else</strong></p>
<pre><code class="xml">    &lt;!--List&lt;Emp&gt; getEmpListByChoose(Emp emp);--&gt;
    &lt;select id=&quot;getEmpListByChoose&quot; resultType=&quot;Emp&quot;&gt;
        select &lt;include refid=&quot;empColumns&quot;&gt;&lt;/include&gt; from t_emp
        &lt;where&gt;
            &lt;choose&gt;
                &lt;when test=&quot;ename != &#39;&#39; and ename != null&quot;&gt;
                    ename = #&#123;ename&#125;
                &lt;/when&gt;
                &lt;when test=&quot;age != &#39;&#39; and age != null&quot;&gt;
                    age = #&#123;age&#125;
                &lt;/when&gt;
                &lt;when test=&quot;sex != &#39;&#39; and sex != null&quot;&gt;
                    sex = #&#123;sex&#125;
                &lt;/when&gt;
                &lt;when test=&quot;email != &#39;&#39; and email != null&quot;&gt;
                    email = #&#123;email&#125;
                &lt;/when&gt;
            &lt;/choose&gt;
        &lt;/where&gt;
    &lt;/select&gt;
</code></pre>
<h2 id="4-5-foreach"><a href="#4-5-foreach" class="headerlink" title="4.5 foreach"></a>4.5 foreach</h2><pre><code class="xml">    &lt;!--int insertMoreEmp(List&lt;Emp&gt; emps);--&gt;
    &lt;insert id=&quot;insertMoreEmp&quot;&gt;
        insert into t_emp values
        &lt;foreach collection=&quot;emps&quot; item=&quot;emp&quot; separator=&quot;,&quot;&gt;
            (null,#&#123;emp.ename&#125;,#&#123;emp.age&#125;,#&#123;emp.sex&#125;,#&#123;emp.email&#125;,null)
        &lt;/foreach&gt;
    &lt;/insert&gt;

    &lt;!--int deleteMoreByArray(int[] eids);--&gt;
    &lt;delete id=&quot;deleteMoreByArray&quot;&gt;
        delete from t_emp where
        &lt;foreach collection=&quot;eids&quot; item=&quot;eid&quot; separator=&quot;or&quot;&gt;
            eid = #&#123;eid&#125;
        &lt;/foreach&gt;
    &lt;/delete&gt;

    &lt;!--int deleteMoreByArray(int[] eids);--&gt;
    &lt;delete id=&quot;deleteMoreByArray&quot;&gt;
        delete from t_emp where eid in
        &lt;foreach collection=&quot;eids&quot; item=&quot;eid&quot; separator=&quot;,&quot; open=&quot;(&quot; close=&quot;)&quot;&gt;
            #&#123;eid&#125;
        &lt;/foreach&gt;
    &lt;/delete&gt;
</code></pre>
<p>属性：</p>
<ul>
<li>collection：设置要循环的数组或集合</li>
<li>item：表示集合或数组中的每一个数据</li>
<li>separator：设置循环体之间的分隔符</li>
<li>open：设置foreach标签中的内容的开始符</li>
<li>close：设置foreach标签中的内容的结束符</li>
</ul>
<h2 id="4-6-SQL片段"><a href="#4-6-SQL片段" class="headerlink" title="4.6 SQL片段"></a>4.6 SQL片段</h2><p>sql片段，可以记录一段公共sql片段，在使用的地方通过include标签进行引入</p>
<pre><code class="xml">    &lt;sql id=&quot;empColumns&quot;&gt;
        eid,ename,age,sex,did
    &lt;/sql&gt;
    &lt;select id=&quot;getAllData&quot;&gt;
        select &lt;include refid=&quot;empColumns&quot;&gt;&lt;/include&gt; from t_emp
    &lt;/select&gt;
</code></pre>
<h1 id="五、MyBatis的缓存"><a href="#五、MyBatis的缓存" class="headerlink" title="五、MyBatis的缓存"></a>五、MyBatis的缓存</h1><h2 id="5-1-MyBatis的一级缓存"><a href="#5-1-MyBatis的一级缓存" class="headerlink" title="5.1 MyBatis的一级缓存"></a>5.1 MyBatis的一级缓存</h2><p>一级缓存是<strong>SqlSession级别</strong>的，通过同一个SqlSession查询的数据会被缓存，下次查询相同的数据，就会从缓存中直接获取，不会从数据库重新访问</p>
<p>使一级缓存失效的四种情况：</p>
<ol>
<li>不同的SqlSession对应不同的一级缓存</li>
<li>同一个SqlSession但是查询条件不同</li>
<li>同一个SqlSession两次查询期间执行了任何一次增删改操作</li>
<li>同一个SqlSession两次查询期间手动清空了缓存</li>
</ol>
<h2 id="5-2-MyBatis的二级缓存"><a href="#5-2-MyBatis的二级缓存" class="headerlink" title="5.2 MyBatis的二级缓存"></a>5.2 MyBatis的二级缓存</h2><p>二级缓存是<strong>SqlSessionFactory级别</strong>，通过同一个SqlSessionFactory创建的SqlSession查询的结果会被缓存；此后若再次执行相同的查询语句，结果就会从缓存中获取</p>
<p>二级缓存<strong>开启</strong>的条件：</p>
<ol>
<li>在核心配置文件中，设置全局配置属性cacheEnabled&#x3D;”true”，默认为true，不需要设置</li>
<li>在映射文件中设置标签</li>
<li>二级缓存必须在SqlSession关闭或提交之后有效</li>
<li>查询的数据所转换的实体类类型必须实现序列化的接口</li>
</ol>
<p>使二级缓存<strong>失效</strong>的情况：</p>
<ul>
<li>两次查询之间执行了任意的增删改，会使一级和二级缓存同时失效</li>
</ul>
<h2 id="5-3-二级缓存的相关配置"><a href="#5-3-二级缓存的相关配置" class="headerlink" title="5.3 二级缓存的相关配置"></a>5.3 二级缓存的相关配置</h2><p>在mapper配置文件中添加的cache标签可以设置一些属性：</p>
<ul>
<li>eviction属性：缓存回收策略<ul>
<li>LRU（Least Recently Used） – 最近最少使用的：移除最长时间不被使用的对象。</li>
<li>FIFO（First in First out） – 先进先出：按对象进入缓存的顺序来移除它们。</li>
<li>SOFT – 软引用：移除基于垃圾回收器状态和软引用规则的对象</li>
<li>WEAK – 弱引用：更积极地移除基于垃圾收集器状态和弱引用规则的对象。</li>
<li>默认的是 LRU</li>
</ul>
</li>
<li>flushInterval属性：刷新间隔，单位毫秒<ul>
<li>默认情况是不设置，也就是没有刷新间隔，缓存仅仅调用语句时刷新</li>
</ul>
</li>
<li>size属性：引用数目，正整数<ul>
<li>代表缓存最多可以存储多少个对象，太大容易导致内存溢出</li>
</ul>
</li>
<li>readOnly属性：只读，true&#x2F;false<ul>
<li>true：只读缓存；会给所有调用者返回缓存对象的相同实例。因此这些对象不能被修改。这提供了很重要的性能优势。</li>
<li>false：读写缓存；会返回缓存对象的拷贝（通过序列化）。这会慢一些，但是安全，因此默认是false</li>
</ul>
</li>
</ul>
<h2 id="5-4-MyBatis缓存查询的顺序"><a href="#5-4-MyBatis缓存查询的顺序" class="headerlink" title="5.4 MyBatis缓存查询的顺序"></a>5.4 MyBatis缓存查询的顺序</h2><ul>
<li>先查询二级缓存，因为二级缓存中可能会有其他程序已经查出来的数据，可以拿来直接使用。</li>
<li>如果二级缓存没有命中，再查询一级缓存</li>
<li>如果一级缓存也没有命中，则查询数据库</li>
<li>SqlSession关闭之后，一级缓存中的数据会写入二级缓存</li>
</ul>
<h2 id="5-5-整合第三方缓存EHCache"><a href="#5-5-整合第三方缓存EHCache" class="headerlink" title="5.5 整合第三方缓存EHCache"></a>5.5 整合第三方缓存EHCache</h2><h3 id="5-5-1-添加依赖"><a href="#5-5-1-添加依赖" class="headerlink" title="5.5.1 添加依赖"></a>5.5.1 添加依赖</h3><pre><code class="xml">        &lt;!-- Mybatis EHCache整合包 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis.caches&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-ehcache&lt;/artifactId&gt;
            &lt;version&gt;1.2.1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;!-- slf4j日志门面的一个具体实现 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;
            &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;
            &lt;version&gt;1.2.3&lt;/version&gt;
        &lt;/dependency&gt;
</code></pre>
<h3 id="5-5-2-各jar包功能"><a href="#5-5-2-各jar包功能" class="headerlink" title="5.5.2 各jar包功能"></a>5.5.2 各jar包功能</h3><table>
<thead>
<tr>
<th>jar包名称</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>mybatis-ehcache</td>
<td>Mybatis和EHCache的整合包</td>
</tr>
<tr>
<td>ehcache</td>
<td>EHCache核心包</td>
</tr>
<tr>
<td>slf4j-api</td>
<td>SLF4J日志门面包</td>
</tr>
<tr>
<td>logback-classic</td>
<td>支持SLF4J门面接口的一个具体实现</td>
</tr>
</tbody></table>
<h3 id="5-5-3-创建EHCache的配置文件ehcache-xml"><a href="#5-5-3-创建EHCache的配置文件ehcache-xml" class="headerlink" title="5.5.3 创建EHCache的配置文件ehcache.xml"></a>5.5.3 创建EHCache的配置文件ehcache.xml</h3><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&gt;
&lt;ehcache xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:noNamespaceSchemaLocation=&quot;../config/ehcache.xsd&quot;&gt;
&lt;!-- 磁盘保存路径 --&gt;
&lt;diskStore path=&quot;D:\atguigu\ehcache&quot;/&gt;
&lt;defaultCache
        maxElementsInMemory=&quot;1000&quot;
        maxElementsOnDisk=&quot;10000000&quot;
        eternal=&quot;false&quot;
        overflowToDisk=&quot;true&quot;
        timeToIdleSeconds=&quot;120&quot;
        timeToLiveSeconds=&quot;120&quot;
        diskExpiryThreadIntervalSeconds=&quot;120&quot;
        memoryStoreEvictionPolicy=&quot;LRU&quot;&gt;
&lt;/defaultCache&gt;
&lt;/ehcache&gt;
</code></pre>
<h3 id="5-5-4-设置二级缓存的类型"><a href="#5-5-4-设置二级缓存的类型" class="headerlink" title="5.5.4 设置二级缓存的类型"></a>5.5.4 设置二级缓存的类型</h3><pre><code class="xml">&lt;cache type=&quot;org.mybatis.caches.ehcache.EhcacheCache&quot;/&gt;
</code></pre>
<h3 id="5-5-5-加入logback日志"><a href="#5-5-5-加入logback日志" class="headerlink" title="5.5.5 加入logback日志"></a>5.5.5 加入logback日志</h3><p>存在SLF4J时，作为简易日志的log4j将失效，此时我们需要借助SLF4J的具体实现logback来打印日志。</p>
<p>创建logback的配置文件<strong>logback.xml</strong></p>
<pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;configuration debug=&quot;true&quot;&gt;
    &lt;!-- 指定日志输出的位置 --&gt;
    &lt;appender name=&quot;STDOUT&quot;
              class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;
        &lt;encoder&gt;
            &lt;!-- 日志输出的格式 --&gt;
            &lt;!-- 按照顺序分别是：时间、日志级别、线程名称、打印日志的类、日志主体内容、换行 --&gt;
            &lt;pattern&gt;[%d&#123;HH:mm:ss.SSS&#125;] [%-5level] [%thread] [%logger] [%msg]%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;
    &lt;!-- 设置全局日志级别。日志级别按顺序分别是：DEBUG、INFO、WARN、ERROR --&gt;
    &lt;!-- 指定任何一个日志级别都只打印当前级别和后面级别的日志。 --&gt;
    &lt;root level=&quot;DEBUG&quot;&gt;
        &lt;!-- 指定打印日志的appender，这里通过“STDOUT”引用了前面配置的appender --&gt;
        &lt;appender-ref ref=&quot;STDOUT&quot; /&gt;
    &lt;/root&gt;
    &lt;!-- 根据特殊需求指定局部日志级别 --&gt;
    &lt;logger name=&quot;com.bamboo.mapper&quot; level=&quot;DEBUG&quot;/&gt;
&lt;/configuration&gt;
</code></pre>
<h3 id="5-5-6-EHCache配置文件说明"><a href="#5-5-6-EHCache配置文件说明" class="headerlink" title="5.5.6 EHCache配置文件说明"></a>5.5.6 EHCache配置文件说明</h3><table>
<thead>
<tr>
<th>属性名</th>
<th>是否必须</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>maxElementsInMemory</td>
<td>是</td>
<td>在内存中缓存的element的最大数目</td>
</tr>
<tr>
<td>maxElementsOnDisk</td>
<td>是</td>
<td>在磁盘上缓存的element的最大数目，若是0表示无穷大</td>
</tr>
<tr>
<td>eternal</td>
<td>是</td>
<td>设定缓存的elements是否永远不过期。 如果为true，则缓存的数据始终有效，如果为false那么还要根据timeToIdleSeconds、timeToLiveSeconds判断</td>
</tr>
<tr>
<td>overflowToDisk</td>
<td>是</td>
<td>设定当内存缓存溢出的时候是否将过期的element缓存到磁盘上</td>
</tr>
<tr>
<td>timeToIdleSeconds</td>
<td>否</td>
<td>当缓存在EhCache中的数据前后两次访问的时间超过timeToIdleSeconds的属性取值时， 这些数据便会删除，默认值是0,也就是可闲置时间无穷大</td>
</tr>
<tr>
<td>timeToLiveSeconds</td>
<td>否</td>
<td>缓存element的有效生命期，默认是0,也就是element存活时间无穷大</td>
</tr>
<tr>
<td>diskSpoolBufferSizeMB</td>
<td>否</td>
<td>DiskStore(磁盘缓存)的缓存区大小。默认是30MB。每个Cache都应该有自己的一个缓冲区</td>
</tr>
<tr>
<td>diskPersistent</td>
<td>否</td>
<td>在VM重启的时候是否启用磁盘保存EhCache中的数据，默认是false。</td>
</tr>
<tr>
<td>diskExpiryThreadIntervalSeconds</td>
<td>否</td>
<td>磁盘缓存的清理线程运行间隔，默认是120秒。每个120s， 相应的线程会进行一次EhCache中数据的清理工作</td>
</tr>
<tr>
<td>memoryStoreEvictionPolicy</td>
<td>否</td>
<td>当内存缓存达到最大，有新的element加入的时候， 移除缓存中element的策略。 默认是LRU（最近最少使用），可选的有LFU（最不常使用）和FIFO（先进先出）</td>
</tr>
</tbody></table>
<h1 id="六、MyBatis的逆向工程"><a href="#六、MyBatis的逆向工程" class="headerlink" title="六、MyBatis的逆向工程"></a>六、MyBatis的逆向工程</h1><ul>
<li>正向工程：先创建Java实体类，由框架负责根据实体类生成数据库表。Hibernate是支持正向工程的。</li>
<li>逆向工程：先创建数据库表，由框架负责根据数据库表，反向生成如下资源：<ul>
<li>Java实体类</li>
<li>Mapper接口</li>
<li>Mapper映射文件</li>
</ul>
</li>
</ul>
<h2 id="6-1-创建逆向工程的步骤"><a href="#6-1-创建逆向工程的步骤" class="headerlink" title="6.1 创建逆向工程的步骤"></a>6.1 创建逆向工程的步骤</h2><h3 id="6-1-1-添加依赖和插件"><a href="#6-1-1-添加依赖和插件" class="headerlink" title="6.1.1 添加依赖和插件"></a>6.1.1 添加依赖和插件</h3><pre><code class="xml">    &lt;dependencies&gt;
        &lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis --&gt;
        &lt;!-- 依赖MyBatis核心包 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis&lt;/artifactId&gt;
            &lt;version&gt;3.5.13&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;!-- 控制Maven在构建过程中相关配置 --&gt;
    &lt;build&gt;
        &lt;!-- 构建过程中用到的插件 --&gt;
        &lt;plugins&gt;
            &lt;!-- 具体插件，逆向工程的操作是以构建过程中插件形式出现的 --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;
                &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;1.4.0&lt;/version&gt;
                &lt;!-- 插件的依赖 --&gt;
                &lt;dependencies&gt;
                    &lt;!-- 逆向工程的核心依赖 --&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;
                        &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt;
                        &lt;version&gt;1.4.0&lt;/version&gt;
                    &lt;/dependency&gt;
                    &lt;!-- 数据库连接池 --&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;com.mchange&lt;/groupId&gt;
                        &lt;artifactId&gt;c3p0&lt;/artifactId&gt;
                        &lt;version&gt;0.9.5.5&lt;/version&gt;
                    &lt;/dependency&gt;
                    &lt;!-- MySQL驱动 --&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;mysql&lt;/groupId&gt;
                        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
                        &lt;version&gt;5.1.49&lt;/version&gt;
                    &lt;/dependency&gt;
                &lt;/dependencies&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
</code></pre>
<h3 id="6-1-2-创建MyBatis的核心配置文件"><a href="#6-1-2-创建MyBatis的核心配置文件" class="headerlink" title="6.1.2 创建MyBatis的核心配置文件"></a>6.1.2 创建MyBatis的核心配置文件</h3><h3 id="6-1-3-创建逆向工程的配置文件"><a href="#6-1-3-创建逆向工程的配置文件" class="headerlink" title="6.1.3 创建逆向工程的配置文件"></a>6.1.3 创建逆向工程的配置文件</h3><p>文件名必须是：<code>generatorConfig.xml</code></p>
<pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE generatorConfigurationPUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot;
        &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt;
&lt;generatorConfiguration&gt;
    &lt;!--
    targetRuntime: 执行生成的逆向工程的版本
    MyBatis3Simple: 生成基本的CRUD（清新简洁版）
    MyBatis3: 生成带条件的CRUD（奢华尊享版）
    --&gt;
    &lt;context id=&quot;DB2Tables&quot; targetRuntime=&quot;MyBatis3Simple&quot;&gt;
        &lt;!-- 数据库的连接信息 --&gt;
        &lt;jdbcConnection driverClass=&quot;com.mysql.jdbc.Driver&quot;
                        connectionURL=&quot;jdbc:mysql://localhost:3306/mybatis&quot;
                        userId=&quot;root&quot;
                        password=&quot;root&quot;&gt;
        &lt;/jdbcConnection&gt;
        &lt;!-- javaBean的生成策略--&gt;
        &lt;javaModelGenerator targetPackage=&quot;com.bamboo.mybatis.bean&quot;
                            targetProject=&quot;.\src\main\java&quot;&gt;
            &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt;
            &lt;property name=&quot;trimStrings&quot; value=&quot;true&quot;/&gt;
        &lt;/javaModelGenerator&gt;
        &lt;!-- SQL映射文件的生成策略 --&gt;
        &lt;sqlMapGenerator targetPackage=&quot;com.bamboo.mybatis.mapper&quot;
                         targetProject=&quot;.\src\main\resources&quot;&gt;
            &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt;
        &lt;/sqlMapGenerator&gt;
        &lt;!-- Mapper接口的生成策略 --&gt;
        &lt;javaClientGenerator type=&quot;XMLMAPPER&quot;
                             targetPackage=&quot;com.bamboo.mybatis.mapper&quot; targetProject=&quot;.\src\main\java&quot;&gt;
            &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt;
        &lt;/javaClientGenerator&gt;
        &lt;!-- 逆向分析的表 --&gt;
        &lt;!-- tableName设置为*号，可以对应所有表，此时不写domainObjectName --&gt;
        &lt;!-- domainObjectName属性指定生成出来的实体类的类名 --&gt;
        &lt;table tableName=&quot;t_emp&quot; domainObjectName=&quot;Emp&quot;/&gt;
        &lt;table tableName=&quot;t_dept&quot; domainObjectName=&quot;Dept&quot;/&gt;
    &lt;/context&gt;
&lt;/generatorConfiguration&gt;
</code></pre>
<h3 id="6-1-4-执行MBG插件的generate目标"><a href="#6-1-4-执行MBG插件的generate目标" class="headerlink" title="6.1.4 执行MBG插件的generate目标"></a>6.1.4 执行MBG插件的generate目标</h3><ul>
<li>Maven<ul>
<li>Plugins<ul>
<li>mybatis-generator</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="七、分页查询"><a href="#七、分页查询" class="headerlink" title="七、分页查询"></a>七、分页查询</h1><h2 id="7-1-分页插件使用步骤"><a href="#7-1-分页插件使用步骤" class="headerlink" title="7.1 分页插件使用步骤"></a>7.1 分页插件使用步骤</h2><h3 id="7-1-1-添加依赖"><a href="#7-1-1-添加依赖" class="headerlink" title="7.1.1 添加依赖"></a>7.1.1 添加依赖</h3><pre><code class="xml">&lt;!-- https://mvnrepository.com/artifact/com.github.pagehelper/pagehelper --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;
    &lt;artifactId&gt;pagehelper&lt;/artifactId&gt;
    &lt;version&gt;5.3.3&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<h3 id="7-1-2-配置分页插件"><a href="#7-1-2-配置分页插件" class="headerlink" title="7.1.2 配置分页插件"></a>7.1.2 配置分页插件</h3><p>在MyBatis的核心配置文件中配置插件</p>
<pre><code class="xml">&lt;plugins&gt;
    &lt;!--设置分页插件--&gt;
    &lt;plugin interceptor=&quot;com.github.pagehelper.PageInterceptor&quot;&gt;&lt;/plugin&gt;
&lt;/plugins&gt;
</code></pre>
<h2 id="7-2-分页插件的使用"><a href="#7-2-分页插件的使用" class="headerlink" title="7.2 分页插件的使用"></a>7.2 分页插件的使用</h2><h3 id="7-2-1-开启分页功能"><a href="#7-2-1-开启分页功能" class="headerlink" title="7.2.1 开启分页功能"></a>7.2.1 开启分页功能</h3><p>在查询功能之前使用<code>PageHelper.startPage(int pageNum, int pageSize)</code>开启分页功能</p>
<ul>
<li>pageNum：当前页的页码</li>
<li>pageSize：每页显示的条数</li>
</ul>
<pre><code class="java">PageHelper.startPage(3, 5);
</code></pre>
<p>即开即用，在调用Mapper前使用</p>
<h3 id="7-2-2-获取分页相关数据"><a href="#7-2-2-获取分页相关数据" class="headerlink" title="7.2.2 获取分页相关数据"></a>7.2.2 获取分页相关数据</h3><p>在查询获取list集合之后，使用<code>PageInfo pageInfo = new PageInfo&lt;&gt;(List list, intnavigatePages)</code>获取分页相关数据</p>
<ul>
<li>list：分页之后的数据</li>
<li>navigatePages：导航分页的页码数</li>
</ul>
<pre><code class="java">UserMapper mapper = sqlSession.getMapper(UserMapper.class);
// 开启分页，后续正常查询
PageHelper.startPage(3, 5);
Map&lt;Integer, User&gt; map = mapper.getAllUserToMap();
System.out.println(map);
</code></pre>
<p>PageHelper使用了ThreadLocal保存分页参数，分页参数和线程是绑定的。因此<strong>我们需要保证PageHelper 的startPage调用后紧跟 MyBatis 查询方法，这就是安全的</strong>。因为 PageHelper 在 finally 代码段中自动清除了 ThreadLocal 存储的对象。</p>
<h3 id="7-2-3-分页相关数据"><a href="#7-2-3-分页相关数据" class="headerlink" title="7.2.3 分页相关数据"></a>7.2.3 分页相关数据</h3><pre><code class="java">PageInfo&#123;
    pageNum=8, pageSize=4, size=2, startRow=29, endRow=30, total=30, pages=8,
    list=Page&#123;count=true, pageNum=8, pageSize=4, startRow=28, endRow=32, total=30,
    pages=8, reasonable=false, pageSizeZero=false&#125;,
    prePage=7, nextPage=0, isFirstPage=false, isLastPage=true, hasPreviousPage=true,
    hasNextPage=false, navigatePages=5, navigateFirstPage4, navigateLastPage8,
    navigatepageNums=[4, 5, 6, 7, 8]
&#125;
</code></pre>
<p>常用数据：</p>
<ul>
<li>pageNum：当前页的页码</li>
<li>pageSize：每页显示的条数</li>
<li>size：当前页显示的真实条数</li>
<li>total：总记录数</li>
<li>pages：总页数</li>
<li>prePage：上一页的页码</li>
<li>nextPage：下一页的页码</li>
<li>isFirstPage&#x2F;isLastPage：是否为第一页&#x2F;最后一页</li>
<li>hasPreviousPage&#x2F;hasNextPage：是否存在上一页&#x2F;下一页</li>
<li>navigatePages：导航分页的页码数</li>
<li>navigatepageNums：导航分页的页码，[1,2,3,4,5]</li>
</ul>

            
        </div>
    </div>
    <div class="post-tags">
        
        
        
    </div>
    <a href="/2023/08/30/mybatis/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/08/30/mybatis-plus/">
        <h2 class="post-title">mybatis-plus</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/8/30
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <p>[TOC]</p>
<h1 id="一、入门"><a href="#一、入门" class="headerlink" title="一、入门"></a>一、入门</h1><h2 id="1-1-添加依赖"><a href="#1-1-添加依赖" class="headerlink" title="1.1 添加依赖"></a>1.1 添加依赖</h2><pre><code class="xml">        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;com.mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/com.baomidou/mybatis-plus-boot-starter --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;3.5.3&lt;/version&gt;
        &lt;/dependency&gt;
</code></pre>
<h2 id="1-2-设置yml"><a href="#1-2-设置yml" class="headerlink" title="1.2 设置yml"></a>1.2 设置yml</h2><pre><code class="yml">server:
  port: 80
spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/mybatis_plus?characterEncoding=utf8&amp;useSSL=false
    username: root
    password: root
</code></pre>
<h2 id="1-3-添加mapper"><a href="#1-3-添加mapper" class="headerlink" title="1.3 添加mapper"></a>1.3 添加mapper</h2><pre><code class="java">public interface UserMapper extends BaseMapper&lt;User&gt; &#123;
&#125;
</code></pre>
<ul>
<li>此时默认无法生效</li>
<li>下列两种方法任取其一即可</li>
</ul>
<h3 id="1-3-1-生效方法一：-Mapper"><a href="#1-3-1-生效方法一：-Mapper" class="headerlink" title="1.3.1 生效方法一：@Mapper"></a>1.3.1 生效方法一：@Mapper</h3><pre><code class="java">@Mapper
//@Repository
public interface UserMapper extends BaseMapper&lt;User&gt; &#123;
&#125;
</code></pre>
<h3 id="1-3-2-生效方法二：-MapperScan"><a href="#1-3-2-生效方法二：-MapperScan" class="headerlink" title="1.3.2 生效方法二：@MapperScan"></a>1.3.2 生效方法二：@MapperScan</h3><pre><code class="java">@MapperScan(basePackages = &quot;com.bamboo.boot.mapper&quot;)
@SpringBootApplication
public class MainApplication &#123;

    public static void main(String[] args) &#123;
        SpringApplication.run(MainApplication.class, args);
    &#125;

&#125;
</code></pre>
<ul>
<li>可选操作：在@MapperScan注解后，为了可读性，可以在mapper接口中添加注解@Repository</li>
</ul>
<h2 id="1-4-应用"><a href="#1-4-应用" class="headerlink" title="1.4 应用"></a>1.4 应用</h2><pre><code class="java">@SpringBootTest
class MainApplicationTests &#123;

    @Autowired
    private UserMapper userMapper;

    @Test
    void contextLoads() &#123;
        userMapper.selectList(null).forEach(System.out::println);
    &#125;

&#125;
</code></pre>
<h2 id="1-5-添加日志"><a href="#1-5-添加日志" class="headerlink" title="1.5 添加日志"></a>1.5 添加日志</h2><pre><code class="yml">mybatis-plus:
  configuration:
    # 配置mybatis日志
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
</code></pre>
<h1 id="二、CRUD"><a href="#二、CRUD" class="headerlink" title="二、CRUD"></a>二、CRUD</h1><h2 id="2-1-BaseMapper"><a href="#2-1-BaseMapper" class="headerlink" title="2.1 BaseMapper"></a>2.1 BaseMapper</h2><p>MyBatis-Plus中的基本CRUD在内置的BaseMapper中都已得到了实现，可以直接使用。</p>
<pre><code class="java">//
// Source code recreated from a .class file by IntelliJ IDEA
// (powered by FernFlower decompiler)
//

package com.baomidou.mybatisplus.core.mapper;

import com.baomidou.mybatisplus.core.conditions.Wrapper;
import com.baomidou.mybatisplus.core.metadata.IPage;
import java.io.Serializable;
import java.util.Collection;
import java.util.List;
import java.util.Map;
import org.apache.ibatis.annotations.Param;
import org.apache.ibatis.exceptions.TooManyResultsException;

/**
 * Mapper 继承该接口后，无需编写 mapper.xml 文件，即可获得CRUD功能
 * &lt;p&gt;这个 Mapper 支持 id 泛型&lt;/p&gt;
 *
 * @author hubin
 * @since 2016-01-23
 */
public interface BaseMapper&lt;T&gt; extends Mapper&lt;T&gt; &#123;

    /**
     * 插入一条记录
     *
     * @param entity 实体对象
     */
    int insert(T entity);

    /**
     * 根据 ID 删除
     *
     * @param id 主键ID
     */
    int deleteById(Serializable id);

    /**
     * 根据实体(ID)删除
     *
     * @param entity 实体对象
     * @since 3.4.4
     */
    int deleteById(T entity);

    /**
     * 根据 columnMap 条件，删除记录
     *
     * @param columnMap 表字段 map 对象
     */
    int deleteByMap(@Param(Constants.COLUMN_MAP) Map&lt;String, Object&gt; columnMap);

    /**
     * 根据 entity 条件，删除记录
     *
     * @param queryWrapper 实体对象封装操作类（可以为 null,里面的 entity 用于生成 where 语句）
     */
    int delete(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);

    /**
     * 删除（根据ID或实体 批量删除）
     *
     * @param idList 主键ID列表或实体列表(不能为 null 以及 empty)
     */
    int deleteBatchIds(@Param(Constants.COLL) Collection&lt;?&gt; idList);

    /**
     * 根据 ID 修改
     *
     * @param entity 实体对象
     */
    int updateById(@Param(Constants.ENTITY) T entity);

    /**
     * 根据 whereEntity 条件，更新记录
     *
     * @param entity        实体对象 (set 条件值,可以为 null)
     * @param updateWrapper 实体对象封装操作类（可以为 null,里面的 entity 用于生成 where 语句）
     */
    int update(@Param(Constants.ENTITY) T entity, @Param(Constants.WRAPPER) Wrapper&lt;T&gt; updateWrapper);

    /**
     * 根据 ID 查询
     *
     * @param id 主键ID
     */
    T selectById(Serializable id);

    /**
     * 查询（根据ID 批量查询）
     *
     * @param idList 主键ID列表(不能为 null 以及 empty)
     */
    List&lt;T&gt; selectBatchIds(@Param(Constants.COLL) Collection&lt;? extends Serializable&gt; idList);

    /**
     * 查询（根据 columnMap 条件）
     *
     * @param columnMap 表字段 map 对象
     */
    List&lt;T&gt; selectByMap(@Param(Constants.COLUMN_MAP) Map&lt;String, Object&gt; columnMap);

    /**
     * 根据 entity 条件，查询一条记录
     * &lt;p&gt;查询一条记录，例如 qw.last(&quot;limit 1&quot;) 限制取一条记录, 注意：多条数据会报异常&lt;/p&gt;
     *
     * @param queryWrapper 实体对象封装操作类（可以为 null）
     */
    default T selectOne(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper) &#123;
        List&lt;T&gt; list = this.selectList(queryWrapper);
        // 抄自 DefaultSqlSession#selectOne
        if (list.size() == 1) &#123;
            return list.get(0);
        &#125; else if (list.size() &gt; 1) &#123;
            throw new TooManyResultsException(&quot;Expected one result (or null) to be returned by selectOne(), but found: &quot; + list.size());
        &#125; else &#123;
            return null;
        &#125;
    &#125;

    /**
     * 根据 Wrapper 条件，判断是否存在记录
     *
     * @param queryWrapper 实体对象封装操作类
     * @return 是否存在记录
     */
    default boolean exists(Wrapper&lt;T&gt; queryWrapper) &#123;
        Long count = this.selectCount(queryWrapper);
        return null != count &amp;&amp; count &gt; 0;
    &#125;

    /**
     * 根据 Wrapper 条件，查询总记录数
     *
     * @param queryWrapper 实体对象封装操作类（可以为 null）
     */
    Long selectCount(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);

    /**
     * 根据 entity 条件，查询全部记录
     *
     * @param queryWrapper 实体对象封装操作类（可以为 null）
     */
    List&lt;T&gt; selectList(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);

    /**
     * 根据 Wrapper 条件，查询全部记录
     *
     * @param queryWrapper 实体对象封装操作类（可以为 null）
     */
    List&lt;Map&lt;String, Object&gt;&gt; selectMaps(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);

    /**
     * 根据 Wrapper 条件，查询全部记录
     * &lt;p&gt;注意： 只返回第一个字段的值&lt;/p&gt;
     *
     * @param queryWrapper 实体对象封装操作类（可以为 null）
     */
    List&lt;Object&gt; selectObjs(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);

    /**
     * 根据 entity 条件，查询全部记录（并翻页）
     *
     * @param page         分页查询条件（可以为 RowBounds.DEFAULT）
     * @param queryWrapper 实体对象封装操作类（可以为 null）
     */
    &lt;P extends IPage&lt;T&gt;&gt; P selectPage(P page, @Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);

    /**
     * 根据 Wrapper 条件，查询全部记录（并翻页）
     *
     * @param page         分页查询条件
     * @param queryWrapper 实体对象封装操作类
     */
    &lt;P extends IPage&lt;Map&lt;String, Object&gt;&gt;&gt; P selectMapsPage(P page, @Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);
&#125;
</code></pre>
<h2 id="2-2-插入"><a href="#2-2-插入" class="headerlink" title="2.2 插入"></a>2.2 插入</h2><pre><code class="java">    @Test
    public void testInsert() &#123;
        User user = new User(null, &quot;张三&quot;, 23, &quot;zhangsan@atguigu.com&quot;);
        //INSERT INTO user ( id, name, age, email ) VALUES ( ?, ?, ?, ? )
        int result = userMapper.insert(user);
        System.out.println(&quot;受影响行数：&quot; + result);
        //1475754982694199298
        System.out.println(&quot;id自动获取：&quot; + user.getId());
    &#125;
</code></pre>
<blockquote>
<p>最终执行的结果，所获取的id为1475754982694199298</p>
<p>这是因为MyBatis-Plus在实现插入数据时，会默认基于雪花算法的策略生成id</p>
</blockquote>
<h2 id="2-3-删除"><a href="#2-3-删除" class="headerlink" title="2.3 删除"></a>2.3 删除</h2><h3 id="2-3-1-通过id删除记录"><a href="#2-3-1-通过id删除记录" class="headerlink" title="2.3.1 通过id删除记录"></a>2.3.1 通过id删除记录</h3><pre><code class="java">    @Test
    public void testDeleteById() &#123;
        //通过id删除用户信息
        //DELETE FROM user WHERE id=?
        int result = userMapper.deleteById(1475754982694199298L);
        System.out.println(&quot;受影响行数：&quot; + result);
    &#125;
</code></pre>
<h3 id="2-3-2-通过id批量删除记录"><a href="#2-3-2-通过id批量删除记录" class="headerlink" title="2.3.2 通过id批量删除记录"></a>2.3.2 通过id批量删除记录</h3><pre><code class="java">    @Test
    public void testDeleteBatchIds()&#123;
        //通过多个id批量删除
        //DELETE FROM user WHERE id IN ( ? , ? , ? )
        List&lt;Long&gt; idList = Arrays.asList(1L, 2L, 3L);
        int result = userMapper.deleteBatchIds(idList);
        System.out.println(&quot;受影响行数：&quot;+result);
    &#125;
</code></pre>
<h3 id="2-3-3-通过map条件删除记录"><a href="#2-3-3-通过map条件删除记录" class="headerlink" title="2.3.3 通过map条件删除记录"></a>2.3.3 通过map条件删除记录</h3><pre><code class="java">    @Test
    public void testDeleteByMap()&#123;
        //根据map集合中所设置的条件删除记录
        //DELETE FROM user WHERE name = ? AND age = ?
        Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();
        map.put(&quot;age&quot;, 23);
        map.put(&quot;name&quot;, &quot;张三&quot;);
        int result = userMapper.deleteByMap(map);
        System.out.println(&quot;受影响行数：&quot;+result);
    &#125;
</code></pre>
<h2 id="2-4-修改"><a href="#2-4-修改" class="headerlink" title="2.4 修改"></a>2.4 修改</h2><pre><code class="java">    @Test
    public void testUpdateById() &#123;
        User user = new User(4L, &quot;admin&quot;, 22, null);
        //UPDATE user SET name=?, age=? WHERE id=?
        int result = userMapper.updateById(user);
        System.out.println(&quot;受影响行数：&quot; + result);
    &#125;
</code></pre>
<h2 id="2-5-查询"><a href="#2-5-查询" class="headerlink" title="2.5 查询"></a>2.5 查询</h2><h3 id="2-5-1-根据id查询用户信息"><a href="#2-5-1-根据id查询用户信息" class="headerlink" title="2.5.1 根据id查询用户信息"></a>2.5.1 根据id查询用户信息</h3><pre><code class="java">    @Test
    public void testSelectById() &#123;
        //根据id查询用户信息
        //SELECT id,name,age,email FROM user WHERE id=?
        User user = userMapper.selectById(4L);
        System.out.println(user);
    &#125;
</code></pre>
<h3 id="2-5-2-根据多个id查询多个用户信息"><a href="#2-5-2-根据多个id查询多个用户信息" class="headerlink" title="2.5.2 根据多个id查询多个用户信息"></a>2.5.2 根据多个id查询多个用户信息</h3><pre><code class="java">    @Test
    public void testSelectBatchIds() &#123;
        //根据多个id查询多个用户信息
        //SELECT id,name,age,email FROM user WHERE id IN ( ? , ? )
        List&lt;Long&gt; idList = Arrays.asList(4L, 5L);
        List&lt;User&gt; list = userMapper.selectBatchIds(idList);
        list.forEach(System.out::println);
    &#125;
</code></pre>
<h3 id="2-5-3-通过map条件查询用户信息"><a href="#2-5-3-通过map条件查询用户信息" class="headerlink" title="2.5.3 通过map条件查询用户信息"></a>2.5.3 通过map条件查询用户信息</h3><pre><code class="java">    @Test
    public void testSelectByMap() &#123;
        //通过map条件查询用户信息
        //SELECT id,name,age,email FROM user WHERE name = ? AND age = ?
        Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();
        map.put(&quot;age&quot;, 22);
        map.put(&quot;name&quot;, &quot;admin&quot;);
        List&lt;User&gt; list = userMapper.selectByMap(map);
        list.forEach(System.out::println);
    &#125;
</code></pre>
<h3 id="2-5-4-查询所有数据"><a href="#2-5-4-查询所有数据" class="headerlink" title="2.5.4 查询所有数据"></a>2.5.4 查询所有数据</h3><pre><code class="java">    @Test
    public void testSelectList() &#123;
        //查询所有用户信息
        //SELECT id,name,age,email FROM user
        List&lt;User&gt; list = userMapper.selectList(null);
        list.forEach(System.out::println);
    &#125;
</code></pre>
<h2 id="2-6-通用Service"><a href="#2-6-通用Service" class="headerlink" title="2.6 通用Service"></a>2.6 通用Service</h2><blockquote>
<p>说明：</p>
<ul>
<li>通用 Service CRUD 封装IService接口，进一步封装 CRUD 采用 <code>get 查询单行</code> <code>remove 删除</code> <code>list 查询集合</code> <code>page 分页</code> 前缀命名方式区分 Mapper 层避免混淆</li>
<li>泛型 <code>T</code> 为任意实体对象</li>
<li>建议如果存在自定义通用 Service 方法的可能，请创建自己的 IBaseService 继承<code>Mybatis-Plus</code>提供的基类</li>
</ul>
</blockquote>
<h3 id="2-6-1-IService"><a href="#2-6-1-IService" class="headerlink" title="2.6.1 IService"></a>2.6.1 IService</h3><ul>
<li>MyBatis-Plus中有一个接口 IService和其实现类 ServiceImpl，封装了常见的业务层逻辑</li>
<li>详情查看源码IService和ServiceImpl</li>
</ul>
<h4 id="①-IService源码"><a href="#①-IService源码" class="headerlink" title="① IService源码"></a>① IService源码</h4><pre><code class="java">package com.baomidou.mybatisplus.extension.service;

/**
 * 顶级 Service
 *
 * @author hubin
 * @since 2018-06-23
 */
public interface IService&lt;T&gt; &#123;

    /**
     * 默认批次提交数量
     */
    int DEFAULT_BATCH_SIZE = 1000;

    /**
     * 插入一条记录（选择字段，策略插入）
     *
     * @param entity 实体对象
     */
    default boolean save(T entity) &#123;
        return SqlHelper.retBool(getBaseMapper().insert(entity));
    &#125;

    /**
     * 插入（批量）
     *
     * @param entityList 实体对象集合
     */
    @Transactional(rollbackFor = Exception.class)
    default boolean saveBatch(Collection&lt;T&gt; entityList) &#123;
        return saveBatch(entityList, DEFAULT_BATCH_SIZE);
    &#125;

    /**
     * 插入（批量）
     *
     * @param entityList 实体对象集合
     * @param batchSize  插入批次数量
     */
    boolean saveBatch(Collection&lt;T&gt; entityList, int batchSize);

    /**
     * 批量修改插入
     *
     * @param entityList 实体对象集合
     */
    @Transactional(rollbackFor = Exception.class)
    default boolean saveOrUpdateBatch(Collection&lt;T&gt; entityList) &#123;
        return saveOrUpdateBatch(entityList, DEFAULT_BATCH_SIZE);
    &#125;

    /**
     * 批量修改插入
     *
     * @param entityList 实体对象集合
     * @param batchSize  每次的数量
     */
    boolean saveOrUpdateBatch(Collection&lt;T&gt; entityList, int batchSize);

    /**
     * 根据 ID 删除
     *
     * @param id 主键ID
     */
    default boolean removeById(Serializable id) &#123;
        return SqlHelper.retBool(getBaseMapper().deleteById(id));
    &#125;

    /**
     * 根据 ID 删除
     *
     * @param id      主键(类型必须与实体类型字段保持一致)
     * @param useFill 是否启用填充(为true的情况,会将入参转换实体进行delete删除)
     * @return 删除结果
     * @since 3.5.0
     */
    default boolean removeById(Serializable id, boolean useFill) &#123;
        throw new UnsupportedOperationException(&quot;不支持的方法!&quot;);
    &#125;

    /**
     * 根据实体(ID)删除
     *
     * @param entity 实体
     * @since 3.4.4
     */
    default boolean removeById(T entity) &#123;
        return SqlHelper.retBool(getBaseMapper().deleteById(entity));
    &#125;

    /**
     * 根据 columnMap 条件，删除记录
     *
     * @param columnMap 表字段 map 对象
     */
    default boolean removeByMap(Map&lt;String, Object&gt; columnMap) &#123;
        Assert.notEmpty(columnMap, &quot;error: columnMap must not be empty&quot;);
        return SqlHelper.retBool(getBaseMapper().deleteByMap(columnMap));
    &#125;

    /**
     * 根据 entity 条件，删除记录
     *
     * @param queryWrapper 实体包装类 &#123;@link com.baomidou.mybatisplus.core.conditions.query.QueryWrapper&#125;
     */
    default boolean remove(Wrapper&lt;T&gt; queryWrapper) &#123;
        return SqlHelper.retBool(getBaseMapper().delete(queryWrapper));
    &#125;

    /**
     * 删除（根据ID 批量删除）
     *
     * @param list 主键ID或实体列表
     */
    default boolean removeByIds(Collection&lt;?&gt; list) &#123;
        if (CollectionUtils.isEmpty(list)) &#123;
            return false;
        &#125;
        return SqlHelper.retBool(getBaseMapper().deleteBatchIds(list));
    &#125;

    /**
     * 批量删除
     *
     * @param list    主键ID或实体列表
     * @param useFill 是否填充(为true的情况,会将入参转换实体进行delete删除)
     * @return 删除结果
     * @since 3.5.0
     */
    @Transactional(rollbackFor = Exception.class)
    default boolean removeByIds(Collection&lt;?&gt; list, boolean useFill) &#123;
        if (CollectionUtils.isEmpty(list)) &#123;
            return false;
        &#125;
        if (useFill) &#123;
            return removeBatchByIds(list, true);
        &#125;
        return SqlHelper.retBool(getBaseMapper().deleteBatchIds(list));
    &#125;

    /**
     * 批量删除(jdbc批量提交)
     *
     * @param list 主键ID或实体列表(主键ID类型必须与实体类型字段保持一致)
     * @return 删除结果
     * @since 3.5.0
     */
    @Transactional(rollbackFor = Exception.class)
    default boolean removeBatchByIds(Collection&lt;?&gt; list) &#123;
        return removeBatchByIds(list, DEFAULT_BATCH_SIZE);
    &#125;

    /**
     * 批量删除(jdbc批量提交)
     *
     * @param list    主键ID或实体列表(主键ID类型必须与实体类型字段保持一致)
     * @param useFill 是否启用填充(为true的情况,会将入参转换实体进行delete删除)
     * @return 删除结果
     * @since 3.5.0
     */
    @Transactional(rollbackFor = Exception.class)
    default boolean removeBatchByIds(Collection&lt;?&gt; list, boolean useFill) &#123;
        return removeBatchByIds(list, DEFAULT_BATCH_SIZE, useFill);
    &#125;

    /**
     * 批量删除(jdbc批量提交)
     *
     * @param list      主键ID或实体列表
     * @param batchSize 批次大小
     * @return 删除结果
     * @since 3.5.0
     */
    default boolean removeBatchByIds(Collection&lt;?&gt; list, int batchSize) &#123;
        throw new UnsupportedOperationException(&quot;不支持的方法!&quot;);
    &#125;

    /**
     * 批量删除(jdbc批量提交)
     *
     * @param list      主键ID或实体列表
     * @param batchSize 批次大小
     * @param useFill   是否启用填充(为true的情况,会将入参转换实体进行delete删除)
     * @return 删除结果
     * @since 3.5.0
     */
    default boolean removeBatchByIds(Collection&lt;?&gt; list, int batchSize, boolean useFill) &#123;
        throw new UnsupportedOperationException(&quot;不支持的方法!&quot;);
    &#125;

    /**
     * 根据 ID 选择修改
     *
     * @param entity 实体对象
     */
    default boolean updateById(T entity) &#123;
        return SqlHelper.retBool(getBaseMapper().updateById(entity));
    &#125;

    /**
     * 根据 UpdateWrapper 条件，更新记录 需要设置sqlset
     *
     * @param updateWrapper 实体对象封装操作类 &#123;@link com.baomidou.mybatisplus.core.conditions.update.UpdateWrapper&#125;
     */
    default boolean update(Wrapper&lt;T&gt; updateWrapper) &#123;
        return update(null, updateWrapper);
    &#125;

    /**
     * 根据 whereEntity 条件，更新记录
     *
     * @param entity        实体对象
     * @param updateWrapper 实体对象封装操作类 &#123;@link com.baomidou.mybatisplus.core.conditions.update.UpdateWrapper&#125;
     */
    default boolean update(T entity, Wrapper&lt;T&gt; updateWrapper) &#123;
        return SqlHelper.retBool(getBaseMapper().update(entity, updateWrapper));
    &#125;

    /**
     * 根据ID 批量更新
     *
     * @param entityList 实体对象集合
     */
    @Transactional(rollbackFor = Exception.class)
    default boolean updateBatchById(Collection&lt;T&gt; entityList) &#123;
        return updateBatchById(entityList, DEFAULT_BATCH_SIZE);
    &#125;

    /**
     * 根据ID 批量更新
     *
     * @param entityList 实体对象集合
     * @param batchSize  更新批次数量
     */
    boolean updateBatchById(Collection&lt;T&gt; entityList, int batchSize);

    /**
     * TableId 注解存在更新记录，否插入一条记录
     *
     * @param entity 实体对象
     */
    boolean saveOrUpdate(T entity);

    /**
     * 根据 ID 查询
     *
     * @param id 主键ID
     */
    default T getById(Serializable id) &#123;
        return getBaseMapper().selectById(id);
    &#125;

    /**
     * 查询（根据ID 批量查询）
     *
     * @param idList 主键ID列表
     */
    default List&lt;T&gt; listByIds(Collection&lt;? extends Serializable&gt; idList) &#123;
        return getBaseMapper().selectBatchIds(idList);
    &#125;

    /**
     * 查询（根据 columnMap 条件）
     *
     * @param columnMap 表字段 map 对象
     */
    default List&lt;T&gt; listByMap(Map&lt;String, Object&gt; columnMap) &#123;
        return getBaseMapper().selectByMap(columnMap);
    &#125;

    /**
     * 根据 Wrapper，查询一条记录 &lt;br/&gt;
     * &lt;p&gt;结果集，如果是多个会抛出异常，随机取一条加上限制条件 wrapper.last(&quot;LIMIT 1&quot;)&lt;/p&gt;
     *
     * @param queryWrapper 实体对象封装操作类 &#123;@link com.baomidou.mybatisplus.core.conditions.query.QueryWrapper&#125;
     */
    default T getOne(Wrapper&lt;T&gt; queryWrapper) &#123;
        return getOne(queryWrapper, true);
    &#125;

    /**
     * 根据 Wrapper，查询一条记录
     *
     * @param queryWrapper 实体对象封装操作类 &#123;@link com.baomidou.mybatisplus.core.conditions.query.QueryWrapper&#125;
     * @param throwEx      有多个 result 是否抛出异常
     */
    T getOne(Wrapper&lt;T&gt; queryWrapper, boolean throwEx);

    /**
     * 根据 Wrapper，查询一条记录
     *
     * @param queryWrapper 实体对象封装操作类 &#123;@link com.baomidou.mybatisplus.core.conditions.query.QueryWrapper&#125;
     */
    Map&lt;String, Object&gt; getMap(Wrapper&lt;T&gt; queryWrapper);

    /**
     * 根据 Wrapper，查询一条记录
     *
     * @param queryWrapper 实体对象封装操作类 &#123;@link com.baomidou.mybatisplus.core.conditions.query.QueryWrapper&#125;
     * @param mapper       转换函数
     */
    &lt;V&gt; V getObj(Wrapper&lt;T&gt; queryWrapper, Function&lt;? super Object, V&gt; mapper);

    /**
     * 查询总记录数
     *
     * @see Wrappers#emptyWrapper()
     */
    default long count() &#123;
        return count(Wrappers.emptyWrapper());
    &#125;

    /**
     * 根据 Wrapper 条件，查询总记录数
     *
     * @param queryWrapper 实体对象封装操作类 &#123;@link com.baomidou.mybatisplus.core.conditions.query.QueryWrapper&#125;
     */
    default long count(Wrapper&lt;T&gt; queryWrapper) &#123;
        return SqlHelper.retCount(getBaseMapper().selectCount(queryWrapper));
    &#125;

    /**
     * 查询列表
     *
     * @param queryWrapper 实体对象封装操作类 &#123;@link com.baomidou.mybatisplus.core.conditions.query.QueryWrapper&#125;
     */
    default List&lt;T&gt; list(Wrapper&lt;T&gt; queryWrapper) &#123;
        return getBaseMapper().selectList(queryWrapper);
    &#125;

    /**
     * 查询所有
     *
     * @see Wrappers#emptyWrapper()
     */
    default List&lt;T&gt; list() &#123;
        return list(Wrappers.emptyWrapper());
    &#125;

    /**
     * 翻页查询
     *
     * @param page         翻页对象
     * @param queryWrapper 实体对象封装操作类 &#123;@link com.baomidou.mybatisplus.core.conditions.query.QueryWrapper&#125;
     */
    default &lt;E extends IPage&lt;T&gt;&gt; E page(E page, Wrapper&lt;T&gt; queryWrapper) &#123;
        return getBaseMapper().selectPage(page, queryWrapper);
    &#125;

    /**
     * 无条件翻页查询
     *
     * @param page 翻页对象
     * @see Wrappers#emptyWrapper()
     */
    default &lt;E extends IPage&lt;T&gt;&gt; E page(E page) &#123;
        return page(page, Wrappers.emptyWrapper());
    &#125;

    /**
     * 查询列表
     *
     * @param queryWrapper 实体对象封装操作类 &#123;@link com.baomidou.mybatisplus.core.conditions.query.QueryWrapper&#125;
     */
    default List&lt;Map&lt;String, Object&gt;&gt; listMaps(Wrapper&lt;T&gt; queryWrapper) &#123;
        return getBaseMapper().selectMaps(queryWrapper);
    &#125;

    /**
     * 查询所有列表
     *
     * @see Wrappers#emptyWrapper()
     */
    default List&lt;Map&lt;String, Object&gt;&gt; listMaps() &#123;
        return listMaps(Wrappers.emptyWrapper());
    &#125;

    /**
     * 查询全部记录
     */
    default List&lt;Object&gt; listObjs() &#123;
        return listObjs(Function.identity());
    &#125;

    /**
     * 查询全部记录
     *
     * @param mapper 转换函数
     */
    default &lt;V&gt; List&lt;V&gt; listObjs(Function&lt;? super Object, V&gt; mapper) &#123;
        return listObjs(Wrappers.emptyWrapper(), mapper);
    &#125;

    /**
     * 根据 Wrapper 条件，查询全部记录
     *
     * @param queryWrapper 实体对象封装操作类 &#123;@link com.baomidou.mybatisplus.core.conditions.query.QueryWrapper&#125;
     */
    default List&lt;Object&gt; listObjs(Wrapper&lt;T&gt; queryWrapper) &#123;
        return listObjs(queryWrapper, Function.identity());
    &#125;

    /**
     * 根据 Wrapper 条件，查询全部记录
     *
     * @param queryWrapper 实体对象封装操作类 &#123;@link com.baomidou.mybatisplus.core.conditions.query.QueryWrapper&#125;
     * @param mapper       转换函数
     */
    default &lt;V&gt; List&lt;V&gt; listObjs(Wrapper&lt;T&gt; queryWrapper, Function&lt;? super Object, V&gt; mapper) &#123;
        return getBaseMapper().selectObjs(queryWrapper).stream().filter(Objects::nonNull).map(mapper).collect(Collectors.toList());
    &#125;

    /**
     * 翻页查询
     *
     * @param page         翻页对象
     * @param queryWrapper 实体对象封装操作类 &#123;@link com.baomidou.mybatisplus.core.conditions.query.QueryWrapper&#125;
     */
    default &lt;E extends IPage&lt;Map&lt;String, Object&gt;&gt;&gt; E pageMaps(E page, Wrapper&lt;T&gt; queryWrapper) &#123;
        return getBaseMapper().selectMapsPage(page, queryWrapper);
    &#125;

    /**
     * 无条件翻页查询
     *
     * @param page 翻页对象
     * @see Wrappers#emptyWrapper()
     */
    default &lt;E extends IPage&lt;Map&lt;String, Object&gt;&gt;&gt; E pageMaps(E page) &#123;
        return pageMaps(page, Wrappers.emptyWrapper());
    &#125;

    /**
     * 获取对应 entity 的 BaseMapper
     *
     * @return BaseMapper
     */
    BaseMapper&lt;T&gt; getBaseMapper();

    /**
     * 获取 entity 的 class
     *
     * @return &#123;@link Class&lt;T&gt;&#125;
     */
    Class&lt;T&gt; getEntityClass();

    /**
     * 以下的方法使用介绍:
     *
     * 一. 名称介绍
     * 1. 方法名带有 query 的为对数据的查询操作, 方法名带有 update 的为对数据的修改操作
     * 2. 方法名带有 lambda 的为内部方法入参 column 支持函数式的
     * 二. 支持介绍
     *
     * 1. 方法名带有 query 的支持以 &#123;@link ChainQuery&#125; 内部的方法名结尾进行数据查询操作
     * 2. 方法名带有 update 的支持以 &#123;@link ChainUpdate&#125; 内部的方法名为结尾进行数据修改操作
     *
     * 三. 使用示例,只用不带 lambda 的方法各展示一个例子,其他类推
     * 1. 根据条件获取一条数据: `query().eq(&quot;column&quot;, value).one()`
     * 2. 根据条件删除一条数据: `update().eq(&quot;column&quot;, value).remove()`
     *
     */

    /**
     * 链式查询 普通
     *
     * @return QueryWrapper 的包装类
     */
    default QueryChainWrapper&lt;T&gt; query() &#123;
        return ChainWrappers.queryChain(getBaseMapper());
    &#125;

    /**
     * 链式查询 lambda 式
     * &lt;p&gt;注意：不支持 Kotlin &lt;/p&gt;
     *
     * @return LambdaQueryWrapper 的包装类
     */
    default LambdaQueryChainWrapper&lt;T&gt; lambdaQuery() &#123;
        return ChainWrappers.lambdaQueryChain(getBaseMapper(), getEntityClass());
    &#125;

    /**
     * 链式查询 lambda 式
     * &lt;p&gt;注意：不支持 Kotlin &lt;/p&gt;
     *
     * @param entity 实体对象
     * @return LambdaQueryWrapper 的包装类
     */
    default LambdaQueryChainWrapper&lt;T&gt; lambdaQuery(T entity) &#123;
        return ChainWrappers.lambdaQueryChain(getBaseMapper(), entity);
    &#125;

    /**
     * 链式查询 lambda 式
     * kotlin 使用
     *
     * @return KtQueryWrapper 的包装类
     */
    default KtQueryChainWrapper&lt;T&gt; ktQuery() &#123;
        return ChainWrappers.ktQueryChain(getBaseMapper(), getEntityClass());
    &#125;

    /**
     * 链式查询 lambda 式
     * kotlin 使用
     *
     * @return KtQueryWrapper 的包装类
     */
    default KtUpdateChainWrapper&lt;T&gt; ktUpdate() &#123;
        return ChainWrappers.ktUpdateChain(getBaseMapper(), getEntityClass());
    &#125;

    /**
     * 链式更改 普通
     *
     * @return UpdateWrapper 的包装类
     */
    default UpdateChainWrapper&lt;T&gt; update() &#123;
        return ChainWrappers.updateChain(getBaseMapper());
    &#125;

    /**
     * 链式更改 lambda 式
     * &lt;p&gt;注意：不支持 Kotlin &lt;/p&gt;
     *
     * @return LambdaUpdateWrapper 的包装类
     */
    default LambdaUpdateChainWrapper&lt;T&gt; lambdaUpdate() &#123;
        return ChainWrappers.lambdaUpdateChain(getBaseMapper());
    &#125;

    /**
     * &lt;p&gt;
     * 根据updateWrapper尝试更新，否继续执行saveOrUpdate(T)方法
     * 此次修改主要是减少了此项业务代码的代码量（存在性验证之后的saveOrUpdate操作）
     * &lt;/p&gt;
     *
     * @param entity 实体对象
     */
    default boolean saveOrUpdate(T entity, Wrapper&lt;T&gt; updateWrapper) &#123;
        return update(entity, updateWrapper) || saveOrUpdate(entity);
    &#125;
&#125;
</code></pre>
<h4 id="②-ServiceImpl源码"><a href="#②-ServiceImpl源码" class="headerlink" title="② ServiceImpl源码"></a>② ServiceImpl源码</h4><pre><code class="java">package com.baomidou.mybatisplus.extension.service.impl;

/**
 * IService 实现类（ 泛型：M 是 mapper 对象，T 是实体 ）
 *
 * @author hubin
 * @since 2018-06-23
 */
@SuppressWarnings(&quot;unchecked&quot;)
public class ServiceImpl&lt;M extends BaseMapper&lt;T&gt;, T&gt; implements IService&lt;T&gt; &#123;

    protected Log log = LogFactory.getLog(getClass());

    @Autowired
    protected M baseMapper;

    @Override
    public M getBaseMapper() &#123;
        return baseMapper;
    &#125;

    protected Class&lt;T&gt; entityClass = currentModelClass();

    @Override
    public Class&lt;T&gt; getEntityClass() &#123;
        return entityClass;
    &#125;

    protected Class&lt;M&gt; mapperClass = currentMapperClass();

    /**
     * 判断数据库操作是否成功
     *
     * @param result 数据库操作返回影响条数
     * @return boolean
     * @deprecated 3.3.1
     */
    @Deprecated
    protected boolean retBool(Integer result) &#123;
        return SqlHelper.retBool(result);
    &#125;

    protected Class&lt;M&gt; currentMapperClass() &#123;
        return (Class&lt;M&gt;) ReflectionKit.getSuperClassGenericType(this.getClass(), ServiceImpl.class, 0);
    &#125;

    protected Class&lt;T&gt; currentModelClass() &#123;
        return (Class&lt;T&gt;) ReflectionKit.getSuperClassGenericType(this.getClass(), ServiceImpl.class, 1);
    &#125;


    /**
     * 批量操作 SqlSession
     *
     * @deprecated 3.3.0
     */
    @Deprecated
    protected SqlSession sqlSessionBatch() &#123;
        return SqlHelper.sqlSessionBatch(entityClass);
    &#125;

    /**
     * 释放sqlSession
     *
     * @param sqlSession session
     * @deprecated 3.3.0
     */
    @Deprecated
    protected void closeSqlSession(SqlSession sqlSession) &#123;
        SqlSessionUtils.closeSqlSession(sqlSession, GlobalConfigUtils.currentSessionFactory(entityClass));
    &#125;

    /**
     * 获取 SqlStatement
     *
     * @param sqlMethod ignore
     * @return ignore
     * @see #getSqlStatement(SqlMethod)
     * @deprecated 3.4.0
     */
    @Deprecated
    protected String sqlStatement(SqlMethod sqlMethod) &#123;
        return SqlHelper.table(entityClass).getSqlStatement(sqlMethod.getMethod());
    &#125;

    /**
     * 批量插入
     *
     * @param entityList ignore
     * @param batchSize  ignore
     * @return ignore
     */
    @Transactional(rollbackFor = Exception.class)
    @Override
    public boolean saveBatch(Collection&lt;T&gt; entityList, int batchSize) &#123;
        String sqlStatement = getSqlStatement(SqlMethod.INSERT_ONE);
        return executeBatch(entityList, batchSize, (sqlSession, entity) -&gt; sqlSession.insert(sqlStatement, entity));
    &#125;

    /**
     * 获取mapperStatementId
     *
     * @param sqlMethod 方法名
     * @return 命名id
     * @since 3.4.0
     */
    protected String getSqlStatement(SqlMethod sqlMethod) &#123;
        return SqlHelper.getSqlStatement(mapperClass, sqlMethod);
    &#125;

    /**
     * TableId 注解存在更新记录，否插入一条记录
     *
     * @param entity 实体对象
     * @return boolean
     */
    @Transactional(rollbackFor = Exception.class)
    @Override
    public boolean saveOrUpdate(T entity) &#123;
        if (null != entity) &#123;
            TableInfo tableInfo = TableInfoHelper.getTableInfo(this.entityClass);
            Assert.notNull(tableInfo, &quot;error: can not execute. because can not find cache of TableInfo for entity!&quot;);
            String keyProperty = tableInfo.getKeyProperty();
            Assert.notEmpty(keyProperty, &quot;error: can not execute. because can not find column for id from entity!&quot;);
            Object idVal = tableInfo.getPropertyValue(entity, tableInfo.getKeyProperty());
            return StringUtils.checkValNull(idVal) || Objects.isNull(getById((Serializable) idVal)) ? save(entity) : updateById(entity);
        &#125;
        return false;
    &#125;

    @Transactional(rollbackFor = Exception.class)
    @Override
    public boolean saveOrUpdateBatch(Collection&lt;T&gt; entityList, int batchSize) &#123;
        TableInfo tableInfo = TableInfoHelper.getTableInfo(entityClass);
        Assert.notNull(tableInfo, &quot;error: can not execute. because can not find cache of TableInfo for entity!&quot;);
        String keyProperty = tableInfo.getKeyProperty();
        Assert.notEmpty(keyProperty, &quot;error: can not execute. because can not find column for id from entity!&quot;);
        return SqlHelper.saveOrUpdateBatch(this.entityClass, this.mapperClass, this.log, entityList, batchSize, (sqlSession, entity) -&gt; &#123;
            Object idVal = tableInfo.getPropertyValue(entity, keyProperty);
            return StringUtils.checkValNull(idVal)
                || CollectionUtils.isEmpty(sqlSession.selectList(getSqlStatement(SqlMethod.SELECT_BY_ID), entity));
        &#125;, (sqlSession, entity) -&gt; &#123;
            MapperMethod.ParamMap&lt;T&gt; param = new MapperMethod.ParamMap&lt;&gt;();
            param.put(Constants.ENTITY, entity);
            sqlSession.update(getSqlStatement(SqlMethod.UPDATE_BY_ID), param);
        &#125;);
    &#125;

    @Transactional(rollbackFor = Exception.class)
    @Override
    public boolean updateBatchById(Collection&lt;T&gt; entityList, int batchSize) &#123;
        String sqlStatement = getSqlStatement(SqlMethod.UPDATE_BY_ID);
        return executeBatch(entityList, batchSize, (sqlSession, entity) -&gt; &#123;
            MapperMethod.ParamMap&lt;T&gt; param = new MapperMethod.ParamMap&lt;&gt;();
            param.put(Constants.ENTITY, entity);
            sqlSession.update(sqlStatement, param);
        &#125;);
    &#125;

    @Override
    public T getOne(Wrapper&lt;T&gt; queryWrapper, boolean throwEx) &#123;
        if (throwEx) &#123;
            return baseMapper.selectOne(queryWrapper);
        &#125;
        return SqlHelper.getObject(log, baseMapper.selectList(queryWrapper));
    &#125;

    @Override
    public Map&lt;String, Object&gt; getMap(Wrapper&lt;T&gt; queryWrapper) &#123;
        return SqlHelper.getObject(log, baseMapper.selectMaps(queryWrapper));
    &#125;

    @Override
    public &lt;V&gt; V getObj(Wrapper&lt;T&gt; queryWrapper, Function&lt;? super Object, V&gt; mapper) &#123;
        return SqlHelper.getObject(log, listObjs(queryWrapper, mapper));
    &#125;

    /**
     * 执行批量操作
     *
     * @param consumer consumer
     * @since 3.3.0
     * @deprecated 3.3.1 后面我打算移除掉 &#123;@link #executeBatch(Collection, int, BiConsumer)&#125; &#125;.
     */
    @Deprecated
    protected boolean executeBatch(Consumer&lt;SqlSession&gt; consumer) &#123;
        return SqlHelper.executeBatch(this.entityClass, this.log, consumer);
    &#125;

    /**
     * 执行批量操作
     *
     * @param list      数据集合
     * @param batchSize 批量大小
     * @param consumer  执行方法
     * @param &lt;E&gt;       泛型
     * @return 操作结果
     * @since 3.3.1
     */
    protected &lt;E&gt; boolean executeBatch(Collection&lt;E&gt; list, int batchSize, BiConsumer&lt;SqlSession, E&gt; consumer) &#123;
        return SqlHelper.executeBatch(this.entityClass, this.log, list, batchSize, consumer);
    &#125;

    /**
     * 执行批量操作（默认批次提交数量&#123;@link IService#DEFAULT_BATCH_SIZE&#125;）
     *
     * @param list     数据集合
     * @param consumer 执行方法
     * @param &lt;E&gt;      泛型
     * @return 操作结果
     * @since 3.3.1
     */
    protected &lt;E&gt; boolean executeBatch(Collection&lt;E&gt; list, BiConsumer&lt;SqlSession, E&gt; consumer) &#123;
        return executeBatch(list, DEFAULT_BATCH_SIZE, consumer);
    &#125;

    @Override
    public boolean removeById(Serializable id) &#123;
        TableInfo tableInfo = TableInfoHelper.getTableInfo(getEntityClass());
        if (tableInfo.isWithLogicDelete() &amp;&amp; tableInfo.isWithUpdateFill()) &#123;
            return removeById(id, true);
        &#125;
        return SqlHelper.retBool(getBaseMapper().deleteById(id));
    &#125;

    @Override
    @Transactional(rollbackFor = Exception.class)
    public boolean removeByIds(Collection&lt;?&gt; list) &#123;
        if (CollectionUtils.isEmpty(list)) &#123;
            return false;
        &#125;
        TableInfo tableInfo = TableInfoHelper.getTableInfo(getEntityClass());
        if (tableInfo.isWithLogicDelete() &amp;&amp; tableInfo.isWithUpdateFill()) &#123;
            return removeBatchByIds(list, true);
        &#125;
        return SqlHelper.retBool(getBaseMapper().deleteBatchIds(list));
    &#125;

    @Override
    public boolean removeById(Serializable id, boolean useFill) &#123;
        TableInfo tableInfo = TableInfoHelper.getTableInfo(entityClass);
        if (useFill &amp;&amp; tableInfo.isWithLogicDelete()) &#123;
            if (!entityClass.isAssignableFrom(id.getClass())) &#123;
                T instance = tableInfo.newInstance();
                tableInfo.setPropertyValue(instance, tableInfo.getKeyProperty(), id);
                return removeById(instance);
            &#125;
        &#125;
        return SqlHelper.retBool(getBaseMapper().deleteById(id));
    &#125;

    @Override
    @Transactional(rollbackFor = Exception.class)
    public boolean removeBatchByIds(Collection&lt;?&gt; list, int batchSize) &#123;
        TableInfo tableInfo = TableInfoHelper.getTableInfo(entityClass);
        return removeBatchByIds(list, batchSize, tableInfo.isWithLogicDelete() &amp;&amp; tableInfo.isWithUpdateFill());
    &#125;

    @Override
    @Transactional(rollbackFor = Exception.class)
    public boolean removeBatchByIds(Collection&lt;?&gt; list, int batchSize, boolean useFill) &#123;
        String sqlStatement = getSqlStatement(SqlMethod.DELETE_BY_ID);
        TableInfo tableInfo = TableInfoHelper.getTableInfo(entityClass);
        return executeBatch(list, batchSize, (sqlSession, e) -&gt; &#123;
            if (useFill &amp;&amp; tableInfo.isWithLogicDelete()) &#123;
                if (entityClass.isAssignableFrom(e.getClass())) &#123;
                    sqlSession.update(sqlStatement, e);
                &#125; else &#123;
                    T instance = tableInfo.newInstance();
                    tableInfo.setPropertyValue(instance, tableInfo.getKeyProperty(), e);
                    sqlSession.update(sqlStatement, instance);
                &#125;
            &#125; else &#123;
                sqlSession.update(sqlStatement, e);
            &#125;
        &#125;);
    &#125;

&#125;
</code></pre>
<h3 id="2-6-2-创建Service接口和实现类"><a href="#2-6-2-创建Service接口和实现类" class="headerlink" title="2.6.2 创建Service接口和实现类"></a>2.6.2 创建Service接口和实现类</h3><pre><code class="java">public interface UserService extends IService&lt;User&gt; &#123;
&#125;

@Service
public class UserServiceImpl extends ServiceImpl&lt;UserMapper, User&gt; implements UserService &#123;
&#125;
</code></pre>
<h3 id="2-6-3-测试查询记录数"><a href="#2-6-3-测试查询记录数" class="headerlink" title="2.6.3 测试查询记录数"></a>2.6.3 测试查询记录数</h3><pre><code class="java">    @Autowired
    private UserService userService;
    
        @Test
    public void testGetCount()&#123;
        long count = userService.count();
        System.out.println(&quot;总记录数：&quot; + count);
    &#125;
</code></pre>
<h3 id="2-6-4-测试批量插入"><a href="#2-6-4-测试批量插入" class="headerlink" title="2.6.4 测试批量插入"></a>2.6.4 测试批量插入</h3><pre><code class="java">    @Test
    public void testSaveBatch()&#123;
        // SQL长度有限制，海量数据插入单条SQL无法实行，
        // 因此MP将批量插入放在了通用Service中实现，而不是通用Mapper
        ArrayList&lt;User&gt; users = new ArrayList&lt;&gt;();
        for (int i = 0; i &lt; 5; i++) &#123;
            User user = new User();
            user.setName(&quot;ybc&quot; + i);
            user.setAge(20 + i);
            users.add(user);
        &#125;
        //SQL:INSERT INTO t_user ( username, age ) VALUES ( ?, ? )
        userService.saveBatch(users);
    &#125;
    /**
     * ==&gt;  Preparing: INSERT INTO user ( id, name, age ) VALUES ( ?, ?, ? )
     * ==&gt; Parameters: 1695218724078444545(Long), ybc0(String), 20(Integer)
     * ==&gt; Parameters: 1695218724221050882(Long), ybc1(String), 21(Integer)
     * ==&gt; Parameters: 1695218724221050883(Long), ybc2(String), 22(Integer)
     * ==&gt; Parameters: 1695218724221050884(Long), ybc3(String), 23(Integer)
     * ==&gt; Parameters: 1695218724221050885(Long), ybc4(String), 24(Integer)
     */
</code></pre>
<h1 id="三、常用注解"><a href="#三、常用注解" class="headerlink" title="三、常用注解"></a>三、常用注解</h1><h2 id="3-1-TableName"><a href="#3-1-TableName" class="headerlink" title="3.1 @TableName"></a>3.1 @TableName</h2><ul>
<li>在使用MyBatis-Plus实现基本的CRUD时，我们并没有指定要操作的表，只是在Mapper接口继承BaseMapper时，设置了泛型User，而操作的表为user表</li>
<li>由此得出结论，MyBatis-Plus在确定操作的表时，由BaseMapper的泛型决定，即实体类型决定，且默认操作的表名和实体类型的类名一致</li>
</ul>
<p>问题：</p>
<ul>
<li>若实体类类型的类名和要操作的表的表名不一致，会出现什么问题？</li>
</ul>
<p>解决：</p>
<ul>
<li>方式一：通过@TableName解决问题</li>
<li>方式二：通过全局配置解决问题</li>
</ul>
<h3 id="3-1-1-TableName解决表名不一致"><a href="#3-1-1-TableName解决表名不一致" class="headerlink" title="3.1.1 @TableName解决表名不一致"></a>3.1.1 @TableName解决表名不一致</h3><pre><code class="java">@Data
@AllArgsConstructor
@NoArgsConstructor
@TableName(&quot;tbl_user&quot;)
public class User &#123;
    private Long id;
    private String name;
    private Integer age;
    private String email;
&#125;
</code></pre>
<h3 id="3-1-2-全局配置默认表前缀"><a href="#3-1-2-全局配置默认表前缀" class="headerlink" title="3.1.2 全局配置默认表前缀"></a>3.1.2 全局配置默认表前缀</h3><ul>
<li>实体类所对应的表都有固定的前缀，例如<code>t_</code>或<code>tbl_</code></li>
<li>使用MyBatis-Plus提供的全局配置，为实体类所对应的表名设置默认的前缀</li>
</ul>
<pre><code class="yml">mybatis-plus:
  global-config:
    db-config:
      table-prefix: tbl_
</code></pre>
<h2 id="3-2-TableId"><a href="#3-2-TableId" class="headerlink" title="3.2 @TableId"></a>3.2 @TableId</h2><p>MyBatis-Plus在实现CRUD时，会默认将id作为主键列，并在插入数据时，默认基于雪花算法的策略生成id</p>
<p>问题：</p>
<ul>
<li>若实体类和表中表示主键的不是id，而是其他字段，例如uid，MyBatis-Plus会自动识别uid为主键列吗？</li>
</ul>
<p>解决：</p>
<ul>
<li>@TableId</li>
</ul>
<h3 id="3-2-1-TableId标识主键"><a href="#3-2-1-TableId标识主键" class="headerlink" title="3.2.1 @TableId标识主键"></a>3.2.1 @TableId标识主键</h3><pre><code class="java">@Data
@AllArgsConstructor
@NoArgsConstructor
public class User &#123;
    @TableId
    private Long uid;
    private String name;
    private Integer age;
    private String email;
&#125;
</code></pre>
<h3 id="3-2-2-TableId的value属性"><a href="#3-2-2-TableId的value属性" class="headerlink" title="3.2.2 @TableId的value属性"></a>3.2.2 @TableId的value属性</h3><ul>
<li>若实体类中主键对应的属性为id，而表中表示主键的字段为uid，此时若只在属性id上添加注解@TableId，则抛出异常Unknown column ‘id’ in ‘field list’，即MyBatis-Plus仍然会将id作为表的主键操作，而表中表示主键的是字段uid</li>
<li>此时需要通过@TableId注解的value属性，指定表中的主键字段，@TableId(“uid”)或@TableId(value&#x3D;”uid”)</li>
</ul>
<pre><code class="java">@Data
@AllArgsConstructor
@NoArgsConstructor
public class User &#123;
    @TableId(&quot;uid&quot;)
    private Long id;
    private String name;
    private Integer age;
    private String email;
&#125;
</code></pre>
<h3 id="3-2-3-TableId的type属性"><a href="#3-2-3-TableId的type属性" class="headerlink" title="3.2.3 @TableId的type属性"></a>3.2.3 @TableId的type属性</h3><p>type属性用来定义主键策略</p>
<h4 id="①-常见的主键策略"><a href="#①-常见的主键策略" class="headerlink" title="① 常见的主键策略"></a>① 常见的主键策略</h4><table>
<thead>
<tr>
<th>值</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>IdType.ASSIGN_ID（默 认）</td>
<td>基于雪花算法的策略生成数据id，与数据库id是否设置自增无关</td>
</tr>
<tr>
<td>IdType.AUTO</td>
<td>使用数据库的自增策略，注意，该类型请确保<strong>数据库设置了id自增</strong>， 否则无效</td>
</tr>
</tbody></table>
<h4 id="②-IdType源码"><a href="#②-IdType源码" class="headerlink" title="② IdType源码"></a>② IdType源码</h4><pre><code class="java">@Getter
public enum IdType &#123;
    /**
     * 数据库ID自增
     * &lt;p&gt;该类型请确保数据库设置了 ID自增 否则无效&lt;/p&gt;
     */
    AUTO(0),
    /**
     * 该类型为未设置主键类型(注解里等于跟随全局,全局里约等于 INPUT)
     */
    NONE(1),
    /**
     * 用户输入ID
     * &lt;p&gt;该类型可以通过自己注册自动填充插件进行填充&lt;/p&gt;
     */
    INPUT(2),

    /* 以下2种类型、只有当插入对象ID 为空，才自动填充。 */
    /**
     * 分配ID (主键类型为number或string）,
     * 默认实现类 &#123;@link com.baomidou.mybatisplus.core.incrementer.DefaultIdentifierGenerator&#125;(雪花算法)
     *
     * @since 3.3.0
     */
    ASSIGN_ID(3),
    /**
     * 分配UUID (主键类型为 string)
     * 默认实现类 &#123;@link com.baomidou.mybatisplus.core.incrementer.DefaultIdentifierGenerator&#125;(UUID.replace(&quot;-&quot;,&quot;&quot;))
     */
    ASSIGN_UUID(4);

    private final int key;

    IdType(int key) &#123;
        this.key = key;
    &#125;
&#125;
</code></pre>
<h4 id="③-配置全局主键策略"><a href="#③-配置全局主键策略" class="headerlink" title="③ 配置全局主键策略"></a>③ 配置全局主键策略</h4><pre><code class="yml">mybatis-plus:
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
  global-config:
    db-config:
      table-prefix: tbl_
      # 配置MyBatis-Plus的主键策略
      id-type: auto
</code></pre>
<h3 id="3-2-4-雪花算法"><a href="#3-2-4-雪花算法" class="headerlink" title="3.2.4 雪花算法"></a>3.2.4 雪花算法</h3><h4 id="①-背景"><a href="#①-背景" class="headerlink" title="① 背景"></a>① 背景</h4><p>需要选择合适的方案去应对数据规模的增长，以应对逐渐增长的访问压力和数据量。</p>
<p>数据库的扩展方式主要包括：业务分库、主从复制，数据库分表。</p>
<h4 id="②-数据库分表"><a href="#②-数据库分表" class="headerlink" title="② 数据库分表"></a>② 数据库分表</h4><p>将不同业务数据分散存储到不同的数据库服务器，能够支撑百万甚至千万用户规模的业务，但如果业务继续发展，同一业务的单表数据也会达到单台数据库服务器的处理瓶颈。例如，淘宝的几亿用户数据，如果全部存放在一台数据库服务器的一张表中，肯定是无法满足性能要求的，此时就需要对单表数据进行拆分。</p>
<p>单表数据拆分有两种方式：垂直分表和水平分表。</p>
<p><strong>垂直分表</strong></p>
<ul>
<li>垂直分表适合将表中某些不常用且占了大量空间的列拆分出去。</li>
<li>例如，前面示意图中的 nickname 和 description 字段，假设我们是一个婚恋网站，用户在筛选其他用户的时候，主要是用 age 和 sex 两个字段进行查询，而 nickname 和 description 两个字段主要用于展示，一般不会在业务查询中用到。description 本身又比较长，因此我们可以将这两个字段独立到另外一张表中，这样在查询 age 和 sex 时，就能带来一定的性能提升。</li>
</ul>
<p><strong>水平分表</strong></p>
<ul>
<li>水平分表适合表行数特别大的表，有的公司要求单表行数超过 5000 万就必须进行分表，这个数字可以作为参考，但并不是绝对标准，关键还是要看表的访问性能。对于一些比较复杂的表，可能超过 1000万就要分表了；而对于一些简单的表，即使存储数据超过 1 亿行，也可以不分表。</li>
<li>但不管怎样，当看到表的数据量达到千万级别时，作为架构师就要警觉起来，因为这很可能是架构的性能瓶颈或者隐患。</li>
</ul>
<p>水平分表相比垂直分表，会引入更多的复杂性，例如要求全局唯一的数据id该如何处理</p>
<ul>
<li>主键自增<ul>
<li>①以最常见的用户 ID 为例，可以按照 1000000 的范围大小进行分段，1 ~ 999999 放到表中，1000000 ~ 1999999 放到表2中，以此类推。</li>
<li>②复杂点：分段大小的选取。分段太小会导致切分后子表数量过多，增加维护复杂度；分段太大可能会导致单表依然存在性能问题，一般建议分段大小在 100 万至 2000 万之间，具体需要根据业务选取合适的分段大小。</li>
<li>③优点：可以随着数据的增加平滑地扩充新的表。例如，现在的用户是 100 万，如果增加到 1000 万，只需要增加新的表就可以了，原有的数据不需要动。</li>
<li>④缺点：分布不均匀。假如按照 1000 万来进行分表，有可能某个分段实际存储的数据量只有 1 条，而另外一个分段实际存储的数据量有 1000 万条。</li>
</ul>
</li>
<li>取模<ul>
<li>①同样以用户 ID 为例，假如我们一开始就规划了 10 个数据库表，可以简单地用 user_id % 10 的值来表示数据所属的数据库表编号，ID 为 985 的用户放到编号为 5 的子表中，ID 为 10086 的用户放到编号为 6 的子表中。</li>
<li>②复杂点：初始表数量的确定。表数量太多维护比较麻烦，表数量太少又可能导致单表性能存在问题。</li>
<li>③优点：表分布比较均匀。</li>
<li>④缺点：扩充新的表很麻烦，所有数据都要重分布。</li>
</ul>
</li>
<li>雪花算法<ul>
<li>雪花算法是由Twitter公布的分布式主键生成算法，它能够保证不同表的主键的不重复性，以及相同表的主键的有序性。</li>
<li>①核心思想：<ul>
<li>长度共64bit（一个long型）。</li>
<li>首先是一个符号位，1bit标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0。</li>
<li>41bit时间截(毫秒级)，存储的是时间截的差值（当前时间截 - 开始时间截)，结果约等于69.73年。</li>
<li>10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID，可以部署在1024个节点）。</li>
<li>12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID）。</li>
</ul>
</li>
<li>②优点：整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞，并且效率较高。</li>
</ul>
</li>
</ul>
<h2 id="3-3-TableField"><a href="#3-3-TableField" class="headerlink" title="3.3 @TableField"></a>3.3 @TableField</h2><p>问题：如果实体类中的属性名和字段名不一致的情况，会出现什么问题呢？</p>
<h3 id="3-3-1-情况1"><a href="#3-3-1-情况1" class="headerlink" title="3.3.1 情况1"></a>3.3.1 情况1</h3><ul>
<li>若实体类中的属性使用的是驼峰命名风格，而表中的字段使用的是下划线命名风格</li>
<li>例如实体类属性userName，表中字段user_name</li>
<li>此时MyBatis-Plus会自动将下划线命名风格转化为驼峰命名风格</li>
<li>相当于在MyBatis中配置</li>
</ul>
<h3 id="3-3-2-情况2"><a href="#3-3-2-情况2" class="headerlink" title="3.3.2 情况2"></a>3.3.2 情况2</h3><ul>
<li>若实体类中的属性和表中的字段不满足情况1</li>
<li>例如实体类属性name，表中字段username</li>
<li>此时需要在实体类属性上使用@TableField(“username”)设置属性所对应的字段名</li>
</ul>
<h2 id="3-4-TableLogic"><a href="#3-4-TableLogic" class="headerlink" title="3.4 @TableLogic"></a>3.4 @TableLogic</h2><h3 id="3-4-1-逻辑删除"><a href="#3-4-1-逻辑删除" class="headerlink" title="3.4.1 逻辑删除"></a>3.4.1 逻辑删除</h3><ul>
<li>物理删除：真实删除，将对应数据从数据库中删除，之后查询不到此条被删除的数据</li>
<li>逻辑删除：假删除，将对应数据中代表是否被删除字段的状态修改为“被删除状态”，之后在数据库中仍旧能看到此条数据记录</li>
<li>使用场景：可以进行数据恢复</li>
</ul>
<h3 id="3-4-2-实现逻辑删除"><a href="#3-4-2-实现逻辑删除" class="headerlink" title="3.4.2 实现逻辑删除"></a>3.4.2 实现逻辑删除</h3><ol>
<li><p>数据库中创建逻辑删除状态列，设置默认值为0</p>
<ul>
<li>字段名：is_deleted</li>
<li>类型：int</li>
<li>默认值：0</li>
</ul>
</li>
<li><p>实体类中添加逻辑删除属性</p>
<pre><code class="java">@Data
@AllArgsConstructor
@NoArgsConstructor
public class User &#123;
    @TableId(value = &quot;uid&quot;, type = IdType.ASSIGN_ID)
    private Long id;
    private String name;
    private Integer age;
//    @TableField(exist = false)
    private String email;
    @TableLogic
    private Integer isDeleted;
&#125;
</code></pre>
</li>
<li><p>测试删除</p>
<ul>
<li><p>Java代码</p>
<pre><code class="java">    @Test
    public void testDeleteById() &#123;
        //通过id删除用户信息
        //DELETE FROM user WHERE id=?
        int result = userMapper.deleteById(5);
        System.out.println(&quot;受影响行数：&quot; + result);
    &#125;
</code></pre>
</li>
<li><p>测试删除功能，真正执行的是修改</p>
<pre><code class="sql">UPDATE t_user SET is_deleted=1 WHERE id=? AND is_deleted=0
</code></pre>
</li>
<li><p>测试查询功能，被逻辑删除的数据默认不会被查询</p>
<pre><code class="sql">SELECT id,username AS name,age,email,is_deleted FROM t_user WHERE is_deleted=0
</code></pre>
</li>
</ul>
</li>
</ol>
<h1 id="四、条件构造器和常用接口"><a href="#四、条件构造器和常用接口" class="headerlink" title="四、条件构造器和常用接口"></a>四、条件构造器和常用接口</h1><h2 id="4-1-wapper介绍"><a href="#4-1-wapper介绍" class="headerlink" title="4.1 wapper介绍"></a>4.1 wapper介绍</h2><ul>
<li>Wrapper ： 条件构造抽象类，最顶端父类<ul>
<li>AbstractWrapper ： 用于查询条件封装，生成 sql 的 where 条件<ul>
<li>QueryWrapper ： 查询条件封装</li>
<li>UpdateWrapper ： Update 条件封装</li>
<li>AbstractLambdaWrapper ： 使用Lambda 语法<ul>
<li>LambdaQueryWrapper ：用于Lambda语法使用的查询Wrapper</li>
<li>LambdaUpdateWrapper ： Lambda 更新封装Wrapper</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="4-2-QueryWrapper"><a href="#4-2-QueryWrapper" class="headerlink" title="4.2 QueryWrapper"></a>4.2 QueryWrapper</h2><h3 id="4-2-1-组装查询条件"><a href="#4-2-1-组装查询条件" class="headerlink" title="4.2.1 组装查询条件"></a>4.2.1 组装查询条件</h3><pre><code class="java">    @Test
    public void test01() &#123;
        //查询用户名包含a，年龄在20到30之间，并且邮箱不为null的用户信息
        //SELECT id,username AS name,age,email,is_deleted FROM t_user WHERE is_deleted=0 AND (username LIKE ? AND age BETWEEN ? AND ? AND email IS NOT NULL)
        QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;();
        queryWrapper.like(&quot;username&quot;, &quot;a&quot;)
                .between(&quot;age&quot;, 20, 30)
                .isNotNull(&quot;email&quot;);
        List&lt;User&gt; list = userMapper.selectList(queryWrapper);
        list.forEach(System.out::println);
    &#125;
</code></pre>
<h3 id="4-2-2-组装排序条件"><a href="#4-2-2-组装排序条件" class="headerlink" title="4.2.2 组装排序条件"></a>4.2.2 组装排序条件</h3><pre><code class="java">@Test
public void test02()&#123;
    //按年龄降序查询用户，如果年龄相同则按id升序排列
    //SELECT id,username AS name,age,email,is_deleted FROM t_user WHERE is_deleted=0 ORDER BY age DESC,id ASC
    QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;();
    queryWrapper
            .orderByDesc(&quot;age&quot;)
            .orderByAsc(&quot;id&quot;);
    List&lt;User&gt; users = userMapper.selectList(queryWrapper);
    users.forEach(System.out::println);
&#125;
</code></pre>
<h3 id="4-2-3-组装删除条件"><a href="#4-2-3-组装删除条件" class="headerlink" title="4.2.3 组装删除条件"></a>4.2.3 组装删除条件</h3><pre><code class="java">@Test
public void test03()&#123;
    //删除email为空的用户
    //DELETE FROM t_user WHERE (email IS NULL)
    QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;();
    queryWrapper.isNull(&quot;email&quot;);
    //条件构造器也可以构建删除语句的条件
    int result = userMapper.delete(queryWrapper);
    System.out.println(&quot;受影响的行数：&quot; + result);
&#125;
</code></pre>
<h3 id="4-2-4-条件的优先级"><a href="#4-2-4-条件的优先级" class="headerlink" title="4.2.4 条件的优先级"></a>4.2.4 条件的优先级</h3><pre><code class="java">@Test
public void test04() &#123;
    QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;();
    //将（年龄大于20并且用户名中包含有a）或邮箱为null的用户信息修改
    //UPDATE t_user SET age=?, email=? WHERE (username LIKE ? AND age &gt; ? OR email IS NULL)
    queryWrapper
            .like(&quot;username&quot;, &quot;a&quot;)
            .gt(&quot;age&quot;, 20)
            .or()
            .isNull(&quot;email&quot;);
    User user = new User();
    user.setAge(18);
    user.setEmail(&quot;user@atguigu.com&quot;);
    int result = userMapper.update(user, queryWrapper);
    System.out.println(&quot;受影响的行数：&quot; + result);
&#125;
</code></pre>
<pre><code class="java">    @Test
    public void test04() &#123;
        QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;();
//将用户名中包含有a并且（年龄大于20或邮箱为null）的用户信息修改
//UPDATE t_user SET age=?, email=? WHERE (username LIKE ? AND (age &gt; ? OR email IS NULL))
//lambda表达式内的逻辑优先运算
        queryWrapper
                .like(&quot;username&quot;, &quot;a&quot;)
                .and(i -&gt; i.gt(&quot;age&quot;, 20).or().isNull(&quot;email&quot;));
        User user = new User();
        user.setAge(18);
        user.setEmail(&quot;user@atguigu.com&quot;);
        int result = userMapper.update(user, queryWrapper);
        System.out.println(&quot;受影响的行数：&quot; + result);
    &#125;
</code></pre>
<h3 id="4-2-5-组装select子句"><a href="#4-2-5-组装select子句" class="headerlink" title="4.2.5 组装select子句"></a>4.2.5 组装select子句</h3><pre><code class="java">@Test
public void test05() &#123;
    //查询用户信息的username和age字段
    //SELECT username,age FROM t_user
    QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;();
    queryWrapper.select(&quot;username&quot;, &quot;age&quot;);
    //selectMaps()返回Map集合列表，通常配合select()使用，避免User对象中没有被查询到的列值 为null
    List&lt;Map&lt;String, Object&gt;&gt; maps = userMapper.selectMaps(queryWrapper);
    maps.forEach(System.out::println);
&#125;
</code></pre>
<h3 id="4-2-6-实现子查询"><a href="#4-2-6-实现子查询" class="headerlink" title="4.2.6 实现子查询"></a>4.2.6 实现子查询</h3><pre><code class="java">@Test
public void test06() &#123;
    //查询id小于等于3的用户信息
    //SELECT id,username AS name,age,email,is_deleted FROM t_user WHERE (id IN (select id from t_user where id &lt;= 3))
    QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;();
    queryWrapper.inSql(&quot;id&quot;, &quot;select id from t_user where id &lt;= 3&quot;);
    List&lt;User&gt; list = userMapper.selectList(queryWrapper);
    list.forEach(System.out::println);
&#125;   
</code></pre>
<h2 id="4-3-UpdateWrapper"><a href="#4-3-UpdateWrapper" class="headerlink" title="4.3 UpdateWrapper"></a>4.3 UpdateWrapper</h2><pre><code class="java">@Test
public void test07() &#123;
    //将（年龄大于20或邮箱为null）并且用户名中包含有a的用户信息修改
    //组装set子句以及修改条件
    UpdateWrapper&lt;User&gt; updateWrapper = new UpdateWrapper&lt;&gt;();
    //lambda表达式内的逻辑优先运算
    updateWrapper
            .set(&quot;age&quot;, 18)
            .set(&quot;email&quot;, &quot;user@atguigu.com&quot;)
            .like(&quot;username&quot;, &quot;a&quot;)
            .and(i -&gt; i.gt(&quot;age&quot;, 20).or().isNull(&quot;email&quot;));
    //这里必须要创建User对象，否则无法应用自动填充。如果没有自动填充，可以设置为null
    //UPDATE t_user SET username=?, age=?,email=? WHERE (username LIKE ? AND (age &gt; ? OR email IS NULL))
    //User user = new User();
    //user.setName(&quot;张三&quot;);
    //int result = userMapper.update(user, updateWrapper);
    //UPDATE t_user SET age=?,email=? WHERE (username LIKE ? AND (age &gt; ? OR email IS NULL))
    int result = userMapper.update(null, updateWrapper);
    System.out.println(result);
&#125;
</code></pre>
<h2 id="4-4-condition"><a href="#4-4-condition" class="headerlink" title="4.4 condition"></a>4.4 condition</h2><p>在真正开发的过程中，组装条件是常见的功能，而这些条件数据来源于用户输入，是可选的，因此我们在组装这些条件时，必须先判断用户是否选择了这些条件，若选择则需要组装该条件，若没有选择则一定不能组装，以免影响SQL执行的结果</p>
<h3 id="4-4-1-思路一"><a href="#4-4-1-思路一" class="headerlink" title="4.4.1 思路一"></a>4.4.1 思路一</h3><pre><code class="java">    @Test
    public void test08() &#123;
        //定义查询条件，有可能为null（用户未输入或未选择）
        String username = null;
        Integer ageBegin = 10;
        Integer ageEnd = 24;
        QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;();
        //StringUtils.isNotBlank()判断某字符串是否不为空且长度不为0且不由空白符(whitespace) 构成
        if (StringUtils.isNotBlank(username)) &#123;
            queryWrapper.like(&quot;username&quot;, &quot;a&quot;);
        &#125;
        if (ageBegin != null) &#123;
            queryWrapper.ge(&quot;age&quot;, ageBegin);
        &#125;
        if (ageEnd != null) &#123;
            queryWrapper.le(&quot;age&quot;, ageEnd);
        &#125;
        //SELECT id,username AS name,age,email,is_deleted FROM t_user WHERE (age &gt;= ?AND age &lt;= ?)
        List&lt;User&gt; users = userMapper.selectList(queryWrapper);
        users.forEach(System.out::println);
    &#125;
</code></pre>
<h3 id="4-4-2-思路二"><a href="#4-4-2-思路二" class="headerlink" title="4.4.2 思路二"></a>4.4.2 思路二</h3><p>以使用带condition参数的重载方法构建查询条件，简化代码的编写</p>
<pre><code class="java">    @Test
    public void test08UseCondition() &#123;
        //定义查询条件，有可能为null（用户未输入或未选择）
        String username = null;
        Integer ageBegin = 10;
        Integer ageEnd = 24;
        QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;();
        //StringUtils.isNotBlank()判断某字符串是否不为空且长度不为0且不由空白符(whitespace) 构成
        queryWrapper
                .like(StringUtils.isNotBlank(username), &quot;username&quot;, &quot;a&quot;).ge(ageBegin != null, &quot;age&quot;, ageBegin)
                .le(ageEnd != null, &quot;age&quot;, ageEnd);
        //SELECT id,username AS name,age,email,is_deleted FROM t_user WHERE (age &gt;= ? AND age &lt;= ?)
        List&lt;User&gt; users = userMapper.selectList(queryWrapper);
        users.forEach(System.out::println);
    &#125;
</code></pre>
<h2 id="4-5-LambdaQueryWrapper"><a href="#4-5-LambdaQueryWrapper" class="headerlink" title="4.5 LambdaQueryWrapper"></a>4.5 LambdaQueryWrapper</h2><pre><code class="java">@Test
public void test09() &#123;
    //定义查询条件，有可能为null（用户未输入）
    String username = &quot;a&quot;;
    Integer ageBegin = 10;
    Integer ageEnd = 24;
    LambdaQueryWrapper&lt;User&gt; queryWrapper = new LambdaQueryWrapper&lt;&gt;();
    //避免使用字符串表示字段，防止运行时错误
    queryWrapper
            .like(StringUtils.isNotBlank(username), User::getName, username)
            .ge(ageBegin != null, User::getAge, ageBegin)
            .le(ageEnd != null, User::getAge, ageEnd);
    List&lt;User&gt; users = userMapper.selectList(queryWrapper);
    users.forEach(System.out::println);
&#125;
</code></pre>
<h2 id="4-6-LambdaUpdateWrapper"><a href="#4-6-LambdaUpdateWrapper" class="headerlink" title="4.6 LambdaUpdateWrapper"></a>4.6 LambdaUpdateWrapper</h2><pre><code class="java">@Test
public void test10() &#123;
    //组装set子句
    LambdaUpdateWrapper&lt;User&gt; updateWrapper = new LambdaUpdateWrapper&lt;&gt;();
    updateWrapper
            .set(User::getAge, 18)
            .set(User::getEmail, &quot;user@atguigu.com&quot;)
            .like(User::getName, &quot;a&quot;)
            .and(i -&gt; i.lt(User::getAge, 24).or().isNull(User::getEmail)); //lambda 表达式内的逻辑优先运算
    User user = new User();
    int result = userMapper.update(user, updateWrapper);
    System.out.println(&quot;受影响的行数：&quot; + result);
&#125;
</code></pre>
<h1 id="五、插件"><a href="#五、插件" class="headerlink" title="五、插件"></a>五、插件</h1><h2 id="5-1-分页插件"><a href="#5-1-分页插件" class="headerlink" title="5.1 分页插件"></a>5.1 分页插件</h2><h3 id="5-1-1-添加配置类"><a href="#5-1-1-添加配置类" class="headerlink" title="5.1.1 添加配置类"></a>5.1.1 添加配置类</h3><pre><code class="java">@Configuration
@MapperScan(&quot;com.atguigu.mybatisplus.mapper&quot;) //可以将主类中的注解移到此处
public class MybatisPlusConfig &#123;
    @Bean
    public MybatisPlusInterceptor mybatisPlusInterceptor() &#123;
        MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor();
        interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL));
        return interceptor;
    &#125;
&#125;
</code></pre>
<h3 id="5-1-2-自动分页"><a href="#5-1-2-自动分页" class="headerlink" title="5.1.2 自动分页"></a>5.1.2 自动分页</h3><pre><code class="java">@Test
public void testPage()&#123;
    //设置分页参数
    Page&lt;User&gt; page = new Page&lt;&gt;(1, 5);
    userMapper.selectPage(page, null);
    //获取分页数据
    List&lt;User&gt; list = page.getRecords();
    list.forEach(System.out::println);
    System.out.println(&quot;当前页：&quot;+page.getCurrent());
    System.out.println(&quot;每页显示的条数：&quot;+page.getSize());
    System.out.println(&quot;总记录数：&quot;+page.getTotal());
    System.out.println(&quot;总页数：&quot;+page.getPages());
    System.out.println(&quot;是否有上一页：&quot;+page.hasPrevious());
    System.out.println(&quot;是否有下一页：&quot;+page.hasNext());
&#125;
</code></pre>
<h3 id="5-1-3-xml自定义分页"><a href="#5-1-3-xml自定义分页" class="headerlink" title="5.1.3 xml自定义分页"></a>5.1.3 xml自定义分页</h3><h4 id="①-定义Mapper接口方法"><a href="#①-定义Mapper接口方法" class="headerlink" title="① 定义Mapper接口方法"></a>① 定义Mapper接口方法</h4><pre><code class="java">@Mapper
@Repository
public interface CustomerMapper extends BaseMapper&lt;Customer&gt; &#123;
    IPage&lt;Customer&gt; selectPage(Page&lt;Customer&gt; pageParam,@Param(&quot;vo&quot;) CustomerVo customerVo);
&#125;
</code></pre>
<h4 id="②-定义Mapper映射文件"><a href="#②-定义Mapper映射文件" class="headerlink" title="② 定义Mapper映射文件"></a>② 定义Mapper映射文件</h4><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE mapper
        PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;
        &quot;https://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;
&lt;mapper namespace=&quot;com.bamboo.warehouseerp.mapper.CustomerMapper&quot;&gt;

    &lt;resultMap id=&quot;CustomerMap&quot; type=&quot;com.bamboo.warehouseerp.pojo.Customer&quot; autoMapping=&quot;true&quot;/&gt;

    &lt;sql id=&quot;columns&quot;&gt;
        id,name,receipt_number,commodity_information,bill_date,operator,total_amount,state,create_time,update_time,is_deleted
    &lt;/sql&gt;
    &lt;select id=&quot;selectPage&quot; resultMap=&quot;CustomerMap&quot;&gt;
        select
        &lt;include refid=&quot;columns&quot;/&gt;
        from customer
        &lt;where&gt;
            &lt;if test=&quot;vo.receiptNumber != null and vo.receiptNumber != &#39;&#39;&quot;&gt;
                and receipt_number like CONCAT(&#39;%&#39;,#&#123;vo.receiptNumber&#125;,&#39;%&#39;)
            &lt;/if&gt;
            &lt;if test=&quot;vo.commodityInformation != null and vo.commodityInformation != &#39;&#39;&quot;&gt;
                and commodity_information like CONCAT(&#39;%&#39;,#&#123;vo.commodityInformation&#125;,&#39;%&#39;)
            &lt;/if&gt;
            &lt;if test=&quot;vo.oldDate != null and vo.oldDate != &#39;&#39;&quot;&gt;
                and bill_date &amp;gt;= #&#123;vo.oldDate&#125;
            &lt;/if&gt;
            &lt;if test=&quot;vo.newDate != null and vo.newDate != &#39;&#39;&quot;&gt;
                and bill_date &amp;lt;= #&#123;vo.newDate&#125;
            &lt;/if&gt;
            and is_deleted = 0
        &lt;/where&gt;
        order by id desc
    &lt;/select&gt;
&lt;/mapper&gt;
</code></pre>
<h4 id="③-Service层嵌套mapper"><a href="#③-Service层嵌套mapper" class="headerlink" title="③ Service层嵌套mapper"></a>③ Service层嵌套mapper</h4><pre><code class="java">@Service
public class CustomerServiceImpl extends ServiceImpl&lt;CustomerMapper, Customer&gt; implements CustomerService &#123;
    @Autowired
    private CustomerMapper customerMapper;
    @Override
    public IPage&lt;Customer&gt; selectPage(Page&lt;Customer&gt; pageParam, CustomerVo customerVo) &#123;
        return customerMapper.selectPage(pageParam, customerVo);
    &#125;
&#125;
</code></pre>
<h4 id="④-Controller层调用"><a href="#④-Controller层调用" class="headerlink" title="④ Controller层调用"></a>④ Controller层调用</h4><pre><code class="java">@GetMapping(&quot;&#123;page&#125;/&#123;limit&#125;&quot;)
    public Result getPageList(
            @PathVariable(&quot;page&quot;) Long page,
            @PathVariable(&quot;limit&quot;) Long limit,
            CustomerVo customerVo
    ) &#123;
        Page&lt;Customer&gt; pageParam = new Page&lt;&gt;(page, limit);
        IPage&lt;Customer&gt; pageModel = customerService.selectPage(pageParam, customerVo);
        return Result.ok(pageModel);
    &#125;
</code></pre>
<h2 id="5-2-乐观锁"><a href="#5-2-乐观锁" class="headerlink" title="5.2 乐观锁"></a>5.2 乐观锁</h2><h3 id="5-2-1-乐观锁与悲观锁"><a href="#5-2-1-乐观锁与悲观锁" class="headerlink" title="5.2.1 乐观锁与悲观锁"></a>5.2.1 乐观锁与悲观锁</h3><ul>
<li>乐观锁<ul>
<li>修改数据前会检查数据是否被修改过。如果被修改过了，则重新取出的被修改后的数据</li>
</ul>
</li>
<li>悲观锁<ul>
<li>在一个修改操作彻底结束后才能进行下一次操作，即等待</li>
</ul>
</li>
</ul>
<h3 id="5-2-2-模拟修改冲突"><a href="#5-2-2-模拟修改冲突" class="headerlink" title="5.2.2 模拟修改冲突"></a>5.2.2 模拟修改冲突</h3><p>数据表</p>
<pre><code class="sql">CREATE TABLE t_product
(
id BIGINT(20) NOT NULL COMMENT &#39;主键ID&#39;,
NAME VARCHAR(30) NULL DEFAULT NULL COMMENT &#39;商品名称&#39;,
price INT(11) DEFAULT 0 COMMENT &#39;价格&#39;,
VERSION INT(11) DEFAULT 0 COMMENT &#39;乐观锁版本号&#39;,
PRIMARY KEY (id)
);
</code></pre>
<p>添加数据</p>
<pre><code class="sql">INSERT INTO t_product (id, NAME, price) VALUES (1, &#39;外星人笔记本&#39;, 100);
</code></pre>
<p>添加实体</p>
<pre><code class="java">@Data
public class Product &#123;
    private Long id;
    private String name;
    private Integer price;
    private Integer version;
&#125;
</code></pre>
<p>添加mapper</p>
<pre><code class="java">public interface ProductMapper extends BaseMapper&lt;Product&gt; &#123;
&#125;
</code></pre>
<p>测试</p>
<pre><code class="java">@SpringBootTest
public class ProductTest &#123;

    @Autowired
    private ProductMapper productMapper;

    @Test
    public void testConcurrentUpdate() &#123;
        //1、小李
        Product p1 = productMapper.selectById(1L);
        System.out.println(&quot;小李取出的价格：&quot; + p1.getPrice());
        //2、小王
        Product p2 = productMapper.selectById(1L);
        System.out.println(&quot;小王取出的价格：&quot; + p2.getPrice());
        //3、小李将价格加了50元，存入了数据库
        p1.setPrice(p1.getPrice() + 50);
        int result1 = productMapper.updateById(p1);
        System.out.println(&quot;小李修改结果：&quot; + result1);
        //4、小王将商品减了30元，存入了数据库
        p2.setPrice(p2.getPrice() - 30);
        int result2 = productMapper.updateById(p2);
        System.out.println(&quot;小王修改结果：&quot; + result2);
        //最后的结果
        Product p3 = productMapper.selectById(1L);
        //价格覆盖，最后的结果：70
        System.out.println(&quot;最后的结果：&quot; + p3.getPrice());
    &#125;
&#125;
</code></pre>
<h3 id="5-2-3-乐观锁实现流程"><a href="#5-2-3-乐观锁实现流程" class="headerlink" title="5.2.3 乐观锁实现流程"></a>5.2.3 乐观锁实现流程</h3><ul>
<li><p>数据库中添加version字段，实体类标注解<code>@Version</code></p>
</li>
<li><p>取出记录时，获取当前version</p>
<pre><code class="sql">SELECT id,name,price,version FROM product WHERE id=1
</code></pre>
</li>
<li><p>更新时，version + 1，如果where语句中的version版本不对，则更新失败</p>
<pre><code class="sql">UPDATE product SET price=price+50, version=version + 1 WHERE id=1 AND version=1
</code></pre>
</li>
</ul>
<h3 id="5-2-4-Mybatis-Plus实现乐观锁"><a href="#5-2-4-Mybatis-Plus实现乐观锁" class="headerlink" title="5.2.4 Mybatis-Plus实现乐观锁"></a>5.2.4 Mybatis-Plus实现乐观锁</h3><h4 id="①-实体类标注-Version"><a href="#①-实体类标注-Version" class="headerlink" title="① 实体类标注@Version"></a>① 实体类标注@Version</h4><p>修改实体类</p>
<pre><code class="java">@Data
@TableName(&quot;t_product&quot;)
public class Product &#123;
    private Long id;
    private String name;
    private Integer price;
    @Version
    private Integer version;
&#125;
</code></pre>
<h4 id="②-添加乐观锁插件配置"><a href="#②-添加乐观锁插件配置" class="headerlink" title="② 添加乐观锁插件配置"></a>② 添加乐观锁插件配置</h4><pre><code class="java">@Configuration
public class MybatisPlusConfig &#123;
    @Bean
    public MybatisPlusInterceptor mybatisPlusInterceptor()&#123;
        MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor();
        //添加分页插件
        interceptor.addInnerInterceptor(new
                PaginationInnerInterceptor(DbType.MYSQL));
        //添加乐观锁插件
        interceptor.addInnerInterceptor(new OptimisticLockerInnerInterceptor());
        return interceptor;
    &#125;
&#125;
</code></pre>
<h4 id="③-测试"><a href="#③-测试" class="headerlink" title="③ 测试"></a>③ 测试</h4><pre><code class="java">@Test
public void testConcurrentVersionUpdate() &#123;
    //小李取数据
    Product p1 = productMapper.selectById(1L);
    //小王取数据
    Product p2 = productMapper.selectById(1L);
    //小李修改 + 50
    p1.setPrice(p1.getPrice() + 50);
    int result1 = productMapper.updateById(p1);
    System.out.println(&quot;小李修改的结果：&quot; + result1);
    //小王修改 - 30
    p2.setPrice(p2.getPrice() - 30);
    int result2 = productMapper.updateById(p2);
    System.out.println(&quot;小王修改的结果：&quot; + result2);
    if (result2 == 0) &#123;
    //失败重试，重新获取version并更新
        p2 = productMapper.selectById(1L);
        p2.setPrice(p2.getPrice() - 30);
        result2 = productMapper.updateById(p2);
    &#125;
    System.out.println(&quot;小王修改重试的结果：&quot; + result2);
    //老板看价格
    Product p3 = productMapper.selectById(1L);
    System.out.println(&quot;老板看价格：&quot; + p3.getPrice());
&#125;
</code></pre>
<h1 id="六、通用枚举"><a href="#六、通用枚举" class="headerlink" title="六、通用枚举"></a>六、通用枚举</h1><p>表中的有些字段值是固定的，例如性别（男或女），可以使用MyBatis-Plus的通用枚举来实现</p>
<h2 id="6-1-旧版配置"><a href="#6-1-旧版配置" class="headerlink" title="6.1 旧版配置"></a>6.1 旧版配置</h2><ol>
<li><p>数据库表添加字段sex</p>
<ul>
<li>字段：sex</li>
<li>类型：int</li>
</ul>
</li>
<li><p>创建通用枚举类型</p>
<pre><code class="java">@Getter
public enum SexEnum &#123;
    MALE(1, &quot;男&quot;),
    FEMALE(2, &quot;女&quot;);
    @EnumValue
    private Integer sex;
    private String sexName;

    SexEnum(Integer sex, String sexName) &#123;
        this.sex = sex;
        this.sexName = sexName;
    &#125;
&#125;
</code></pre>
</li>
<li><p>配置扫描通用枚举【3.5.2版本开始弃用】</p>
<pre><code class="java">mybatis-plus:
  type-enums-package: com.bamboo.boot.enums
</code></pre>
</li>
</ol>
<h2 id="6-2-新版配置"><a href="#6-2-新版配置" class="headerlink" title="6.2 新版配置"></a>6.2 新版配置</h2><p>3.5.2版本开始实现一步就可枚举</p>
<h3 id="6-2-1-方式一"><a href="#6-2-1-方式一" class="headerlink" title="6.2.1 方式一"></a>6.2.1 方式一</h3><p><strong>使用 @EnumValue 注解枚举属性</strong></p>
<pre><code class="java">@Getter
public enum SexEnum &#123;
    MALE(1, &quot;男&quot;),
    FEMALE(2, &quot;女&quot;);
    @EnumValue
    private Integer sex;
    private String sexName;

    SexEnum(Integer sex, String sexName) &#123;
        this.sex = sex;
        this.sexName = sexName;
    &#125;
&#125;
</code></pre>
<h3 id="6-2-2-方式二"><a href="#6-2-2-方式二" class="headerlink" title="6.2.2 方式二"></a>6.2.2 方式二</h3><p>枚举属性，实现 IEnum 接口</p>
<pre><code class="java">public enum AgeEnum implements IEnum&lt;Integer&gt; &#123;
    ONE(1, &quot;一岁&quot;),
    TWO(2, &quot;二岁&quot;),
    THREE(3, &quot;三岁&quot;);

    private int value;
    private String desc;

    @Override
    public Integer getValue() &#123;
        return this.value;
    &#125;
&#125;
</code></pre>
<p>实体属性使用枚举类型</p>
<pre><code class="java">public class User &#123;
    /**
     * 名字
     * 数据库字段: name varchar(20)
     */
    private String name;

    /**
     * 年龄，IEnum接口的枚举处理
     * 数据库字段：age INT(3)
     */
    private AgeEnum age;


    /**
     * 年级，原生枚举（带&#123;@link com.baomidou.mybatisplus.annotation.EnumValue&#125;):
     * 数据库字段：grade INT(2)
     */
    private GradeEnum grade;
&#125;
</code></pre>
<h2 id="6-3-测试"><a href="#6-3-测试" class="headerlink" title="6.3 测试"></a>6.3 测试</h2><pre><code class="java">@Test
public void testSexEnum()&#123;
    User user = new User();
    user.setName(&quot;Enum&quot;);
    user.setAge(20);
    //设置性别信息为枚举项，会将@EnumValue注解所标识的属性值存储到数据库
    user.setSex(SexEnum.MALE);
    //INSERT INTO t_user ( username, age, sex ) VALUES ( ?, ?, ? )
    //Parameters: Enum(String), 20(Integer), 1(Integer)
    userMapper.insert(user);
&#125;
</code></pre>
<h1 id="七、代码生成器"><a href="#七、代码生成器" class="headerlink" title="七、代码生成器"></a>七、代码生成器</h1><h2 id="7-1-引入依赖"><a href="#7-1-引入依赖" class="headerlink" title="7.1 引入依赖"></a>7.1 引入依赖</h2><pre><code class="xml">        &lt;dependency&gt;
            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt;
            &lt;version&gt;3.5.1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.freemarker&lt;/groupId&gt;
            &lt;artifactId&gt;freemarker&lt;/artifactId&gt;
            &lt;version&gt;2.3.31&lt;/version&gt;
        &lt;/dependency&gt;
</code></pre>
<h2 id="7-2-快速生成"><a href="#7-2-快速生成" class="headerlink" title="7.2 快速生成"></a>7.2 快速生成</h2><pre><code class="java">public class FastAutoGeneratorTest &#123;
    public static void main(String[] args) &#123;
        FastAutoGenerator.create(&quot;jdbc:mysql://127.0.0.1:3306/mybatis_plus?characterEncoding=utf-8&amp;&amp;userSSL=false&quot;, &quot; root&quot;, &quot;root&quot;)
                        .globalConfig(builder -&gt; &#123;
                            builder.author(&quot;bamboo&quot;) // 设置作者
                                    //.enableSwagger() // 开启 swagger 模式
                                    .fileOverride() // 覆盖已生成文件
                                    .outputDir(&quot;D://mybatis_plus&quot;); // 指定输出目录
                        &#125;)
                        .packageConfig(builder -&gt; &#123;
                            builder.parent(&quot;com.bamboo&quot;) // 设置父包名
                                    .moduleName(&quot;mybatisplus&quot;) // 设置父包模块名
                                    .pathInfo(Collections.singletonMap(OutputFile.mapperXml, &quot;D://mybatis_plus&quot;)); // 设置mapperXml生成路径
                        &#125;)
                        .strategyConfig(builder -&gt; &#123;
                            builder.addInclude(&quot;tbl_user&quot;) // 设置需要生成的表名
                                    .addTablePrefix(&quot;tbl_&quot;, &quot;c_&quot;); // 设置过滤表前缀：通俗易懂来说就是去掉生成pojo的前缀名，和上述addInclude对应即可
                        &#125;)
                        .templateEngine(new FreemarkerTemplateEngine()) // 使用Freemarker引擎模板，默认的是Velocity引擎模板
                        .execute();
    &#125;

&#125;
</code></pre>
<h1 id="八、多数据源"><a href="#八、多数据源" class="headerlink" title="八、多数据源"></a>八、多数据源</h1><p>适用于多种场景：纯粹多库、 读写分离、 一主多从、 混合模式等</p>
<p>模拟一个纯粹多库的一个场景，其他场景类似：</p>
<ul>
<li>我们创建两个库，分别为：mybatis_plus（以前的库不动）与mybatis_plus_1（新建）</li>
<li>将mybatis_plus库的product表移动到mybatis_plus_1库</li>
<li>每个库一张表，通过一个测试用例分别获取用户数据与商品数据，如果获取到说明多库模拟成功</li>
</ul>
<h2 id="8-1-创建数据库及表"><a href="#8-1-创建数据库及表" class="headerlink" title="8.1 创建数据库及表"></a>8.1 创建数据库及表</h2><p>创建数据库mybatis_plus_1和表product</p>
<ul>
<li>复制数据库mybatis_plus的表product到第二个数据库中</li>
<li>将mybatis_plus数据库中的product表删除</li>
<li>两个数据库一人一个不同的表</li>
</ul>
<h2 id="8-2-引入依赖"><a href="#8-2-引入依赖" class="headerlink" title="8.2 引入依赖"></a>8.2 引入依赖</h2><pre><code class="xml">        &lt;dependency&gt;
            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
            &lt;artifactId&gt;dynamic-datasource-spring-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;3.5.0&lt;/version&gt;
        &lt;/dependency&gt;
</code></pre>
<h2 id="8-3-配置多数据源"><a href="#8-3-配置多数据源" class="headerlink" title="8.3 配置多数据源"></a>8.3 配置多数据源</h2><blockquote>
<p>说明：注释掉之前的数据库连接，添加新配置</p>
</blockquote>
<pre><code class="yml">spring:
  # 配置数据源信息
  datasource:
    dynamic:
      # 设置默认的数据源或者数据源组,默认值即为master
      primary: master
      # 严格匹配数据源,默认false,true未匹配到指定数据源时抛异常,false使用默认数据源
      strict: false
      datasource:
        master:
          url: jdbc:mysql://localhost:3306/mybatis_plus?characterEncoding=utf8&amp;useSSL=false
          driver-class-name: com.mysql.cj.jdbc.Driver
          username: root
          password: root
        slave_1:
          url: jdbc:mysql://localhost:3306/mybatis_plus_1?characterEncoding=utf8&amp;useSSL=false
          driver-class-name: com.mysql.cj.jdbc.Driver
          username: root
          password: root
</code></pre>
<h2 id="8-4-创建用户和商品的service"><a href="#8-4-创建用户和商品的service" class="headerlink" title="8.4 创建用户和商品的service"></a>8.4 创建用户和商品的service</h2><p>用户service</p>
<pre><code class="java">@DS(&quot;master&quot;) //指定所操作的数据源
@Service
public class UserServiceImpl extends ServiceImpl&lt;UserMapper, User&gt; implements UserService &#123;
&#125;
</code></pre>
<p>商品service</p>
<pre><code class="java">@DS(&quot;slave_1&quot;)
@Service
public class ProductServiceImpl extends ServiceImpl&lt;ProductMapper, Product&gt; implements ProductService &#123;
&#125;
</code></pre>
<h2 id="8-5-测试"><a href="#8-5-测试" class="headerlink" title="8.5 测试"></a>8.5 测试</h2><pre><code class="java">@SpringBootTest
class MainApplicationTests &#123;

    @Autowired
    private ProductService productService;

    @Autowired
    private UserService userService;

    @Test
    void contextLoads() &#123;
        System.out.println(userService.getById(1L));
        System.out.println(productService.getById(1L));
    &#125;

&#125;
</code></pre>

            
        </div>
    </div>
    <div class="post-tags">
        
        
        
    </div>
    <a href="/2023/08/30/mybatis-plus/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/08/30/springcloud/">
        <h2 class="post-title">springcloud</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/8/30
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <p>[TOC]</p>
<h1 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h1><h2 id="1-1-微服务技术对比"><a href="#1-1-微服务技术对比" class="headerlink" title="1.1. 微服务技术对比"></a>1.1. 微服务技术对比</h2><h3 id="1-1-1-SpringCloud-Feign"><a href="#1-1-1-SpringCloud-Feign" class="headerlink" title="1.1.1 SpringCloud + Feign"></a>1.1.1 SpringCloud + Feign</h3><ul>
<li>使用SpringCloud技术栈</li>
<li>服务接口采用Restful风格</li>
<li>服务调用采用Feign方式</li>
</ul>
<h3 id="1-1-2-SpringCloudAlibaba-Feign"><a href="#1-1-2-SpringCloudAlibaba-Feign" class="headerlink" title="1.1.2 SpringCloudAlibaba + Feign"></a>1.1.2 SpringCloudAlibaba + Feign</h3><ul>
<li>使用SpringCloudAlibaba技术栈</li>
<li>服务接口采用Restful风格</li>
<li>服务调用采用Feign方式</li>
</ul>
<h3 id="1-1-3-SpringCloudAlibaba-Dubbo"><a href="#1-1-3-SpringCloudAlibaba-Dubbo" class="headerlink" title="1.1.3 SpringCloudAlibaba + Dubbo"></a>1.1.3 SpringCloudAlibaba + Dubbo</h3><ul>
<li>使用SpringCloudAlibaba技术栈</li>
<li>服务接口采用Dubbo协议标准</li>
<li>服务调用采用Dubbo方式</li>
</ul>
<h3 id="1-1-4-Dubbo原始模式"><a href="#1-1-4-Dubbo原始模式" class="headerlink" title="1.1.4 Dubbo原始模式"></a>1.1.4 Dubbo原始模式</h3><ul>
<li>局域Dubbo老旧技术体系</li>
<li>服务接口采用Dubbo协议标准</li>
<li>服务调用采用Dubbo方式</li>
<li>可升级为SpringCloudAlibaba + Dubbo</li>
</ul>
<p><strong>注册中心</strong>：Eureka、Nacos，内部都由Ribbon作负载均衡</p>
<h2 id="1-2-微服务框架"><a href="#1-2-微服务框架" class="headerlink" title="1.2. 微服务框架"></a>1.2. 微服务框架</h2><ol>
<li>微服务治理：二~七</li>
<li>Docker：八</li>
<li>异步通信：九</li>
<li>分布式搜索：十</li>
<li>微服务保护：十一</li>
<li>分布式事务：十二</li>
<li>多级缓存：十三</li>
<li>分布式缓存：十四</li>
<li>可靠消息服务：十五</li>
</ol>
<h1 id="二、远程调用"><a href="#二、远程调用" class="headerlink" title="二、远程调用"></a>二、远程调用</h1><h2 id="2-1-服务拆分"><a href="#2-1-服务拆分" class="headerlink" title="2.1. 服务拆分"></a>2.1. 服务拆分</h2><ol>
<li>根据业务模块拆分，做到单依职责，不重复开发相同业务</li>
<li>可以将业务暴露为借口，供其他微服务使用</li>
<li>不同为服务都应该有自己独立的数据库</li>
</ol>
<h2 id="2-2-RestTemplate"><a href="#2-2-RestTemplate" class="headerlink" title="2.2. RestTemplate"></a>2.2. RestTemplate</h2><ul>
<li>由于微服务拆分，各项功能对外暴露REST的api接口，使用RestTemplate进行对REST接口的请求</li>
<li>将RestTemplate注册到Spring容器中</li>
</ul>
<pre><code>@MapperScan(&quot;cn.itcast.order.mapper&quot;)
@SpringBootApplication
public class OrderApplication &#123;

    public static void main(String[] args) &#123;
        SpringApplication.run(OrderApplication.class, args);
    &#125;

    /**
     * 创建RestTemplate并注入到Spring容器
     * @return
     */
    @Bean
    public RestTemplate restTemplate() &#123;
        return new RestTemplate();
    &#125;

&#125;
</code></pre>
<h2 id="2-3-测试接口"><a href="#2-3-测试接口" class="headerlink" title="2.3. 测试接口"></a>2.3. 测试接口</h2><p>接口地址1：<a target="_blank" rel="noopener" href="http://localhost:8081/user/1">http://localhost:8081/user/1</a></p>
<p>返回对象：</p>
<pre><code>&#123;
  &quot;id&quot;: 101,
  &quot;price&quot;: 699900,
  &quot;name&quot;: &quot;Apple 苹果 iPhone 12 &quot;,
  &quot;num&quot;: 1,
  &quot;userId&quot;: 1,
  &quot;user&quot;: null
&#125;
</code></pre>
<p>接口地址2：<a target="_blank" rel="noopener" href="http://localhost:8081/user/1">http://localhost:8081/user/1</a></p>
<p>返回对象：</p>
<pre><code class="json">&#123;
  &quot;id&quot;: 1,
  &quot;username&quot;: &quot;柳岩&quot;,
  &quot;address&quot;: &quot;湖南省衡阳市&quot;
&#125;
</code></pre>
<h2 id="2-4-远程调用应用"><a href="#2-4-远程调用应用" class="headerlink" title="2.4. 远程调用应用"></a>2.4. 远程调用应用</h2><p><strong>①注入RestTemplate</strong></p>
<pre><code class="java">@MapperScan(&quot;cn.itcast.order.mapper&quot;)
@SpringBootApplication
public class OrderApplication &#123;

    public static void main(String[] args) &#123;
        SpringApplication.run(OrderApplication.class, args);
    &#125;

    /**
     * 创建RestTemplate并注入到Spring容器
     * @return
     */
    @Bean
    public RestTemplate restTemplate() &#123;
        return new RestTemplate();
    &#125;

&#125;
</code></pre>
<p><strong>②增加业务代码</strong></p>
<pre><code>@Service
public class OrderService &#123;

    @Autowired
    private OrderMapper orderMapper;

    // 注入RestTemplate
    @Autowired
    private RestTemplate restTemplate;

    public Order queryOrderById(Long orderId) &#123;
        // 1.查询订单
        Order order = orderMapper.findById(orderId);
        // 2.利用RestTemplate发起http请求，查询用户
        // 2.1url路径
        String url = &quot;http://localhost:8081/user/&quot; + order.getUserId();
        // 2.2发哦是哪个http请求，实现远程调用
        User user = restTemplate.getForObject(url, User.class);
        // 3.封装User到Order
        order.setUser(user);
        // 4.返回
        return order;
    &#125;
&#125;
</code></pre>
<p><strong>③实现效果</strong></p>
<pre><code>&#123;
  &quot;id&quot;: 101,
  &quot;price&quot;: 699900,
  &quot;name&quot;: &quot;Apple 苹果 iPhone 12 &quot;,
  &quot;num&quot;: 1,
  &quot;userId&quot;: 1,
  &quot;user&quot;: &#123;
    &quot;id&quot;: 1,
    &quot;username&quot;: &quot;柳岩&quot;,
    &quot;address&quot;: &quot;湖南省衡阳市&quot;
  &#125;
&#125;
</code></pre>
<h2 id="2-5-服务调用关系"><a href="#2-5-服务调用关系" class="headerlink" title="2.5. 服务调用关系"></a>2.5. 服务调用关系</h2><ul>
<li>Provider服务提供者：暴露接口给其他微服务调用</li>
<li>Consumer服务消费者：调用其他微服务提供的接口</li>
<li>提供者与消费者角色其实是<strong>相对</strong>的</li>
<li>一个服务可以同时是服务提供者和服务消费者</li>
</ul>
<h1 id="三、Eureka注册中心"><a href="#三、Eureka注册中心" class="headerlink" title="三、Eureka注册中心"></a>三、Eureka注册中心</h1><ul>
<li>服务调用出现的问题：硬编码 “<a target="_blank" rel="noopener" href="http://localhost:8081/user/">http://localhost:8081/user/</a>“ + order.getUserId()</li>
<li>负载均衡时<ul>
<li>服务消费者如何获取服务提供者的地址信息</li>
<li>多个服务提供者，消费者怎样选择</li>
<li>消费者如何得知服务提供者的健康状态</li>
</ul>
</li>
</ul>
<h2 id="3-1-作用"><a href="#3-1-作用" class="headerlink" title="3.1. 作用"></a>3.1. 作用</h2><p>Eureka分为两个模块：</p>
<ul>
<li><p>eureka-server注册中心</p>
<ul>
<li><p>保存eureka-client发送过来的信息，以供服务消费者调用</p>
</li>
<li><p>例如：</p>
<pre><code>user-service:
    localhost:8081
    localhost:8082
order-service:
    localhost:8080
</code></pre>
</li>
</ul>
</li>
<li><p>eureka-client</p>
<ul>
<li>服务消费者和服务提供者都在client中</li>
<li>服务消费者和多个服务提供者的信息被注册到eureka-server中</li>
<li>每隔30秒eureka-client会对eureka-server进行一次心跳续约，保证服务提供者没有宕掉</li>
</ul>
</li>
</ul>
<p>执行顺序：</p>
<ol>
<li>注册服务信息：eureka-client中的服务消费者和服务提供者向eureka-server注册中心发送信息</li>
<li>拉取服务【定时拉取服务pull 30s&#x2F;次】：服务消费者去拉取eureka-server注册中心中的服务提供者信息</li>
<li>负载均衡：服务消费者去选择调用服务提供者的服务器</li>
<li>远程调用</li>
<li>心跳续约：eureka-client每过30秒刷新一次</li>
</ol>
<ul>
<li>消费者获取提供者具体信息<ul>
<li>服务提供者启动时向eureka注册自己的信息</li>
<li>eureka保存这些信息</li>
<li>消费者根据服务名称向eureka拉取提供者信息</li>
</ul>
</li>
<li>多个服务提供者时消费者的选择<ul>
<li>服务消费者利用负载均衡算法从服务列表中挑选一个</li>
</ul>
</li>
<li>消费者感知服务提供者健康状态<ul>
<li>服务提供者每隔30秒向EurekaServer发送心跳请求，报告健康状态</li>
<li>eureka会更新记录服务列表信息，心跳不正常被剔除</li>
<li>消费者可以拉取到最新的信息</li>
</ul>
</li>
</ul>
<h2 id="3-2-搭建EurekaServer服务"><a href="#3-2-搭建EurekaServer服务" class="headerlink" title="3.2. 搭建EurekaServer服务"></a>3.2. 搭建EurekaServer服务</h2><ol>
<li><p>创建eureka-server项目并引入依赖</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
</li>
<li><p>编写启动类，添加@EnableEurekaServer注解</p>
<pre><code class="java">@EnableEurekaServer
@SpringBootApplication
public class EurekaApplication &#123;
    public static void main(String[] args) &#123;
        SpringApplication.run(EurekaApplication.class, args);
    &#125;
&#125;
</code></pre>
</li>
<li><p>添加applicaiton.yml文件编写配置</p>
<pre><code class="yaml">server:
  port: 10086 # 服务端口
spring:
  application:
    name: eurekaserver # eureka服务名称
eureka:
  client:
    service-url: # eureka地址信息：将自己也注册进eureka,后续多个eureka,集群使用
      defaultZone: http://127.0.0.1:10086/eureka
</code></pre>
</li>
</ol>
<h2 id="3-3-eureka服务注册"><a href="#3-3-eureka服务注册" class="headerlink" title="3.3. eureka服务注册"></a>3.3. eureka服务注册</h2><ol>
<li><p>服务提供者模块添加依赖</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
</li>
<li><p>服务提供者模块添加yml配置eureka地址</p>
<pre><code class="yml">spring:
  application:
    name: userservice # eureka服务名称
eureka:
  client:
    service-url: # eureka地址信息：将自己也注册进eureka,后续多个eureka,集群使用
      defaultZone: http://127.0.0.1:10086/eureka
</code></pre>
</li>
<li><p>让某一服务多次启动</p>
<ol>
<li>在IDEA的Service中，右键已经启动的服务</li>
<li>选择Copy Configuration… 或Ctrl+D</li>
<li>修改VMoptions: -Dserver.port&#x3D;8082</li>
<li>如果找不到VMoptions，则选择Modify options选择Add VM Options</li>
<li>效果：** UP** (2) - <a target="_blank" rel="noopener" href="http://192.168.209.1:8082/actuator/info">192.168.209.1:userservice:8082</a> , <a target="_blank" rel="noopener" href="http://192.168.209.1:8081/actuator/info">192.168.209.1:userservice:8081</a></li>
</ol>
</li>
</ol>
<h2 id="3-4-服务拉取"><a href="#3-4-服务拉取" class="headerlink" title="3.4. 服务拉取"></a>3.4. 服务拉取</h2><ol>
<li><p>修改Service代码，修改访问的url路径，用服务名代替ip、端口</p>
<pre><code class="java">@Service
public class OrderService &#123;

    @Autowired
    private OrderMapper orderMapper;

    @Autowired
    private RestTemplate restTemplate;

    public Order queryOrderById(Long orderId) &#123;
        // 1.查询订单
        Order order = orderMapper.findById(orderId);
        // 2.利用RestTemplate发起http请求，查询用户
        // 2.1url路径
        String url = &quot;http://userservice/user/&quot; + order.getUserId();
        // 2.2发哦是哪个http请求，实现远程调用
        User user = restTemplate.getForObject(url, User.class);
        // 3.封装User到Order
        order.setUser(user);
        // 4.返回
        return order;
    &#125;
&#125;
</code></pre>
</li>
<li><p>在项目启动类注册的RestTemplate添加负载均衡注解：@LoadBalanced</p>
<pre><code class="java">@MapperScan(&quot;cn.itcast.order.mapper&quot;)
@SpringBootApplication
public class OrderApplication &#123;

    public static void main(String[] args) &#123;
        SpringApplication.run(OrderApplication.class, args);
    &#125;

    /**
     * 创建RestTemplate并注入到Spring容器
     * @return
     */
    @Bean
    @LoadBalanced
    public RestTemplate restTemplate() &#123;
        return new RestTemplate();
    &#125;

&#125;
</code></pre>
</li>
</ol>
<h1 id="四、Ribbon负载均衡"><a href="#四、Ribbon负载均衡" class="headerlink" title="四、Ribbon负载均衡"></a>四、Ribbon负载均衡</h1><h2 id="4-1-负载均衡流程"><a href="#4-1-负载均衡流程" class="headerlink" title="4.1. 负载均衡流程"></a>4.1. 负载均衡流程</h2><ol>
<li>服务消费者order-service发起请求<ul>
<li><a target="_blank" rel="noopener" href="http://userservice/user/1">http://userservice/user/1</a></li>
<li>此地址不是一个可以访问的地址</li>
</ul>
</li>
<li>Ribbon负载均衡作用<ul>
<li>接收服务消费者发来的请求地址<a target="_blank" rel="noopener" href="http://userservice/user/1">http://userservice/user/1</a></li>
<li>拉取eureka-server中的userservice</li>
</ul>
</li>
<li>eureka-server给Ribbon返回服务列表<ul>
<li>localhost:8081</li>
<li>localhost:8082</li>
</ul>
</li>
<li>Ribbon对服务器进行负载均衡<ul>
<li>轮询到8081实现访问</li>
<li>轮询操作：一个服务器访问完换下一个服务器</li>
</ul>
</li>
</ol>
<ul>
<li>@LoadBalanced原理<ul>
<li>被LoadBalancerInterceptor.java拦截</li>
</ul>
</li>
</ul>
<h2 id="4-2-负载均衡策略定义"><a href="#4-2-负载均衡策略定义" class="headerlink" title="4.2. 负载均衡策略定义"></a>4.2. 负载均衡策略定义</h2><h3 id="4-2-1-代码方式"><a href="#4-2-1-代码方式" class="headerlink" title="4.2.1 代码方式"></a>4.2.1 代码方式</h3><p>启动类中添加IRule的实现类为@Bean</p>
<pre><code class="java">@MapperScan(&quot;cn.itcast.order.mapper&quot;)
@SpringBootApplication
public class OrderApplication &#123;

    public static void main(String[] args) &#123;
        SpringApplication.run(OrderApplication.class, args);
    &#125;

    /**
     * 创建RestTemplate并注入到Spring容器
     * @return
     */
    @Bean
    @LoadBalanced
    public RestTemplate restTemplate() &#123;
        return new RestTemplate();
    &#125;

    @Bean
    public IRule randomRule() &#123;
        return new RandomRule();
    &#125;

&#125;
</code></pre>
<h3 id="4-2-2-配置文件方式"><a href="#4-2-2-配置文件方式" class="headerlink" title="4.2.2 配置文件方式"></a>4.2.2 配置文件方式</h3><p>yml配置</p>
<pre><code class="yml">userservice: # Eureka服务名
  ribbon:
    NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 负载均衡规则
</code></pre>
<h2 id="4-3-Ribbon饥饿加载"><a href="#4-3-Ribbon饥饿加载" class="headerlink" title="4.3. Ribbon饥饿加载"></a>4.3. Ribbon饥饿加载</h2><p>Ribbon默认采用懒加载，即第一次访问时创建LoadBalanceClient，请求时间会很长</p>
<p>饥饿加载会在项目启动时创建，降低第一次访问的耗时</p>
<p>yml配置</p>
<pre><code class="yml">ribbon:
  eager-load:
    clients: userservice # 指定对userservice这个服务饥饿加载
    enabled: true # 开启饥饿加载
    
    # clients: # 指定对多个服务提供者饥饿加载，数组形式
    #	- userservice
    # 	- xxservice
</code></pre>
<h1 id="五、Nacos注册中心"><a href="#五、Nacos注册中心" class="headerlink" title="五、Nacos注册中心"></a>五、Nacos注册中心</h1><p><strong>认识Nacos</strong>：Nacos是阿里巴巴的产品，现在是SpringCloud中的一个组件，相比于Eureka功能更加丰富</p>
<h2 id="5-1-Nacos安装指南"><a href="#5-1-Nacos安装指南" class="headerlink" title="5.1. Nacos安装指南"></a>5.1. Nacos安装指南</h2><p><strong>登录默认账号密码都是nacos</strong></p>
<h3 id="5-1-1-Windows安装"><a href="#5-1-1-Windows安装" class="headerlink" title="5.1.1 Windows安装"></a>5.1.1 Windows安装</h3><p>开发阶段采用单机安装即可。</p>
<p><strong>①下载安装包</strong></p>
<p>在Nacos的GitHub页面，提供有下载链接，可以下载编译好的Nacos服务端或者源代码：</p>
<p>GitHub主页：<a target="_blank" rel="noopener" href="https://github.com/alibaba/nacos">https://github.com/alibaba/nacos</a></p>
<p>GitHub的Release下载页：<a target="_blank" rel="noopener" href="https://github.com/alibaba/nacos/releases">https://github.com/alibaba/nacos/releases</a></p>
<p><strong>②解压</strong></p>
<p>目录说明：</p>
<ul>
<li>bin：启动脚本</li>
<li>conf：配置文件</li>
</ul>
<p><strong>③端口配置</strong></p>
<p>Nacos的默认端口是8848，如果你电脑上的其它进程占用了8848端口，请先尝试关闭该进程。</p>
<p><strong>如果无法关闭占用8848端口的进程</strong>，也可以进入nacos的conf目录，修改配置文件中的端口：</p>
<p>application.properties</p>
<p><strong>④启动</strong></p>
<p>启动非常简单，进入bin目录，然后执行命令即可：</p>
<ul>
<li><p>windows命令：</p>
<pre><code>startup.cmd -m standalone
</code></pre>
</li>
</ul>
<p><strong>⑤访问</strong></p>
<p>在浏览器输入地址：<a target="_blank" rel="noopener" href="http://127.0.0.1:8848/nacos%E5%8D%B3%E5%8F%AF">http://127.0.0.1:8848/nacos即可</a></p>
<h3 id="5-1-2-Linux安装"><a href="#5-1-2-Linux安装" class="headerlink" title="5.1.2 Linux安装"></a>5.1.2 Linux安装</h3><p>Linux或者Mac安装方式与Windows类似。</p>
<p><strong>①安装JDK</strong></p>
<p>Nacos依赖于JDK运行，索引Linux上也需要安装JDK才行。</p>
<p>上传jdk安装包：</p>
<p>上传jdk-8u144-linux-x64.tar.gz到某个目录，例如：<code>/usr/local/</code></p>
<p>然后解压缩：</p>
<pre><code class="sh">tar -xvf jdk-8u144-linux-x64.tar.gz
</code></pre>
<p>然后重命名为java</p>
<p>配置环境变量：</p>
<pre><code class="sh">export JAVA_HOME=/usr/local/java
export PATH=$PATH:$JAVA_HOME/bin
</code></pre>
<p>设置环境变量：</p>
<pre><code class="sh">source /etc/profile
</code></pre>
<p><strong>②上传安装包</strong></p>
<p>上传nacos-server-1.4.1.tar.gz到Linux服务器的某个目录，例如<code>/usr/local/src</code>目录下</p>
<p><strong>③解压</strong></p>
<p>命令解压缩安装包：</p>
<pre><code class="sh">tar -xvf nacos-server-1.4.1.tar.gz
</code></pre>
<p>然后删除安装包：</p>
<pre><code class="sh">rm -rf nacos-server-1.4.1.tar.gz
</code></pre>
<p><strong>④端口配置</strong></p>
<p>与windows中类似</p>
<p><strong>⑤启动</strong></p>
<p>在nacos&#x2F;bin目录中，输入命令启动Nacos：</p>
<pre><code class="sh">sh startup.sh -m standalone
</code></pre>
<h3 id="5-1-3-Nacos的依赖"><a href="#5-1-3-Nacos的依赖" class="headerlink" title="5.1.3 Nacos的依赖"></a>5.1.3 Nacos的依赖</h3><p>父工程：</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt;
    &lt;version&gt;2.2.5.RELEASE&lt;/version&gt;
    &lt;type&gt;pom&lt;/type&gt;
    &lt;scope&gt;import&lt;/scope&gt;
&lt;/dependency&gt;
</code></pre>
<p>客户端：</p>
<pre><code class="xml">&lt;!-- nacos客户端依赖包 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<h2 id="5-2-使用Nacos"><a href="#5-2-使用Nacos" class="headerlink" title="5.2. 使用Nacos"></a>5.2. 使用Nacos</h2><p><strong>①父工程引入依赖</strong></p>
<p>这个依赖声明会将 <code>spring-cloud-alibaba-dependencies</code> 添加到项目的依赖管理器中，从而可以方便地管理 Spring Cloud Alibaba 组件的版本。</p>
<pre><code class="xml">&lt;dependencyManagement&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt;
            &lt;version&gt;2.2.5.RELEASE&lt;/version&gt;
            &lt;type&gt;pom&lt;/type&gt;
            &lt;scope&gt;import&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/dependencyManagement&gt;
</code></pre>
<p><strong>②所有的Provider和Consumer引入依赖</strong></p>
<pre><code class="xml">&lt;!-- nacos客户端依赖包 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p><strong>③配置application.yml</strong></p>
<pre><code class="yml">spring:
  application:
    name: userservice # eureka/nacos服务名称
  cloud:
    nacos:
      server-addr: localhost:8848 # nacos服务端地址
</code></pre>
<h2 id="5-3-nacos服务分级存储模型"><a href="#5-3-nacos服务分级存储模型" class="headerlink" title="5.3. nacos服务分级存储模型"></a>5.3. nacos服务分级存储模型</h2><h3 id="5-3-1-集群概念"><a href="#5-3-1-集群概念" class="headerlink" title="5.3.1 集群概念"></a>5.3.1 集群概念</h3><p>①一级是服务，例如userservice</p>
<p>②二级是集群，例如杭州或上海</p>
<p>③三级是服务实例，例如杭州机房的某台部署了userservice的服务器</p>
<ul>
<li>nacos<ul>
<li>HZ集群<ul>
<li>userservice1</li>
<li>userservice2</li>
</ul>
</li>
<li>SH集群<ul>
<li>userservice1</li>
<li>userservice2</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="5-3-2-配置集群"><a href="#5-3-2-配置集群" class="headerlink" title="5.3.2 配置集群"></a>5.3.2 配置集群</h3><pre><code class="yml"># Consumer和Provider服务都进行设置集群
spring:
  application:
    name: userservice # eureka服务名称
  cloud:
    nacos:
      server-addr: localhost:8848 # nacos服务端地址
      discovery:
        cluster-name: HZ # 集群名称，这里HZ代指杭州，可自定义
</code></pre>
<p>注：Consumer会优先调用相同集群区域的Provider</p>
<h3 id="5-3-3-配置集群负载均衡"><a href="#5-3-3-配置集群负载均衡" class="headerlink" title="5.3.3 配置集群负载均衡"></a>5.3.3 配置集群负载均衡</h3><pre><code class="yml"># Consumer消费者服务设置
userservice: # Eureka服务名
  ribbon:
    NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule # 负载均衡规则
</code></pre>
<h3 id="5-3-4-跨集群查询"><a href="#5-3-4-跨集群查询" class="headerlink" title="5.3.4 跨集群查询"></a>5.3.4 跨集群查询</h3><p>当前Consumer调用的Provider无法在相同集群中找到时，会去查找其他集群，同时在Consumer日志中报如下警告</p>
<pre><code class="bash">07-17 22:57:28:729  WARN 16336 --- [nio-8080-exec-5] c.alibaba.cloud.nacos.ribbon.NacosRule   : A cross-cluster call occurs，name = userservice, clusterName = HZ, instance = [Instance&#123;instanceId=&#39;192.168.209.1#8083#SH#DEFAULT_GROUP@@userservice&#39;, ip=&#39;192.168.209.1&#39;, port=8083, weight=1.0, healthy=true, enabled=true, ephemeral=true, clusterName=&#39;SH&#39;, serviceName=&#39;DEFAULT_GROUP@@userservice&#39;, metadata=&#123;preserved.register.source=SPRING_CLOUD&#125;&#125;]
</code></pre>
<h2 id="5-4-根据权重负载均衡"><a href="#5-4-根据权重负载均衡" class="headerlink" title="5.4. 根据权重负载均衡"></a>5.4. 根据权重负载均衡</h2><ul>
<li>服务器设备性能有所差异，部分实例所在机器性能好一些，另一些较差</li>
<li>Nacos提供了权重配置来控制访问频率，权重越大访问频率越高</li>
<li>权重值：[0,1]<ul>
<li>权重为0时，不会访问此服务</li>
</ul>
</li>
</ul>
<p><strong>设置权重</strong></p>
<ul>
<li>打开Nacos本地服务的网站Console: <a target="_blank" rel="noopener" href="http://192.168.209.1:8848/nacos/index.html">http://192.168.209.1:8848/nacos/index.html</a></li>
<li>服务管理-&gt;服务列表-&gt;设置权重</li>
</ul>
<h2 id="5-5-环境隔离-namespace"><a href="#5-5-环境隔离-namespace" class="headerlink" title="5.5. 环境隔离-namespace"></a>5.5. 环境隔离-namespace</h2><p>Nacos中服务存储和数据存储的最外层都是一个名为namespace的东西，用来做最外层隔离</p>
<p>如果想让服务之间可以相互调用，放到同一个环境下，否则访问不到各自的环境</p>
<ul>
<li>Namespace<ul>
<li>Group<ul>
<li>Service&#x2F;Data</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>创建环境隔离[命名空间] - namespace</strong></p>
<ol>
<li><p>Nacos本地服务地址中配置：<a target="_blank" rel="noopener" href="http://192.168.209.1:8848/nacos/index.html">http://192.168.209.1:8848/nacos/index.html</a></p>
</li>
<li><p>找到命名空间</p>
</li>
<li><p>新建命名空间，设置命名空间和描述</p>
</li>
<li><p>拿到自动生成的命名空间id</p>
</li>
<li><p>在application.yml中进行配置命名空间</p>
<pre><code class="yml">spring:

  application:
    name: orderservice
  cloud:
    nacos:
      server-addr: localhost:8848 #nacos服务端地址
      discovery:
        cluster-name: HZ # 集群配置
        # 命名空间配置
        namespace: bfeb4944-eeb0-4f6e-952a-f290298c9654 # dev环境
</code></pre>
</li>
</ol>
<p><strong>总结</strong></p>
<ul>
<li>namespace用来做环境隔离</li>
<li>每个namespace都有唯一Id</li>
<li>不同namespace下的服务不可见</li>
</ul>
<h2 id="5-6-Nacos注册中心细节"><a href="#5-6-Nacos注册中心细节" class="headerlink" title="5.6. Nacos注册中心细节"></a>5.6. Nacos注册中心细节</h2><ul>
<li>Eureka对Consumer服务消费者只有定时拉取服务pull的功能</li>
<li>Eureka对Provider服务提供者只有心跳监测</li>
<li>Eureka集群采用AP方式</li>
</ul>
<h3 id="5-6-1-服务消费者Consumer"><a href="#5-6-1-服务消费者Consumer" class="headerlink" title="5.6.1 服务消费者Consumer"></a>5.6.1 服务消费者Consumer</h3><ul>
<li>Consumer服务消费者定时拉取服务pull,30s&#x2F;次</li>
<li>nacos主动推送变更消息push</li>
</ul>
<h3 id="5-6-2-服务提供者Provider"><a href="#5-6-2-服务提供者Provider" class="headerlink" title="5.6.2 服务提供者Provider"></a>5.6.2 服务提供者Provider</h3><ul>
<li>临时实例：采用与Eureka相同的心跳监测</li>
<li>非临时实例：Nacos主动询问，当此实例挂掉后，Nacos并<strong>不会</strong>从实例中<strong>剔除</strong></li>
</ul>
<h3 id="5-6-3-Nacos集群"><a href="#5-6-3-Nacos集群" class="headerlink" title="5.6.3 Nacos集群"></a>5.6.3 Nacos集群</h3><ul>
<li>Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式</li>
</ul>
<p><strong>配置非临时实例</strong></p>
<pre><code class="yml">spring:
  application:
    name: orderservice
  cloud:
    nacos:
      server-addr: localhost:8848,localhost:8849,localhost:8847 #nacos服务端地址
      discovery:
        cluster-name: HZ # 集群配置
        namespace: bfeb4944-eeb0-4f6e-952a-f290298c9654 # dev环境
        ephemeral: false # 永久实例配置
</code></pre>
<h2 id="5-7-Nacos配置管理"><a href="#5-7-Nacos配置管理" class="headerlink" title="5.7. Nacos配置管理"></a>5.7. Nacos配置管理</h2><h3 id="5-7-1-统一配置管理"><a href="#5-7-1-统一配置管理" class="headerlink" title="5.7.1 统一配置管理"></a>5.7.1 统一配置管理</h3><ol>
<li><p>启动Nacos进入管理页面</p>
</li>
<li><p>选择配置管理-&gt;配置列表-&gt;命名空间-&gt;新建</p>
</li>
<li><p>设置Data ID : userservice-dev.yaml</p>
</li>
<li><p>设置Group : 默认即可</p>
</li>
<li><p>添加描述</p>
</li>
<li><p>选择配置格式： yaml和properties</p>
</li>
<li><p>填写配置内容，内容为核心或后续具备变化的配置</p>
<pre><code class="yml">pattern:
  dateformat: yyyy-MM-dd HH:mm:ss
</code></pre>
</li>
</ol>
<h3 id="5-7-2-配置获取"><a href="#5-7-2-配置获取" class="headerlink" title="5.7.2 配置获取"></a>5.7.2 配置获取</h3><p>源springboot项目：</p>
<ul>
<li>项目启动-&gt;读取本地配置文件application.yml-&gt;创建Spring容器-&gt;加载bean</li>
</ul>
<p>Nacos配置后的springboot项目：</p>
<ul>
<li>项目启动-&gt;读取Nacos的配置文件-&gt;读取本地配置文件application.yml-&gt;创建Spring容器-&gt;加载bean</li>
</ul>
<p><strong>①引入Nacos配置管理客户端依赖</strong></p>
<pre><code class="xml">        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>
<p><strong>②userservice中resource目录添加一个bootstrap.yml文件，这个文件是引导文件，优先级高于application.yml</strong></p>
<pre><code class="yml">spring:
  application:
    name: userservice # 服务名称
  profiles:
    active: dev # 开发环境，这里是dev
  cloud:
    nacos:
      server-addr: localhost:8848 # Nacos地址
      config:
        file-extension: yaml # 文件后缀名
</code></pre>
<p>注：</p>
<ul>
<li>删除application.yml中的重复配置，如application.name，cloud.nacos</li>
<li>配置的命名空间一定要在同一个，否则会启动服务失败，因为找不到这个配置属性</li>
</ul>
<p><strong>③Controller层注入在Nacos中的配置进行测试</strong></p>
<p>此配置在7.1可查看</p>
<pre><code class="java">    @Value(&quot;$&#123;pattern.dateformat&#125;&quot;)
    private String dateformat;

    @GetMapping(&quot;/now&quot;)
    public String now() &#123;
        return LocalDateTime.now().format(DateTimeFormatter.ofPattern(dateformat));
    &#125;
// 测试地址：http://localhost:8081/user/now
</code></pre>
<h3 id="5-7-3-配置刷新"><a href="#5-7-3-配置刷新" class="headerlink" title="5.7.3 配置刷新"></a>5.7.3 配置刷新</h3><p>Nacos配置更改后，微服务可以实现热更新，方式：</p>
<ul>
<li>① 通过@Value注解注入，结合@RefreshScope来刷新</li>
<li>② 通过@ConfigurationProperties注入，自动刷新</li>
</ul>
<p>注意事项：</p>
<ul>
<li>不是所有的配置都适合放到配置中心，维护麻烦</li>
<li>建议将一些关键参数，需要运行时调整的参数放到nacos配置中心，一般都是自定义配置</li>
</ul>
<p><strong>①方式一</strong></p>
<p>在@Value注入的变量所在类上添加注解@RefreshScope</p>
<pre><code class="java">@Slf4j
@RestController
@RefreshScope
@RequestMapping(&quot;/user&quot;)
public class UserController &#123;

    @Value(&quot;$&#123;pattern.dateformat&#125;&quot;)
    private String dateformat;

    @GetMapping(&quot;/now&quot;)
    public String now() &#123;
        return LocalDateTime.now().format(DateTimeFormatter.ofPattern(dateformat));
    &#125;
&#125;
</code></pre>
<p><strong>②方式二</strong></p>
<p>使用@ConfigurationProperties注解</p>
<ol>
<li><p>添加配置类</p>
<pre><code class="java">// com.bamboo.user.config.PatternProperties
@Component
@Data
@ConfigurationProperties(prefix = &quot;pattern&quot;)
public class PatternProperties &#123;
    private String dateformat;
&#125;
</code></pre>
</li>
<li><p>添加spring-boot-configuration-processor注解驱动</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;
    &lt;optional&gt;true&lt;/optional&gt;
&lt;/dependency&gt;
</code></pre>
</li>
<li><p>使用@Autowired进行注入</p>
<pre><code class="java">@Slf4j
@RestController
// nacos配置热部署
//@RefreshScope
@RequestMapping(&quot;/user&quot;)
public class UserController &#123;

    @Autowired
    private UserService userService;

    // 注入热部署配置
    @Autowired
    private PatternProperties properties;

    @GetMapping(&quot;/now&quot;)
    public String now() &#123;
        return LocalDateTime.now().format(DateTimeFormatter.ofPattern(properties.getDateformat()));
    &#125;

&#125;
</code></pre>
</li>
</ol>
<h2 id="5-8-Nacos多环境配置共享"><a href="#5-8-Nacos多环境配置共享" class="headerlink" title="5.8. Nacos多环境配置共享"></a>5.8. Nacos多环境配置共享</h2><p>微服务启动时会从nacos读取多个配置文件：</p>
<ul>
<li>[spring.application.name]-[spring.profiles.active].yaml，例如：userservice-dev.yaml</li>
<li>[spring.application.name].yaml，例如：userservice.yaml</li>
</ul>
<p>无论profile如何变化，[spring.application.name].yaml这个文件一定会加载，因此多环境共享配置可以写入这个文件</p>
<p>文件配置优先级：Nacos配置中的application-dev.yaml &gt; Nacos配置中的application.yaml &gt; 本地application.yaml配置</p>
<ul>
<li>即 服务名-profile.yaml &gt; 服务名.yaml &gt; 本地配置</li>
</ul>
<p><strong>使用</strong></p>
<ol>
<li><p>Nacos服务上添加配置列表</p>
<ul>
<li><p>新建配置</p>
</li>
<li><p>设置<strong>Data ID</strong>：userservice.yaml</p>
</li>
<li><p>添加描述：环境共享</p>
</li>
<li><p>设置<strong>配置格式</strong>：YAML</p>
</li>
<li><p>设置<strong>配置内容</strong>：</p>
<pre><code class="yaml">pattern:
    envSharedValue: 环境共享属性值
</code></pre>
</li>
</ul>
</li>
<li><p>修改读取配置类</p>
<pre><code class="java">@Component
@Data
@ConfigurationProperties(prefix = &quot;pattern&quot;)
public class PatternProperties &#123;
    private String dateformat;
    private String envSharedValue;
&#125;
</code></pre>
</li>
<li><p>自动注入并调用接口</p>
<pre><code class="java">@Autowired
private PatternProperties properties;
@GetMapping(&quot;/prop&quot;)
public PatternProperties loadProp() &#123;
    return properties;
&#125;
</code></pre>
</li>
<li><p>测试</p>
<ul>
<li>测试结果通过，不同profiles环境下只有多环境配置userservice.yaml可以读取到</li>
<li>测试多环境方式：IDEA右键Edit Configuration，选择Active profiles填写test，说明这是一个userservice-test.yaml配置的SpringBoot</li>
</ul>
</li>
</ol>
<h2 id="5-9-Nacos集群搭建"><a href="#5-9-Nacos集群搭建" class="headerlink" title="5.9. Nacos集群搭建"></a>5.9. Nacos集群搭建</h2><p>搭建级别：</p>
<ul>
<li>nacos client<ul>
<li>Nginx<ul>
<li>Nacos node1</li>
<li>Nacos node2</li>
<li>Nacos node3<ul>
<li>MySQL主<ul>
<li>MySQL从</li>
<li>MySQL从</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Nacos node统一接入MySQL</p>
<h3 id="5-9-1-搭建数据库和Nacos"><a href="#5-9-1-搭建数据库和Nacos" class="headerlink" title="5.9.1 搭建数据库和Nacos"></a>5.9.1 搭建数据库和Nacos</h3><p><strong>①初始化数据库</strong></p>
<p>Nacos默认数据存储在内嵌数据库Derby中，不属于生产可用的数据库。</p>
<p>官方推荐的最佳实践是使用带有主从的高可用数据库集群。</p>
<p>这里我们以单点的数据库为例来讲解。</p>
<p>首先新建一个数据库，命名为nacos，而后导入下面的SQL：</p>
<pre><code class="sql">CREATE TABLE `config_info` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;,
  `data_id` varchar(255) NOT NULL COMMENT &#39;data_id&#39;,
  `group_id` varchar(255) DEFAULT NULL,
  `content` longtext NOT NULL COMMENT &#39;content&#39;,
  `md5` varchar(32) DEFAULT NULL COMMENT &#39;md5&#39;,
  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,
  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,
  `src_user` text COMMENT &#39;source user&#39;,
  `src_ip` varchar(50) DEFAULT NULL COMMENT &#39;source ip&#39;,
  `app_name` varchar(128) DEFAULT NULL,
  `tenant_id` varchar(128) DEFAULT &#39;&#39; COMMENT &#39;租户字段&#39;,
  `c_desc` varchar(256) DEFAULT NULL,
  `c_use` varchar(64) DEFAULT NULL,
  `effect` varchar(64) DEFAULT NULL,
  `type` varchar(64) DEFAULT NULL,
  `c_schema` text,
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_configinfo_datagrouptenant` (`data_id`,`group_id`,`tenant_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=&#39;config_info&#39;;

/******************************************/
/*   数据库全名 = nacos_config   */
/*   表名称 = config_info_aggr   */
/******************************************/
CREATE TABLE `config_info_aggr` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;,
  `data_id` varchar(255) NOT NULL COMMENT &#39;data_id&#39;,
  `group_id` varchar(255) NOT NULL COMMENT &#39;group_id&#39;,
  `datum_id` varchar(255) NOT NULL COMMENT &#39;datum_id&#39;,
  `content` longtext NOT NULL COMMENT &#39;内容&#39;,
  `gmt_modified` datetime NOT NULL COMMENT &#39;修改时间&#39;,
  `app_name` varchar(128) DEFAULT NULL,
  `tenant_id` varchar(128) DEFAULT &#39;&#39; COMMENT &#39;租户字段&#39;,
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_configinfoaggr_datagrouptenantdatum` (`data_id`,`group_id`,`tenant_id`,`datum_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=&#39;增加租户字段&#39;;


/******************************************/
/*   数据库全名 = nacos_config   */
/*   表名称 = config_info_beta   */
/******************************************/
CREATE TABLE `config_info_beta` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;,
  `data_id` varchar(255) NOT NULL COMMENT &#39;data_id&#39;,
  `group_id` varchar(128) NOT NULL COMMENT &#39;group_id&#39;,
  `app_name` varchar(128) DEFAULT NULL COMMENT &#39;app_name&#39;,
  `content` longtext NOT NULL COMMENT &#39;content&#39;,
  `beta_ips` varchar(1024) DEFAULT NULL COMMENT &#39;betaIps&#39;,
  `md5` varchar(32) DEFAULT NULL COMMENT &#39;md5&#39;,
  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,
  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,
  `src_user` text COMMENT &#39;source user&#39;,
  `src_ip` varchar(50) DEFAULT NULL COMMENT &#39;source ip&#39;,
  `tenant_id` varchar(128) DEFAULT &#39;&#39; COMMENT &#39;租户字段&#39;,
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_configinfobeta_datagrouptenant` (`data_id`,`group_id`,`tenant_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=&#39;config_info_beta&#39;;

/******************************************/
/*   数据库全名 = nacos_config   */
/*   表名称 = config_info_tag   */
/******************************************/
CREATE TABLE `config_info_tag` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;,
  `data_id` varchar(255) NOT NULL COMMENT &#39;data_id&#39;,
  `group_id` varchar(128) NOT NULL COMMENT &#39;group_id&#39;,
  `tenant_id` varchar(128) DEFAULT &#39;&#39; COMMENT &#39;tenant_id&#39;,
  `tag_id` varchar(128) NOT NULL COMMENT &#39;tag_id&#39;,
  `app_name` varchar(128) DEFAULT NULL COMMENT &#39;app_name&#39;,
  `content` longtext NOT NULL COMMENT &#39;content&#39;,
  `md5` varchar(32) DEFAULT NULL COMMENT &#39;md5&#39;,
  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,
  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,
  `src_user` text COMMENT &#39;source user&#39;,
  `src_ip` varchar(50) DEFAULT NULL COMMENT &#39;source ip&#39;,
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_configinfotag_datagrouptenanttag` (`data_id`,`group_id`,`tenant_id`,`tag_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=&#39;config_info_tag&#39;;

/******************************************/
/*   数据库全名 = nacos_config   */
/*   表名称 = config_tags_relation   */
/******************************************/
CREATE TABLE `config_tags_relation` (
  `id` bigint(20) NOT NULL COMMENT &#39;id&#39;,
  `tag_name` varchar(128) NOT NULL COMMENT &#39;tag_name&#39;,
  `tag_type` varchar(64) DEFAULT NULL COMMENT &#39;tag_type&#39;,
  `data_id` varchar(255) NOT NULL COMMENT &#39;data_id&#39;,
  `group_id` varchar(128) NOT NULL COMMENT &#39;group_id&#39;,
  `tenant_id` varchar(128) DEFAULT &#39;&#39; COMMENT &#39;tenant_id&#39;,
  `nid` bigint(20) NOT NULL AUTO_INCREMENT,
  PRIMARY KEY (`nid`),
  UNIQUE KEY `uk_configtagrelation_configidtag` (`id`,`tag_name`,`tag_type`),
  KEY `idx_tenant_id` (`tenant_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=&#39;config_tag_relation&#39;;

/******************************************/
/*   数据库全名 = nacos_config   */
/*   表名称 = group_capacity   */
/******************************************/
CREATE TABLE `group_capacity` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;主键ID&#39;,
  `group_id` varchar(128) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;Group ID，空字符表示整个集群&#39;,
  `quota` int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;配额，0表示使用默认值&#39;,
  `usage` int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;使用量&#39;,
  `max_size` int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;单个配置大小上限，单位为字节，0表示使用默认值&#39;,
  `max_aggr_count` int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;聚合子配置最大个数，，0表示使用默认值&#39;,
  `max_aggr_size` int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值&#39;,
  `max_history_count` int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;最大变更历史数量&#39;,
  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,
  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_group_id` (`group_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=&#39;集群、各Group容量信息表&#39;;

/******************************************/
/*   数据库全名 = nacos_config   */
/*   表名称 = his_config_info   */
/******************************************/
CREATE TABLE `his_config_info` (
  `id` bigint(64) unsigned NOT NULL,
  `nid` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `data_id` varchar(255) NOT NULL,
  `group_id` varchar(128) NOT NULL,
  `app_name` varchar(128) DEFAULT NULL COMMENT &#39;app_name&#39;,
  `content` longtext NOT NULL,
  `md5` varchar(32) DEFAULT NULL,
  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,
  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,
  `src_user` text,
  `src_ip` varchar(50) DEFAULT NULL,
  `op_type` char(10) DEFAULT NULL,
  `tenant_id` varchar(128) DEFAULT &#39;&#39; COMMENT &#39;租户字段&#39;,
  PRIMARY KEY (`nid`),
  KEY `idx_gmt_create` (`gmt_create`),
  KEY `idx_gmt_modified` (`gmt_modified`),
  KEY `idx_did` (`data_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=&#39;多租户改造&#39;;


/******************************************/
/*   数据库全名 = nacos_config   */
/*   表名称 = tenant_capacity   */
/******************************************/
CREATE TABLE `tenant_capacity` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;主键ID&#39;,
  `tenant_id` varchar(128) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;Tenant ID&#39;,
  `quota` int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;配额，0表示使用默认值&#39;,
  `usage` int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;使用量&#39;,
  `max_size` int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;单个配置大小上限，单位为字节，0表示使用默认值&#39;,
  `max_aggr_count` int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;聚合子配置最大个数&#39;,
  `max_aggr_size` int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值&#39;,
  `max_history_count` int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;最大变更历史数量&#39;,
  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,
  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_tenant_id` (`tenant_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=&#39;租户容量信息表&#39;;


CREATE TABLE `tenant_info` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;,
  `kp` varchar(128) NOT NULL COMMENT &#39;kp&#39;,
  `tenant_id` varchar(128) default &#39;&#39; COMMENT &#39;tenant_id&#39;,
  `tenant_name` varchar(128) default &#39;&#39; COMMENT &#39;tenant_name&#39;,
  `tenant_desc` varchar(256) DEFAULT NULL COMMENT &#39;tenant_desc&#39;,
  `create_source` varchar(32) DEFAULT NULL COMMENT &#39;create_source&#39;,
  `gmt_create` bigint(20) NOT NULL COMMENT &#39;创建时间&#39;,
  `gmt_modified` bigint(20) NOT NULL COMMENT &#39;修改时间&#39;,
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_tenant_info_kptenantid` (`kp`,`tenant_id`),
  KEY `idx_tenant_id` (`tenant_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=&#39;tenant_info&#39;;

CREATE TABLE `users` (
    `username` varchar(50) NOT NULL PRIMARY KEY,
    `password` varchar(500) NOT NULL,
    `enabled` boolean NOT NULL
);

CREATE TABLE `roles` (
    `username` varchar(50) NOT NULL,
    `role` varchar(50) NOT NULL,
    UNIQUE INDEX `idx_user_role` (`username` ASC, `role` ASC) USING BTREE
);

CREATE TABLE `permissions` (
    `role` varchar(50) NOT NULL,
    `resource` varchar(255) NOT NULL,
    `action` varchar(8) NOT NULL,
    UNIQUE INDEX `uk_role_permission` (`role`,`resource`,`action`) USING BTREE
);

INSERT INTO users (username, password, enabled) VALUES (&#39;nacos&#39;, &#39;$2a$10$EuWPZHzz32dJN7jexM34MOeYirDdFAZm2kuWj7VEOJhhZkDrxfvUu&#39;, TRUE);

INSERT INTO roles (username, role) VALUES (&#39;nacos&#39;, &#39;ROLE_ADMIN&#39;);
</code></pre>
<p><strong>②下载nacos</strong></p>
<p>nacos在GitHub上有下载地址：<a target="_blank" rel="noopener" href="https://github.com/alibaba/nacos/tags%EF%BC%8C%E5%8F%AF%E4%BB%A5%E9%80%89%E6%8B%A9%E4%BB%BB%E6%84%8F%E7%89%88%E6%9C%AC%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/alibaba/nacos/tags，可以选择任意版本下载。</a></p>
<p><strong>③配置nacos</strong></p>
<p>目录说明：</p>
<ul>
<li>bin：启动脚本</li>
<li>conf：配置文件</li>
</ul>
<p>进入nacos的conf目录，修改配置文件cluster.conf.example，重命名为cluster.conf</p>
<p>然后添加内容：</p>
<pre><code>127.0.0.1:8845
127.0.0.1.8846
127.0.0.1.8847
</code></pre>
<p>然后修改application.properties文件，添加数据库配置</p>
<pre><code class="properties">spring.datasource.platform=mysql

db.num=1

db.url.0=jdbc:mysql://127.0.0.1:3306/nacos?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTC
db.user.0=root
db.password.0=123
</code></pre>
<p><strong>④启动</strong></p>
<p>将nacos文件夹复制三份，分别命名为：nacos1、nacos2、nacos3</p>
<p>然后分别修改三个文件夹中的application.properties，</p>
<p>nacos1:</p>
<pre><code class="properties">server.port=8845
</code></pre>
<p>nacos2:</p>
<pre><code class="properties">server.port=8846
</code></pre>
<p>nacos3:</p>
<pre><code class="properties">server.port=8847
</code></pre>
<p>然后分别启动三个nacos节点：</p>
<pre><code>startup.cmd
</code></pre>
<h3 id="5-9-2-配置nginx反向代理"><a href="#5-9-2-配置nginx反向代理" class="headerlink" title="5.9.2 配置nginx反向代理"></a>5.9.2 配置nginx反向代理</h3><p>修改conf&#x2F;nginx.conf文件，配置如下：</p>
<pre><code class="nginx">upstream nacos-cluster &#123;
    server 127.0.0.1:8845;
    server 127.0.0.1:8846;
    server 127.0.0.1:8847;
&#125;

server &#123;
    listen       80;
    server_name  localhost;

    location /nacos &#123;
        proxy_pass http://nacos-cluster;
    &#125;
&#125;
</code></pre>
<p>而后在浏览器访问：<a target="_blank" rel="noopener" href="http://localhost/nacos%E5%8D%B3%E5%8F%AF%E3%80%82">http://localhost/nacos即可。</a></p>
<p>代码中application.yml文件配置如下：</p>
<pre><code class="yaml">spring:
  cloud:
    nacos:
      server-addr: localhost:80 # Nacos地址
</code></pre>
<h1 id="六、http客户端Feign"><a href="#六、http客户端Feign" class="headerlink" title="六、http客户端Feign"></a>六、http客户端Feign</h1><p>RestTemplate方式调用存在的弊端</p>
<p>源代码：</p>
<pre><code class="java">String url = &quot;http://userservice/user/&quot; + order.getUserId();
User user = restTemplate.getForObject(url,User.class);
</code></pre>
<ul>
<li>代码可读性差，编程体验不统一</li>
<li>参数复杂的URL难以维护</li>
</ul>
<h2 id="6-1-Feign概述"><a href="#6-1-Feign概述" class="headerlink" title="6.1. Feign概述"></a>6.1. Feign概述</h2><p>声明式的http客户端，作用是帮助我们优雅的实现http请求的发送</p>
<h2 id="6-2-使用"><a href="#6-2-使用" class="headerlink" title="6.2. 使用"></a>6.2. 使用</h2><ol>
<li><p>服务消费者Consumer引入依赖</p>
<pre><code class="xml">        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>
</li>
<li><p>在服务消费者Consumer的启动类中加入注解开启Feign功能</p>
<pre><code class="java">@MapperScan(&quot;cn.itcast.order.mapper&quot;)
@EnableFeignClients
@SpringBootApplication
public class OrderApplication &#123;

    public static void main(String[] args) &#123;
        SpringApplication.run(OrderApplication.class, args);
    &#125;

&#125;
</code></pre>
</li>
<li><p>编写Feign客户端</p>
<pre><code class="java">@FeignClient(&quot;userservice&quot;)
public interface UserClient &#123;
    @GetMapping(&quot;/user/&#123;id&#125;&quot;)
    User findById(@PathVariable(&quot;id&quot;) Long id);
&#125;
</code></pre>
<p>主要基于SpringMVC注解来声明远程调用的信息：</p>
<ul>
<li>服务名称：userservice</li>
<li>请求方式：GET</li>
<li>请求路径：&#x2F;user&#x2F;{id}</li>
<li>请求参数：Long id</li>
<li>返回值类型：User</li>
</ul>
</li>
<li><p>调用</p>
<pre><code class="java">@Service
public class OrderService &#123;

    @Autowired
    private OrderMapper orderMapper;

    @Autowired
    private RestTemplate restTemplate;
    // 注入Feign
    @Autowired
    private UserClient userClient;

    public Order queryOrderById(Long orderId) &#123;
        // 1.查询订单
        Order order = orderMapper.findById(orderId);
        // 2.用Feign来进行远程调用
        User user = userClient.findById(order.getUserId());
        // 3.封装User到Order
        order.setUser(user);
        // 4.返回
        return order;
    &#125;
&#125;
</code></pre>
</li>
<li><p>使用总结</p>
<ul>
<li>引入依赖</li>
<li>添加@EnableFeignClients注解</li>
<li>编写FeignClient接口</li>
<li>使用FeignClient中定义的方法代替RestTemplate</li>
</ul>
</li>
</ol>
<h2 id="6-3-自定义配置"><a href="#6-3-自定义配置" class="headerlink" title="6.3. 自定义配置"></a>6.3. 自定义配置</h2><p>Feign运行自定义配置来覆盖默认配置，可以修改的配置如下：</p>
<table>
<thead>
<tr>
<th align="center">类型</th>
<th align="center">作用</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">feign.Logger.Level</td>
<td align="center">修改日志级别</td>
<td align="center">包含四种不同的级别：NONE、BASIC、HEADERS、FULL</td>
</tr>
<tr>
<td align="center">feign.codec.Decoder</td>
<td align="center">响应结果的解析器</td>
<td align="center">http远程调用的结果做解析，例如解析json字符串作为java对象</td>
</tr>
<tr>
<td align="center">feign.codec.Encoder</td>
<td align="center">请求参数编码</td>
<td align="center">将请求参数编码，便于通过http请求发送</td>
</tr>
<tr>
<td align="center">feign.Contract</td>
<td align="center">支持的注解格式</td>
<td align="center">默认是SpringMVC 的注解</td>
</tr>
<tr>
<td align="center">feign.Retryer</td>
<td align="center">失败重试机制</td>
<td align="center">请求事变的重试机制，默认不开启，不过会使用Ribbon的重试</td>
</tr>
</tbody></table>
<p><strong>配置Feign日志</strong></p>
<ol>
<li><p>方式一：配置文件，feign.client.config.xxx.loggerLevel</p>
<ul>
<li><p>如果是xxx是default则代表全局</p>
<pre><code class="yaml"># 配置feign
feign:
  client:
    config:
      default: # 全局配置
        logger-level: full # 日志级别
</code></pre>
</li>
<li><p>如果xxx是服务名称，例如userservice则代表某服务</p>
<pre><code class="yaml"># 配置feign
feign:
  client:
    config:
      userservice: # 局部日志
        logger-level: full # 日志级别
</code></pre>
</li>
</ul>
</li>
<li><p>方式二：Java代码方式，配置Logger.Level的Bean</p>
<ul>
<li><p>定义Bean</p>
<pre><code class="java">public class FeignClientConfiguration &#123;
    @Bean
    public Logger.Level feignLogLevel() &#123;
        return Logger.Level.BASIC;
    &#125;
&#125;
</code></pre>
</li>
<li><p>如果在@EnableFeignClients注解声明则代表全局</p>
<pre><code class="java">@MapperScan(&quot;cn.itcast.order.mapper&quot;)
@EnableFeignClients(defaultConfiguration = FeignClientConfiguration.class)
@SpringBootApplication
public class OrderApplication &#123;

    public static void main(String[] args) &#123;
        SpringApplication.run(OrderApplication.class, args);
    &#125;

&#125;
</code></pre>
</li>
<li><p>如果在@FeignClient注解中声明则代表某服务</p>
<pre><code class="java">@FeignClient(value = &quot;userservice&quot;,configuration = FeignClientConfiguration.class)
public interface UserClient &#123;
    @GetMapping(&quot;/user/&#123;id&#125;&quot;)
    User findById(@PathVariable(&quot;id&quot;) Long id);
&#125;
</code></pre>
</li>
</ul>
</li>
</ol>
<h2 id="6-4-性能优化"><a href="#6-4-性能优化" class="headerlink" title="6.4. 性能优化"></a>6.4. 性能优化</h2><p>Feign底层he护短实现：</p>
<ul>
<li>URLConnection：默认实现，不支持连接池</li>
<li>Apache HttpClient：支持链接吃</li>
<li>OKHttp：支持连接池</li>
</ul>
<p><strong>优化Feign性能</strong>主要包括：</p>
<p>① 使用连接池代替默认的URLConnection</p>
<p>② 日志级别，最好使用basic或none</p>
<p>Feign<strong>添加HttpClient支持</strong>：</p>
<ol>
<li><p>引入依赖：</p>
<pre><code class="xml">        &lt;dependency&gt;
            &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt;
            &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>
</li>
<li><p>配置连接池</p>
<pre><code class="yml">feign:
#  client: # 已使用java代码对日志进行了配置
#    config:
#      default: # 全局配置
#        logger-level: full # 日志级别
  httpclient:
    enabled: true # 开启feign对HttpClient的支持
    max-connections: 200 # 最大连接数
    max-connections-per-route: 50 # 每个路径最大的连接数
</code></pre>
</li>
</ol>
<h2 id="6-5-最佳实践"><a href="#6-5-最佳实践" class="headerlink" title="6.5. 最佳实践"></a>6.5. 最佳实践</h2><ol>
<li>让controller和FeignClient继承同一接口</li>
<li>让FeignClient、POJO、Feign的默认配置豆丁一道一个项目中，供所有消费者使用</li>
</ol>
<p><strong>①方式一(继承)</strong></p>
<p>给消费者的FeignClient和提供者的controller定义统一的父接口作为标准。</p>
<ul>
<li><p>父接口</p>
<pre><code class="java">public interface USerAPI&#123;
    @GetMapping(&quot;/user/&#123;id&#125;&quot;)
    User findById(@PathVariable(&quot;id&quot;) Long id);
&#125;
</code></pre>
<ul>
<li><p>FeignClient</p>
<pre><code class="java">@FeignClient(value = &quot;userservice&quot;)
public interface UserClient extends UserAPI&#123;&#125;
</code></pre>
</li>
<li><p>服务提供者Controller</p>
<pre><code class="java">@RestController
public class UserController implements UserAPI&#123;
    public User findById(@PathVariable(&quot;id&quot;) Long id)&#123;
        // ...实现业务
    &#125;
&#125;
</code></pre>
</li>
</ul>
</li>
</ul>
<p>*通常不建议在服务器和客户机之间共享一个接口。它引入了紧密耦合，并且实际上也不能与当前形式的Spring MVC一起工作(方法参数映射不能继承)。</p>
<p><strong>② 方式二(抽取)</strong></p>
<p>将FeignClient抽取为独立模块，并且把接口有关的POJO、默认的Feign配置都放到这个模块中，提供给所有的消费者使用</p>
<ol>
<li><p>创建一个module，命名为feign-api，然后引入feign的starter依赖</p>
<pre><code class="xml">    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
</code></pre>
</li>
<li><p>将order-service中编写的UserClient、User、DefaultFeignConfiguration都复制到feign-api项目中</p>
<ul>
<li><p>UserClient</p>
<pre><code class="java">package cn.itcast.feign.clients;


import cn.itcast.feign.pojo.User;
import cn.itcast.feign.config.FeignClientConfiguration;
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;

@FeignClient(value = &quot;userservice&quot;,configuration = FeignClientConfiguration.class)
public interface UserClient &#123;
    @GetMapping(&quot;/user/&#123;id&#125;&quot;)
    User findById(@PathVariable(&quot;id&quot;) Long id);
&#125;
</code></pre>
</li>
<li><p>User</p>
<pre><code class="java">package cn.itcast.feign.pojo;

import lombok.Data;

@Data
public class User &#123;
    private Long id;
    private String username;
    private String address;
&#125;
</code></pre>
</li>
<li><p>DefaultFeignConfiguration</p>
<pre><code class="java">package cn.itcast.feign.config;

import feign.Logger;
import org.springframework.context.annotation.Bean;

/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/19 13:25
 */
public class FeignClientConfiguration &#123;
    @Bean
    public Logger.Level feignLogLevel() &#123;
        return Logger.Level.BASIC;
    &#125;
&#125;
</code></pre>
</li>
</ul>
</li>
<li><p>在order-service中引入feign-api的依赖</p>
<pre><code class="xml">&lt;!--引入feign-api--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.bamboo&lt;/groupId&gt;
    &lt;artifactId&gt;feign-api&lt;/artifactId&gt;
    &lt;version&gt;1.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
</li>
<li><p>修改Order-service中的所有与上述三个组件有关的import部分，改成导入feign-api中的包</p>
</li>
<li><p>重启测试</p>
</li>
<li><p>扫不到FeignClient的解决方案</p>
<ul>
<li><p>方式一：指定FeignClient所在包</p>
<pre><code class="java">@EnableFeignClients(basePackages = &quot;cn.itcast.feign.clients&quot;)
</code></pre>
</li>
<li><p>方式二：指定FeignClient字节码</p>
<pre><code class="java">@EnableFeignClients(&#123;UserClient.class&#125;)
</code></pre>
</li>
</ul>
</li>
</ol>
<h1 id="七、统一网关Gateway"><a href="#七、统一网关Gateway" class="headerlink" title="七、统一网关Gateway"></a>七、统一网关Gateway</h1><p><strong>网关作用</strong></p>
<ul>
<li>对用户请求做身份认证和权限校验</li>
<li>将用户请求路由到微服务，并实现负载均衡</li>
<li>对用户请求做限流</li>
</ul>
<p><strong>网关的技术实现</strong></p>
<p>在SpringCloud中网关的实现包括两种：</p>
<ul>
<li>gateway</li>
<li>zuul</li>
</ul>
<p>Zuul是基于Servlet的实现，属于阻塞式编程。而SpringCloudGateway则是基于Spring5中提供的WebFlux，属于响应式编程的实现，具备更好的性能。</p>
<h2 id="7-1-搭建网关服务"><a href="#7-1-搭建网关服务" class="headerlink" title="7.1. 搭建网关服务"></a>7.1. 搭建网关服务</h2><ol>
<li><p>创建新的module【gateway】，引入SpringCloudGateway的依赖和nacos的服务发现依赖，并创建SpringBoot启动类</p>
<pre><code class="xml">&lt;dependencies&gt;
    &lt;!--网关依赖--&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;
    &lt;/dependency&gt;

    &lt;!-- nacos服务发现依赖 --&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<pre><code class="java">package cn.itcast.gateway;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/19 22:35
 */
@SpringBootApplication
public class GatewayApplication &#123;
    public static void main(String[] args) &#123;
        SpringApplication.run(GatewayApplication.class,args);
    &#125;
&#125;
</code></pre>
</li>
<li><p>配置application.yml，包括服务基本信息、nacos地址、路由</p>
<pre><code class="yml">server:
  port: 10010
spring:
  application:
    name: gateway
  cloud:
    nacos:
      server-addr: localhost:8848 # nacos地址
    gateway:
      routes:
        - id: user-service # 路由标识，必须唯一
          # uri: http://127.0.0.1:8081 路由的目标地址，http就是固定地址
          uri: lb://userservice # 路由目标地址 lb是负载均衡loadBalance 后面跟服务名称
          predicates: # 路由断言，判断请求是否符合规则
            - Path=/user/** # 路径断言，判断路径是否是以/user开头，如果是则符合
        - id: order-service
          uri: lb://orderservice
          predicates:
            - Path=/order/**
</code></pre>
</li>
<li><p>测试</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://localhost:10010/order/102">http://localhost:10010/order/102</a></li>
<li><a target="_blank" rel="noopener" href="http://localhost:10010/user/3">http://localhost:10010/user/3</a></li>
</ul>
</li>
</ol>
<p><strong>路由配置</strong>包括：</p>
<ol>
<li>路由id：路由的唯一标识</li>
<li>路由目标（uri）：路由的目标地址，http代表固定地址，lb代表根据服务名负载均衡</li>
<li>路由断言（predicates）：判断路由的规则</li>
<li>路由过滤器（filters）：对请求或响应做处理</li>
</ol>
<h2 id="7-2-路由断言工厂-Route-Predicate-Factory"><a href="#7-2-路由断言工厂-Route-Predicate-Factory" class="headerlink" title="7.2. 路由断言工厂 Route Predicate Factory"></a>7.2. 路由断言工厂 Route Predicate Factory</h2><ul>
<li>配置文件中的predicates</li>
<li>predicates: 路由断言，判断请求是否符合要求，符合则转发到路由目的地</li>
<li>配置文件中写的断言规则只是字符串，这些字符串会被Predicate Factory读取并处理，转变为路由判断的条件</li>
<li>例如Path&#x3D;&#x2F;user&#x2F;*<em>是按照路径匹配，这个规则是由</em>org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory类来处理的</li>
</ul>
<p><strong>11中基本的Predicate工厂</strong></p>
<table>
<thead>
<tr>
<th>名称</th>
<th>说明</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>After</td>
<td>是某个时间点后的请求</td>
<td>- After&#x3D;2017-01-20T17:42:47.789-07:00[Asia&#x2F;Shanghai]</td>
</tr>
<tr>
<td>Before</td>
<td>是某个时间点之前的请求</td>
<td>- Before&#x3D;2017-01-20T17:42:47.789-07:00[America&#x2F;Denver]</td>
</tr>
<tr>
<td>Between</td>
<td>是某两个时间点之间的请求</td>
<td>- Between&#x3D;2017-01-20T17:42:47.789-07:00[America&#x2F;Denver], 2017-01-21T17:42:47.789-07:00[America&#x2F;Denver]</td>
</tr>
<tr>
<td>Cookie</td>
<td>请求必须包含某些cookie</td>
<td>- Cookie&#x3D;chocolate, ch.p</td>
</tr>
<tr>
<td>Header</td>
<td>请求必须包含某些header</td>
<td>- Header&#x3D;X-Request-Id, \d+</td>
</tr>
<tr>
<td>Host</td>
<td>请求必须是访问某个host（域名）</td>
<td>- Host&#x3D;<strong>.somehost.org,</strong>.anotherhost.org</td>
</tr>
<tr>
<td>Method</td>
<td>请求方式必须是指定方式</td>
<td>- Method&#x3D;GET,POST</td>
</tr>
<tr>
<td>Path</td>
<td>请求路径必须符合指定规则</td>
<td>- Path&#x3D;&#x2F;red&#x2F;{segment},&#x2F;blue&#x2F;**</td>
</tr>
<tr>
<td>Query</td>
<td>请求参数必须包含指定参数</td>
<td>- Query&#x3D;green 或 - Query&#x3D;red, gree.</td>
</tr>
<tr>
<td>RemoteAddr</td>
<td>请求者的ip必须是指定范围</td>
<td>- RemoteAddr&#x3D;192.168.1.1&#x2F;24</td>
</tr>
<tr>
<td>Weight</td>
<td>权重处理</td>
<td>- Weight&#x3D;group1, 2</td>
</tr>
</tbody></table>
<h2 id="7-3-路由过滤器-GatewayFilter"><a href="#7-3-路由过滤器-GatewayFilter" class="headerlink" title="7.3. 路由过滤器 GatewayFilter"></a>7.3. 路由过滤器 GatewayFilter</h2><p>过滤器链，网关中包含一系列过滤器，形成过滤器链</p>
<p>Spring提供了31种不同的路由过滤器工厂</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>AddRequestHeader</td>
<td>给当前请求添加一个请求头</td>
</tr>
<tr>
<td>RemoveRequestHeader</td>
<td>移除请求中的一个请求头</td>
</tr>
<tr>
<td>AddResponseHeader</td>
<td>给响应结果中添加一个响应头</td>
</tr>
<tr>
<td>RemoveResponseHeader</td>
<td>从响应结果中移除已有的一个响应头</td>
</tr>
<tr>
<td>RequestRateLimiter</td>
<td>限制请求的流量</td>
</tr>
</tbody></table>
<p><strong>实现方式</strong>：在gateway中修改application.yml文件，给userservice的路由添加过滤器</p>
<pre><code class="yml">server:
  port: 10010
spring:
  application:
    name: gateway
  cloud:
    nacos:
      server-addr: localhost:8848 # nacos地址
    gateway:
      routes:
        - id: user-service # 路由标识，必须唯一
          # uri: http://127.0.0.1:8081 路由的目标地址，http就是固定地址
          uri: lb://userservice # 路由目标地址 lb是负载均衡loadBalance 后面跟服务名称
          predicates: # 路由断言，判断请求是否符合规则
            - Path=/user/** # 路径断言，判断路径是否是以/user开头，如果是则符合
          filters:
            - AddRequestHeader=Truth,Itcast is freaking awesome! # 添加请求头
        - id: order-service
          uri: lb://orderservice
          predicates:
            - Path=/order/**
            - Before=2031-01-20T17:42:47.789-07:00[Asia/Shanghai]
</code></pre>
<p>服务中<strong>测试</strong>请求头信息</p>
<pre><code class="java">package cn.itcast.user.web;

import cn.itcast.user.config.PatternProperties;
import cn.itcast.user.pojo.User;
import cn.itcast.user.service.UserService;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.cloud.context.config.annotation.RefreshScope;
import org.springframework.web.bind.annotation.*;

import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;

@Slf4j
@RestController
// nacos配置热部署
//@RefreshScope
@RequestMapping(&quot;/user&quot;)
public class UserController &#123;

    @Autowired
    private UserService userService;
    
    /**
     * 路径： /user/110
     *
     * @param id 用户id
     * @return 用户
     */
    @GetMapping(&quot;/&#123;id&#125;&quot;)
    public User queryById(@PathVariable(&quot;id&quot;) Long id,
                          @RequestHeader(value = &quot;Truth&quot;, required = false) String truth) &#123;
        System.out.println(&quot;truth: &quot; + truth);
        return userService.queryById(id);
    &#125;
&#125;
</code></pre>
<p><strong>默认过滤器</strong> </p>
<pre><code class="yml">server:
  port: 10010
spring:
  application:
    name: gateway
  cloud:
    nacos:
      server-addr: localhost:8848 # nacos地址
    gateway:
      routes:
        - id: user-service # 路由标识，必须唯一
          # uri: http://127.0.0.1:8081 路由的目标地址，http就是固定地址
          uri: lb://userservice # 路由目标地址 lb是负载均衡loadBalance 后面跟服务名称
          predicates: # 路由断言，判断请求是否符合规则
            - Path=/user/** # 路径断言，判断路径是否是以/user开头，如果是则符合
        - id: order-service
          uri: lb://orderservice
          predicates:
            - Path=/order/**
            - Before=2031-01-20T17:42:47.789-07:00[Asia/Shanghai]
      default-filters: # 默认过滤器，会对所有的路由请求都生效，与routes同级
        - AddRequestHeader=Truth,Itcast is freaking awesome! # 添加请求头
</code></pre>
<h2 id="7-4-全局过滤器GlobalFilter"><a href="#7-4-全局过滤器GlobalFilter" class="headerlink" title="7.4. 全局过滤器GlobalFilter"></a>7.4. 全局过滤器GlobalFilter</h2><p>不同于路由过滤器中的default-filters，全局过滤器定义在yml之外，具有高可控性</p>
<p>全局过滤器也是处理一切进入网关的请求和微服务响应，与GatewayFilter作用一样。</p>
<p>区别在于GatewayFilter通过配置定义，处理逻辑是固定的。而GlobalFilter的逻辑需要自己写代码实现，定时方式是实现GlobalFilter接口</p>
<pre><code class="java">public interface GlobalFilter &#123;

    /**
     * Process the Web request and (optionally) delegate to the next &#123;@code WebFilter&#125;
     * through the given &#123;@link GatewayFilterChain&#125;.
     * 处理 Web 请求并（可选）通过给定的网关过滤器链委派给下一个 WebFilter。
     * @param exchange the current server exchange
     * exchange – 当前服务器 Exchange chain
     * @param chain provides a way to delegate to the next filter
     * chain – 提供了一种委托给下一个过滤器的方法
     * @return &#123;@code Mono&lt;Void&gt;&#125; to indicate when request processing is complete
     */
    Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain);
&#125;
</code></pre>
<p><strong>案例</strong>：定义全局过滤器，拦截并判断用户身份</p>
<ul>
<li>参数中有authorization</li>
<li>参数值为admin</li>
</ul>
<pre><code class="java">package cn.itcast.gateway;

import org.springframework.cloud.gateway.filter.GatewayFilterChain;
import org.springframework.cloud.gateway.filter.GlobalFilter;
import org.springframework.core.Ordered;
import org.springframework.core.annotation.Order;
import org.springframework.http.HttpStatus;
import org.springframework.http.server.reactive.ServerHttpRequest;
import org.springframework.stereotype.Component;
import org.springframework.util.MultiValueMap;
import org.springframework.web.server.ServerWebExchange;
import reactor.core.publisher.Mono;

/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/19 23:47
 */
//@Order(-1)
@Component
public class AuthorizeFilter implements GlobalFilter, Ordered &#123;
    @Override
    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123;
        // 1.获取请求参数
        ServerHttpRequest request = exchange.getRequest();
        MultiValueMap&lt;String, String&gt; params = request.getQueryParams();
        // 2.获取参数中的 authorization 参数
        String auth = params.getFirst(&quot;authorization&quot;);
        // 3.判断参数值是否等于admin
        if (&quot;admin&quot;.equals(auth)) &#123;
            // 4.是，放行
            return chain.filter(exchange);
        &#125;
        // 5.否，拦截
        // 5.1设置状态码
        exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED);
        // 5.2拦截请求
        return exchange.getResponse().setComplete();
    &#125;

    @Override
    public int getOrder() &#123;
        return -1;
    &#125;
&#125;
</code></pre>
<p>@Order注解与Ordered接口实现的功能一致，都是优先级</p>
<p>测试：<a target="_blank" rel="noopener" href="http://localhost:10010/user/3?authorization=admin">http://localhost:10010/user/3?authorization=admin</a></p>
<h2 id="7-5-过滤器执行顺序"><a href="#7-5-过滤器执行顺序" class="headerlink" title="7.5. 过滤器执行顺序"></a>7.5. 过滤器执行顺序</h2><ul>
<li>请求进入网关会碰到三类过滤器: 当前路由的过滤器、DefaultFilter、GlobalFilter</li>
<li>请求路由后，会将当前路由过滤器和DefaultFilter、GlobalFilter，合并到一个过滤器链 (集合)中，排序后依次执行每个过滤器</li>
<li>DefaultFilter &gt;&gt;&gt; 路由过滤器 &gt;&gt;&gt; GlobalFilter</li>
<li>每一个过滤器都必须指定一个int类型的order值，order值越小，优先级越高，执行顺序越靠前</li>
<li>GlobalFilter通过实现Ordered接口，或者添加@Order注解来指定order值，由我们自己指定路由过滤器和defaultFilter的order由Spring指定，默认是按照声明顺序从1递增。</li>
<li>当过滤器的order值一样时，会按照 defaultFilter &gt; 路由过滤器&gt;GobalFilter的顺序执行。</li>
</ul>
<h2 id="7-6-网关cors跨域配置"><a href="#7-6-网关cors跨域配置" class="headerlink" title="7.6. 网关cors跨域配置"></a>7.6. 网关cors跨域配置</h2><p>跨域：</p>
<ul>
<li>协议不同</li>
<li>域名不同</li>
<li>端口不同</li>
</ul>
<p>跨域问题:浏览器禁止请求的发起者与服务端发生跨域ajax请求，请求被浏览器拦截的问题</p>
<p>解决方案:CORS</p>
<pre><code class="yml">spring:
  cloud:
    gateway:
      globalcors: # 全局的跨域处理
        add-to-simple-url-handler-mapping: true # 解决options请求被拦截问题
        corsConfigurations:
          &#39;[/**]&#39;:
            allowedOrigins: # 允许哪些网站的跨域请求
              - &quot;http://localhost:8090&quot;
              - &quot;http://www.leyou.com&quot;
            allowedMethods: # 允许的跨域ajax的请求方式
              - &quot;GET&quot;
              - &quot;POST&quot;
              - &quot;DELETE&quot;
              - &quot;PUT&quot;
              - &quot;OPTIONS&quot;
            allowedHeaders: &quot;*&quot; # 允许在请求中携带的头信息
            allowCredentials: true # 是否允许携带cookie
            maxAge: 360000 # 这次跨域检测的有效期
</code></pre>
<p>yaml全部参数</p>
<pre><code class="yml">server:
  port: 10010
spring:
  application:
    name: gateway
  cloud:
    nacos:
      server-addr: localhost:8848 # nacos地址
    gateway:
      routes:
        - id: user-service # 路由标识，必须唯一
          # uri: http://127.0.0.1:8081 路由的目标地址，http就是固定地址
          uri: lb://userservice # 路由目标地址 lb是负载均衡loadBalance 后面跟服务名称
          predicates: # 路由断言，判断请求是否符合规则
            - Path=/user/** # 路径断言，判断路径是否是以/user开头，如果是则符合
        #          filters:
        #            - AddRequestHeader=Truth,Itcast is freaking awesome! # 添加请求头
        - id: order-service
          uri: lb://orderservice
          predicates:
            - Path=/order/**
            - Before=2031-01-20T17:42:47.789-07:00[Asia/Shanghai]
      default-filters: # 默认过滤器，会对所有的路由请求都生效
        - AddRequestHeader=Truth,Itcast is freaking awesome! # 添加请求头
      globalcors: # 全局的跨域处理
        add-to-simple-url-handler-mapping: true # 解决options请求被拦截问题
        corsConfigurations:
          &#39;[/**]&#39;:
            allowedOrigins: # 允许哪些网站的跨域请求
              - &quot;http://localhost:5500&quot;
              - &quot;http://www.leyou.com&quot;
            allowedMethods: # 允许的跨域ajax的请求方式
              - &quot;GET&quot;
              - &quot;POST&quot;
              - &quot;DELETE&quot;
              - &quot;PUT&quot;
              - &quot;OPTIONS&quot;
            allowedHeaders: &quot;*&quot; # 允许在请求中携带的头信息
            allowCredentials: true # 是否允许携带cookie
            maxAge: 360000 # 这次跨域检测的有效期
</code></pre>
<h1 id="八、Docker"><a href="#八、Docker" class="headerlink" title="八、Docker"></a>八、Docker</h1><p>微服务项目部署环境过多，例如：Nodejs、Redis、MySQL、MQ等等</p>
<p><strong>Docker解决依赖的兼容问题</strong></p>
<ul>
<li>将应用的Libs（函数库）、Deps（依赖）、配置与应用一起打包</li>
<li>将每个应用放到一个隔离容器去运行，避免互相打扰</li>
</ul>
<p><strong>服务器详解</strong></p>
<ul>
<li>内核与硬件交互，提供操作硬件的指令</li>
<li>系统应用封装内核指令作为函数，便于程序员调用</li>
<li>用户程序基于系统函数库实现功能</li>
</ul>
<p><strong>Docker解决不同系统环境的问题</strong></p>
<ul>
<li>Docker将用户程序与所需要调用的系统(比如Ubuntu)函数库一起打包</li>
<li>Docker运行到不同操作系统时，直接基于打包的库函数，借助于操作系统的Linux内核来运行</li>
</ul>
<p><strong>Docker解决大型项目依赖关系复杂，不同组件依赖的兼容性问题</strong></p>
<ul>
<li>Docker允许开发中将应用、依赖、函数库、配置一起<strong>打包</strong>，形成可移植镜像</li>
<li>Docker应用运行在容器中，使用沙箱机制，相互<strong>隔离</strong></li>
</ul>
<p><strong>Docker解决开发、测试、生产环境有差异的问题</strong></p>
<ul>
<li>Docker镜像中包含完整运行环境，包括系统函数库，仅依赖系统的Linux内核，因此可以在任意Linux操作系统上运行</li>
</ul>
<p>Docker是一个<strong>快速交付应用、运行应用的技术</strong>：</p>
<ol>
<li>可以将程序及其依赖、运行环境一起打包为一个镜像，可以迁移到任意Linux操作系统</li>
<li>运行时利用沙箱机制形成隔离容器，各个应用互不干扰</li>
<li>启动、移除都可以通过一行命令完成，方便快捷</li>
</ol>
<p><strong>Docker与虚拟机</strong></p>
<p>虚拟机（Virtual Machine）是在操作系统中模拟硬件设备，然后运行另一个操作系统，比如在windows系统中运行Ubuntu系统，这样就可以运行任意Ubuntu应用了</p>
<p>Docker和虚拟机的茶语：</p>
<ul>
<li>docker是一个系统进程；虚拟机是在操作系统中的操作系统</li>
<li>docker体积小、启动速度快、性能好；虚拟机体积大、启动速度慢、性能一般</li>
</ul>
<table>
<thead>
<tr>
<th>特性</th>
<th>Docker</th>
<th>虚拟机</th>
</tr>
</thead>
<tbody><tr>
<td>性能</td>
<td>接近原生</td>
<td>性能较差</td>
</tr>
<tr>
<td>硬盘占用</td>
<td>一般为MB</td>
<td>一般为GB</td>
</tr>
<tr>
<td>启动</td>
<td>秒级</td>
<td>分钟级</td>
</tr>
</tbody></table>
<h2 id="8-1-Docker概述"><a href="#8-1-Docker概述" class="headerlink" title="8.1. Docker概述"></a>8.1. Docker概述</h2><p><strong>镜像和容器</strong></p>
<ul>
<li>镜像（Image）：Docker将应用程序及其所需的依赖、函数库、环境、配置等文件打包在一起，称为镜像。</li>
<li>容器（Container）：镜像中的应用程序运行后形成的进程就是容器，只是Docker会给容器做隔离，对外不可见。</li>
</ul>
<p><strong>Docker和DockerHub</strong></p>
<ul>
<li>DockerHub：DockerHub是一个Docker镜像的托管平台。这样的平台称为Docker Registry。</li>
<li>国内也有类似于DockerHub的公开服务，比如网易云镜像服务、阿里云镜像库等。</li>
</ul>
<p><strong>Docker架构</strong></p>
<p>Docker是一个CS架构的程序，由两部分组成：</p>
<ul>
<li>服务端（server）：Docker守护进程，负责处理Docker指令，管理镜像、容器等</li>
<li>客户端（client）：通过命令或RestAPI向Docker服务端发送指令。可以在本地或远程向服务端发送指令。</li>
</ul>
<p>架构分析</p>
<ul>
<li>Client发送命令<ul>
<li>docker build</li>
<li>docker pull</li>
<li>docker run</li>
</ul>
</li>
<li>DockerServer<ul>
<li>docker daemon守护进程</li>
<li>存放了镜像Image和数个相互隔离的容器</li>
</ul>
</li>
<li>Registry<ul>
<li>镜像托管服务器</li>
</ul>
</li>
</ul>
<p><strong>总结</strong>：</p>
<ol>
<li>镜像：应用程序及其依赖、环境、配置打包在一起</li>
<li>容器：镜像运行起来就是容器，一个镜像可以运行多个容器</li>
<li>Docker结构<ul>
<li>服务端：接收命令或远程请求，操作镜像或容器</li>
<li>客户端：发送命令或者请求到Docker服务器</li>
</ul>
</li>
<li>DockerHub：一个镜像托管的服务器，它们统称为DockerRegistry</li>
</ol>
<h2 id="8-2-Centos安装Docker"><a href="#8-2-Centos安装Docker" class="headerlink" title="8.2. Centos安装Docker"></a>8.2. Centos安装Docker</h2><p><strong>①卸载原有Docker</strong></p>
<p>如果之前安装过旧版本的Docker，可以使用下面命令卸载：</p>
<pre><code>yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-selinux \
                  docker-engine-selinux \
                  docker-engine \
                  docker-ce
</code></pre>
<p><strong>②安装docker</strong></p>
<p>首先需要虚拟机联网，<strong>安装yum工具</strong></p>
<pre><code class="sh">yum install -y yum-utils \
           device-mapper-persistent-data \
           lvm2 --skip-broken
</code></pre>
<p>然后<strong>更新本地镜像源</strong>：</p>
<pre><code class="shell"># 设置docker镜像源
yum-config-manager \
    --add-repo \
    https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
    
sed -i &#39;s/download.docker.com/mirrors.aliyun.com\/docker-ce/g&#39; /etc/yum.repos.d/docker-ce.repo

yum makecache fast
</code></pre>
<p>然后输入命令：</p>
<pre><code class="shell">yum install -y docker-ce
</code></pre>
<p><strong>docker-ce</strong>为社区免费版本。稍等片刻，docker即可安装成功。</p>
<p><strong>③启动docker</strong></p>
<p>Docker应用需要用到各种端口，逐一去修改防火墙设置。非常麻烦，因此建议直接关闭防火墙！</p>
<pre><code class="sh"># 关闭
systemctl stop firewalld
# 禁止开机启动防火墙
systemctl disable firewalld
</code></pre>
<p>通过命令<strong>启动docker</strong>：</p>
<pre><code class="sh">systemctl start docker  # 启动docker服务

systemctl stop docker  # 停止docker服务

systemctl restart docker  # 重启docker服务
</code></pre>
<p>然后输入命令，可以<strong>查看docker版本</strong>：</p>
<pre><code>docker -v
</code></pre>
<p><strong>④配置镜像加速</strong></p>
<p>docker官方镜像仓库网速较差，我们需要设置国内镜像服务：</p>
<p>参考阿里云的镜像加速文档：<a target="_blank" rel="noopener" href="https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors">https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors</a></p>
<pre><code class="bash"># linux控制台命令
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json &lt;&lt;-&#39;EOF&#39;
&#123;
  &quot;registry-mirrors&quot;: [&quot;https://43vmefya.mirror.aliyuncs.com&quot;]
&#125;
EOF
sudo systemctl daemon-reload
sudo systemctl restart docker
</code></pre>
<h2 id="8-3-Docker命令"><a href="#8-3-Docker命令" class="headerlink" title="8.3. Docker命令"></a>8.3. Docker命令</h2><h3 id="8-3-1-Docker命令帮助文档"><a href="#8-3-1-Docker命令帮助文档" class="headerlink" title="8.3.1 Docker命令帮助文档"></a>8.3.1 Docker命令帮助文档</h3><ul>
<li>docker –help</li>
<li>docker images –help</li>
</ul>
<h3 id="8-3-2-镜像相关命令"><a href="#8-3-2-镜像相关命令" class="headerlink" title="8.3.2 镜像相关命令"></a>8.3.2 镜像相关命令</h3><ul>
<li>镜像名称一般分为两部分组成：[repository]:[tag]</li>
<li>在没有指定tag时，默认是latest，代表最新版本的镜像</li>
<li>例：mysql:5.7<ul>
<li>repository就是mysql</li>
<li>tag就是5.7</li>
</ul>
</li>
</ul>
<ol>
<li>构建镜像：<strong>Dockerfile</strong>使用命令<strong>docker build</strong>进行对本地Local的Docker环境进行<strong>构建镜像</strong></li>
<li>推送镜像：本地Local的Docker使用命令<strong>docker push</strong>推送镜像到服务(镜像服务器Docker Registry)</li>
<li>拉取镜像：本地Local的Docker使用明亮<strong>docker pull</strong>从服务(镜像服务器Docker Registry)拉取镜像</li>
<li>查看镜像：<strong>docker images</strong></li>
<li>删除镜像：<strong>docker rmi</strong></li>
<li>保存镜像为一个压缩包tar：<strong>docker save</strong></li>
<li>加载压缩包为镜像：<strong>docker load</strong></li>
</ol>
<p><strong>使用案例</strong></p>
<ol>
<li><p>拉取nginx</p>
<ul>
<li>①打开镜像仓库DockerHub<a target="_blank" rel="noopener" href="https://hub.docker.com/%E6%90%9C%E7%B4%A2nginx">https://hub.docker.com/搜索nginx</a></li>
<li>②复制docker pull nginx到控制台进行安装Nginx</li>
<li>③使用docker images查看拉取到本地的镜像</li>
</ul>
</li>
<li><p>导出导入磁盘</p>
<ul>
<li><p>利用docker xx –help命令查看docker save和docker load的语法</p>
</li>
<li><p><strong>导出</strong></p>
<ol>
<li><p>docker save –help</p>
<p>查询到以下关键信息</p>
<pre><code class="bash"># 使用方式
Usage:  docker save [OPTIONS] IMAGE [IMAGE...]
Options:
# option选择
  -o, --output string   Write to a file, instead of STDOUT
</code></pre>
</li>
<li><p>查看镜像：docker images</p>
</li>
<li><p>保存：docker save -o nginx.tar nginx:latest</p>
</li>
<li><p>查看保存的镜像：ll</p>
</li>
</ol>
</li>
<li><p><strong>导入</strong></p>
<ol>
<li><p>查看镜像：docker images</p>
</li>
<li><p>删除Nginx镜像：docker rmi -f nginx:latest</p>
</li>
<li><p>docker load –help</p>
<p>查到以下帮助</p>
<pre><code class="bash">Usage:  docker load [OPTIONS]

Options:
  -i, --input string   Read from tar archive file, instead of STDIN
  -q, --quiet          Suppress the load output
</code></pre>
</li>
<li><p>导入：docker load -i nginx.tar</p>
</li>
</ol>
</li>
</ul>
</li>
</ol>
<h3 id="8-3-3-容器相关命令"><a href="#8-3-3-容器相关命令" class="headerlink" title="8.3.3 容器相关命令"></a>8.3.3 容器相关命令</h3><ul>
<li>运行：docker run</li>
<li>暂停：docker pause</li>
<li>取消暂停：docker unpause</li>
<li>停止：docker stop</li>
<li>停止后启动：docker start</li>
<li>进入容器执行命令：docker exec</li>
<li>查看容器运行日志：docker logs</li>
<li>查看所有运行的容器及状态：docker ps</li>
<li>删除指定容器：docker rm</li>
</ul>
<p><strong>使用案例1</strong></p>
<p><strong>创建运行一个Nginx容器</strong></p>
<p><strong>①docker hub查看Nginx容器运行命令</strong></p>
<pre><code class="bash">docker run --name some-nginx -d -p 8080:80 some-content-nginx
</code></pre>
<p>命令解读：</p>
<ul>
<li>docker run：创建并运行起一个容器</li>
<li>–name：给容器起名，mn【my nginx】</li>
<li>-p：将宿主机端口与容器端口映射，冒号左侧是宿主机端口，右侧是容器端口</li>
<li>-d：后台运行容器</li>
<li>some-content-nginx：镜像名称，例如nginx</li>
<li>原理：客户端通过<a target="_blank" rel="noopener" href="http://192.168.49.10/">http://192.168.49.10:80</a>访问Linux，通过绑定的80端口链接到Docker容器</li>
</ul>
<p><strong>②运行</strong></p>
<pre><code class="bash"> docker run --name mn -p 80:80 -d nginx:latest
</code></pre>
<p><strong>③查看容器状态</strong></p>
<pre><code class="bash">docker ps
</code></pre>
<p><strong>④查看nginx容器日志</strong></p>
<pre><code class="bash"># 持续查看日志
docker logs -f mn
</code></pre>
<p><strong>使用案例2</strong></p>
<p><strong>进入Nginx容器修改HTML内容</strong></p>
<p><strong>①进入容器</strong></p>
<pre><code class="bash">docker exec -it mn bash
</code></pre>
<p>命令解读：</p>
<ul>
<li>docker exec：进入容器内部，执行一个命令</li>
<li>-it：给当前进入的容器创建一个标准输入、输出终端，允许我们与容器交互</li>
<li>mn：要进入的容器的名称</li>
<li>bash：进入容器后执行的命令，bash是一个linux终端的交互命令</li>
</ul>
<p><strong>②进入nginx容器的HTML所在目录</strong></p>
<p>具体可在docker hub中查看</p>
<pre><code class="bash">cd /usr/share/nginx/html/
</code></pre>
<p><strong>③修改index.html的内容</strong></p>
<pre><code class="bash">sed -i &#39;s#Welcome to nginx#Bamboo welcome to you#g&#39; index.html
sed -i &#39;s#&lt;head&gt;#&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;#g&#39; index.html 
</code></pre>
<p><strong>④其他命令调用</strong></p>
<ul>
<li>docker stop mn：停止nginx容器</li>
<li>docker ps -a：查看所有状态的容器</li>
<li>docker rm -f mn：不能删除运行中的容器，除非添加 -f 参数</li>
<li>进入容器<ul>
<li>命令是docker exec -it [容器名] [要执行的命令]</li>
<li>exec命令可以进入容器修改文件，但是在容器内修改文件是<strong>不推荐</strong>的</li>
</ul>
</li>
</ul>
<p><strong>使用案例3</strong></p>
<p><strong>进入redis容器，执行redis-cli客户端命令，存入num&#x3D;666</strong></p>
<p>官网：start with persistent storage</p>
<pre><code class="console">$ docker run --name some-redis -d redis redis-server --save 60 1 --loglevel warning
</code></pre>
<p><strong>①启动redis容器</strong></p>
<pre><code class="bash">docker run --name mr -p 6379:6379 -d redis redis-server --save 60 1 --loglevel warning
</code></pre>
<p><strong>②进入redis容器</strong></p>
<pre><code class="bash">docker exec -it mr bash
# 或直接进入redis-cli
docker exec -it mr redis-cli
</code></pre>
<p><strong>③连接并使用redis</strong></p>
<pre><code class="bash"># 连接redis服务
redis-cli

# 查看keys
keys *
# 添加string类型key-value
set num 666
# 获取key为num的value
get num
# 退出
exit
</code></pre>
<h2 id="8-4-数据卷"><a href="#8-4-数据卷" class="headerlink" title="8.4. 数据卷"></a>8.4. 数据卷</h2><p>容器与数据耦合的问题：</p>
<ul>
<li><strong>不便于修改</strong>：修改Nginx的html内容时，需要进入容器内部修改，不方便</li>
<li><strong>数据不可复用</strong>：在容器内的修改对外是不可见的，所有修改对新创建的容器是不可复用的</li>
<li><strong>升级维护困难</strong>：数据在用期内，如果需要升级容器必然删除旧容器，所有数据都跟着删除了</li>
</ul>
<p><strong>数据卷（volume）</strong>是一个虚拟目录，指向宿主机文件系统中的某个目录</p>
<ul>
<li>DockerHost存在以下两个<ul>
<li>宿主机文件系统<ul>
<li>&#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes&#x2F;html</li>
<li>&#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes&#x2F;conf</li>
</ul>
</li>
<li>Volumes<ul>
<li>html：指向宿主机文件系统的html</li>
<li>conf：指向宿主机文件系统的conf</li>
</ul>
</li>
</ul>
</li>
<li>Container<ul>
<li>&#x2F;etc&#x2F;nginx&#x2F;conf指向Volumes中的conf</li>
<li>&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html指向Volumes中的html</li>
</ul>
</li>
</ul>
<h3 id="8-4-1-数据卷基本语法"><a href="#8-4-1-数据卷基本语法" class="headerlink" title="8.4.1 数据卷基本语法"></a>8.4.1 数据卷基本语法</h3><pre><code class="bash">docker volume [COMMAND]
</code></pre>
<p>docker volume命令是数据卷操作，根据命令后跟随的command来确定下一步的操作：</p>
<ul>
<li>create 创建一个volume</li>
<li>inspect 显示一个或多个volume的信息</li>
<li>ls 列出所有的volume</li>
<li>prune 删除未使用的volume</li>
<li>rm 删除一个或多个指定的volume</li>
</ul>
<p><strong>使用案例</strong></p>
<p><strong>①创建数据卷</strong></p>
<pre><code>docker volume create html
</code></pre>
<p><strong>②查看所有数据</strong></p>
<pre><code>docker volume ls
</code></pre>
<p><strong>③查看数据卷详细信息卷</strong></p>
<pre><code>docker volume inspect html
</code></pre>
<p><strong>④删除数据卷</strong></p>
<pre><code># 删除未使用的数据卷
docker volume prune
# 删除指定的数据卷
docker volume rm html
</code></pre>
<h3 id="8-4-2-数据卷挂载"><a href="#8-4-2-数据卷挂载" class="headerlink" title="8.4.2 数据卷挂载"></a>8.4.2 数据卷挂载</h3><p><strong>方式一：volume数据卷挂载</strong></p>
<ul>
<li>-v volumeName: &#x2F;targetContainerPath</li>
<li>如果容器运行时volume不存在，会自动被创建出来</li>
</ul>
<pre><code class="bash">docker run \				# 创建并运行容器
    --name mn \				# 给容器起名为mn
    -v html:/root/html \	# 把html数据卷挂载到容器内的/root/html这个目录中
    -p 8080:80 \			# 把宿主机的8080端口映射到容器内部的80端口
    nginx \					# 镜像名称
</code></pre>
<p><strong>方式二：目录挂载</strong></p>
<p>提示：目录挂载与数据卷挂载的语法是类似的：</p>
<ul>
<li>-v [宿主机目录]:[容器内目录]</li>
<li>-v [宿主机文件]:[容器内文件]</li>
</ul>
<p><strong>使用案例1</strong></p>
<p>创建nginx容器，修改容器内的html目录中的index.html</p>
<pre><code class="bash"># 创建容器并挂载html数据卷到容器内HTML目录
docker run --name mn -p 80:80 -v html:/usr/share/nginx/html -d nginx
# 查看html数据卷的位置
docker volume inspect html
# 进入html数据卷位置
cd /var/lib/docker/volumes/html/_data
# 查看目录文件
ls
</code></pre>
<p><strong>使用案例2</strong></p>
<p><strong>创建并运行MySQL 容器，将宿主机目录直接挂载到容器</strong></p>
<p><strong>①搭建初始环境</strong></p>
<pre><code># 拉取mysql
docker pull mysql:5.7.42
# 创建目录
mkdir -p /tmp/mysql/data
mkdir -p /tmp/mysql/conf
</code></pre>
<p><strong>②将hmy.cnf上传到&#x2F;tmp&#x2F;mysql&#x2F;conf</strong></p>
<pre><code class="bash"># hmy.cnf
[mysqld]
skip-name-resolve
character_set_server=utf8
datadir=/var/lib/mysql
server-id=1000
</code></pre>
<p><strong>③查阅docker hub挂载</strong></p>
<pre><code class="bash">docker run \ 
  --name mysql \
  -e MYSQL_ROOT_PASSWORD=root \
  -p 3306:3306 \
  -v /tmp/mysql/conf/hmy.cnf:/etc/mysql/conf.d/hmy.cnf \
  -v /tmp/mysql/data:/var/lib/mysql \
  -d \
  mysql:5.7.42
 
 # 或
 docker run  --name mysql  -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -v /tmp/mysql/conf/hmy.cnf:/etc/mysql/conf.d/hmy.cnf -v /tmp/mysql/data:/var/lib/mysql -d mysql:5.7.42
</code></pre>
<h3 id="8-4-3-数据卷挂载总结"><a href="#8-4-3-数据卷挂载总结" class="headerlink" title="8.4.3 数据卷挂载总结"></a>8.4.3 数据卷挂载总结</h3><ol>
<li>docker run命令通过-v参数挂载文件或目录到容器中：<ul>
<li>-v volume名称:容器内目录</li>
<li>-v 宿主机文件:容器内文件</li>
<li>-v 宿主机目录:容器内目录</li>
</ul>
</li>
<li>数据卷挂载与目录直接挂载的区别<ul>
<li>数据卷挂载耦合度低，由docker来管理目录，但是目录较深，不好找</li>
<li>目录挂载耦合度高，需要我们自己管理目录，不过目录容易寻找查看</li>
</ul>
</li>
</ol>
<h2 id="8-5-Dockerfile自定义镜像"><a href="#8-5-Dockerfile自定义镜像" class="headerlink" title="8.5. Dockerfile自定义镜像"></a>8.5. Dockerfile自定义镜像</h2><p><strong>镜像结构</strong></p>
<ul>
<li>镜像是将应用程序及其需要的系统函数库、环境、配置、依赖打包而成</li>
<li>它是一个分层结构，每一层称为一个Layer<ul>
<li>Entrypoint：镜像运行入口，一般是程序启动的脚本和参数</li>
<li>层：Layer，夹在Entrypoint和BaseImage中间，在BaseImage基础上添加安装包、依赖、配置等，每次操作都形成新的一层</li>
<li>BaseImage层：基础镜像层，包含基本的系统函数库、环境变量、文件系统</li>
</ul>
</li>
</ul>
<p><strong>Dockerfile</strong></p>
<p>Dockerfile就是一个文本文件，其中包含一个个指令(Instruction)，用指令来说明要执行说明操作来构建镜像，每个指令都会形成一层Layer</p>
<table>
<thead>
<tr>
<th>指令</th>
<th>说明</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>FROM</td>
<td>指定基础镜像</td>
<td>FROM centos:6</td>
</tr>
<tr>
<td>ENV</td>
<td>设置环境变量，可在后面指令使用</td>
<td>ENV key value</td>
</tr>
<tr>
<td>COPY</td>
<td>拷贝本地文件到镜像的指定目录</td>
<td>COPY .&#x2F;mysql-5.7.rpm &#x2F;tmp</td>
</tr>
<tr>
<td>RUN</td>
<td>执行Linux的shell命令，一般是安装过程的命令</td>
<td>RUN yum install gcc</td>
</tr>
<tr>
<td>EXPOSE</td>
<td>指定容器运行时监听的端口，是给镜像使用者看的</td>
<td>EXPOSE 8080</td>
</tr>
<tr>
<td>ENTRYPOINT</td>
<td>镜像中应用的启动命令，容器运行时调用</td>
<td>ENTRYPOINT java -jar xx.jar</td>
</tr>
</tbody></table>
<p><strong>①使用案例</strong></p>
<p>基于Ubuntu镜像构建一个新镜像，运行一个java项目</p>
<p><strong>Dockerfile文件内容</strong></p>
<pre><code class="dockerfile"># 1.指定基础镜像
FROM ubuntu:16.04

# 2.安装jdk
# 配置环境变量，JDK的安装目录
ENV JAVA_DIR=/usr/local

# 拷贝jdk和java项目的包
COPY ./jdk8.tar.gz $JAVA_DIR/

# 安装JDK
RUN cd $JAVA_DIR \
 &amp;&amp; tar -xf ./jdk8.tar.gz \
 &amp;&amp; mv ./jdk1.8.0_144 ./java8

# 配置环境变量
ENV JAVA_HOME=$JAVA_DIR/java8
ENV PATH=$PATH:$JAVA_HOME/bin

# 3.部署java项目
COPY ./docker-demo.jar /tmp/app.jar
# 暴露端口
EXPOSE 8090
# 入口，java项目的启动命令
ENTRYPOINT java -jar /tmp/app.jar
</code></pre>
<ol>
<li><p>新建一个空文件夹，将docker-demo.jar、jdk8.tar.gz、Dockerfile拷贝到此目录下</p>
<pre><code>mkdir -p /tmp/docker-demo
</code></pre>
</li>
<li><p>进入docker-demo目录运行命令</p>
<pre><code>docker build -t javaweb:1.0 .
</code></pre>
</li>
<li><p>查看镜像</p>
<pre><code>docker images
</code></pre>
</li>
<li><p>运行docker容器</p>
<pre><code>docker run --name web -p 8090:8090 -d javaweb:1.0
</code></pre>
</li>
<li><p>测试地址</p>
<pre><code>http://192.168.49.10:8090/hello/count
</code></pre>
</li>
</ol>
<p><strong>②基于java:8-alpine镜像</strong></p>
<p><strong>优化</strong>前一个使用案例的Dockerfile</p>
<pre><code class="dockerfile"># 指定基础镜像
FROM java:8-alpine

# 部署java项目
COPY ./docker-demo.jar /tmp/app.jar
# 暴露端口
EXPOSE 8090
# 入口，java项目的启动命令
ENTRYPOINT java -jar /tmp/app.jar
</code></pre>
<h2 id="8-6-DockerCompose"><a href="#8-6-DockerCompose" class="headerlink" title="8.6. DockerCompose"></a>8.6. DockerCompose</h2><p><strong>什么是DockerCompose</strong></p>
<ul>
<li><p>Docker Compose可以基于Compose文件帮我们快速部署分布式应用，而无需手动一个个创建和运行容器</p>
</li>
<li><p>Compose文件是一个文本文件，通过指令定义集群中的每个容器如何运行</p>
<pre><code class="yml">version:&quot;3.8&quot;

services:
  mysql:
    image: mysql:5.7.42
    environment:
      MYSQL_ROOT_PASSWORD: 123
    volumes:
      - /tmp/mysql/data:/var/lib/mysql
      - /tmp/mysql/conf/hmy.cnf:/etc/mysql/conf.d/hmy.cnf
  web:
    build: .
    ports:
    - 8090: 8090
</code></pre>
</li>
</ul>
<p><strong>CentOS7安装DockerCompose</strong></p>
<p><strong>①下载</strong></p>
<p>Linux下需要通过命令下载：</p>
<pre><code class="sh"># 安装
curl -L https://github.com/docker/compose/releases/download/1.23.1/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose
</code></pre>
<p>上传docker-compose到<code>/usr/local/bin/</code>目录也可以</p>
<p><strong>②修改文件权限</strong></p>
<pre><code class="sh"># 修改权限
chmod +x /usr/local/bin/docker-compose
</code></pre>
<p><strong>③Base自动补全命令</strong></p>
<pre><code class="sh"># 补全命令
curl -L https://raw.githubusercontent.com/docker/compose/1.29.1/contrib/completion/bash/docker-compose &gt; /etc/bash_completion.d/docker-compose
</code></pre>
<p>如果这里出现错误，需要修改自己的hosts文件：</p>
<pre><code class="sh">echo &quot;199.232.68.133 raw.githubusercontent.com&quot; &gt;&gt; /etc/hosts
</code></pre>
<p><strong>实例：部署微服务项目至Docker</strong></p>
<p><strong>①文件目录</strong></p>
<ul>
<li><p>cloud-demo</p>
<ul>
<li><p>gateway</p>
<ul>
<li><p>app.jar</p>
</li>
<li><p>Dockerfile</p>
<pre><code class="dockerfile">FROM java:8-alpine
COPY ./app.jar /tmp/app.jar
ENTRYPOINT java -jar /tmp/app.jar
</code></pre>
</li>
</ul>
</li>
<li><p>mysql</p>
<ul>
<li><p>conf</p>
<ul>
<li><p>hmy.cnf</p>
<pre><code class="cnf">[mysqld]
skip-name-resolve
character_set_server=utf8
datadir=/var/lib/mysql
server-id=1000
</code></pre>
</li>
</ul>
</li>
<li><p>data</p>
</li>
</ul>
</li>
<li><p>order-service</p>
<ul>
<li><p>app.jar</p>
</li>
<li><p>Dockerfile</p>
<pre><code class="dockerfile">FROM java:8-alpine
COPY ./app.jar /tmp/app.jar
ENTRYPOINT java -jar /tmp/app.jar
</code></pre>
</li>
</ul>
</li>
<li><p>user-service</p>
<ul>
<li><p>app.jar</p>
</li>
<li><p>Dockerfile</p>
<pre><code class="dockerfile">FROM java:8-alpine
COPY ./app.jar /tmp/app.jar
ENTRYPOINT java -jar /tmp/app.jar
</code></pre>
</li>
</ul>
</li>
<li><p>docker-compose.yml</p>
<pre><code class="yml">version: &quot;3.2&quot;

services:
  nacos:
  # docker pull nacos/nacos-server 相当于拉取了一个nacos镜像
    image: nacos/nacos-server
    environment:
      MODE: standalone
    ports:
      - &quot;8848:8848&quot;
  mysql:
    image: mysql:5.7.42
    environment:
      MYSQL_ROOT_PASSWORD: root
    volumes:
    # $PWD为当前linux目录
      - &quot;$PWD/mysql/data:/var/lib/mysql&quot;
      - &quot;$PWD/mysql/conf:/etc/mysql/conf.d/&quot;
  userservice:
      # 在当前目录的suer-service下找docker进行构建
    build: ./user-service
  orderservice:
    build: ./order-service
  gateway:
    build: ./gateway
    ports:
      - &quot;10010:10010&quot;
</code></pre>
</li>
</ul>
</li>
</ul>
<p><strong>②修改本地项目yml</strong></p>
<p>  将地址改成服务名称</p>
<pre><code class="yml">spring:
  datasource:
    url: jdbc:mysql://mysql:3306/cloud_user?useSSL=false
    username: root
    password: root
    driver-class-name: com.mysql.jdbc.Driver
  cloud:
    nacos:
      server-addr: nacos:8848 # Nacos服务端地址  
</code></pre>
<p><strong>③本地项目打包</strong></p>
<pre><code class="xml">&lt;build&gt;
    &lt;finalName&gt;app&lt;/finalName&gt;
    &lt;plugins&gt;
        &lt;plugin&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt;
&lt;/build&gt;
</code></pre>
<p>注：</p>
<ul>
<li>feign-api不需要添加此配置，只需要增加<code>&lt;packaging&gt;jar&lt;/packaging&gt;</code>即可</li>
<li>父pom不要设置spring-boot-maven-plugin</li>
</ul>
<p><strong>④上传linux</strong></p>
<ol>
<li>将cloud-demo上传至&#x2F;tmp并进入文件夹内</li>
<li>docker-compose up -d 后台运行启动</li>
<li>docker-compose –help 查看命令帮助</li>
<li>docker ps 查看状态</li>
<li>docker-compose logs -f 查看并跟踪日志<ul>
<li>发现错误，nacos未启动时其他微服务注册</li>
</ul>
</li>
<li>docker-compose restart gateway userservice orderservice 重启服务解决nacos注册问题</li>
</ol>
<h2 id="8-7-Docker镜像仓库"><a href="#8-7-Docker镜像仓库" class="headerlink" title="8.7. Docker镜像仓库"></a>8.7. Docker镜像仓库</h2><h3 id="8-7-1-搭建私有仓库"><a href="#8-7-1-搭建私有仓库" class="headerlink" title="8.7.1 搭建私有仓库"></a>8.7.1 搭建私有仓库</h3><p>搭建镜像仓库可以基于Docker官方提供的DockerRegistry来实现。</p>
<p>官网地址：<a target="_blank" rel="noopener" href="https://hub.docker.com/_/registry">https://hub.docker.com/_/registry</a></p>
<p><strong>①简化版镜像仓库</strong></p>
<p>Docker官方的Docker Registry是一个基础版本的Docker镜像仓库，具备仓库管理的完整功能，但是没有图形化界面。</p>
<p>搭建方式比较简单，命令如下：</p>
<pre><code class="sh">docker run -d \
    --restart=always \
    --name registry	\
    -p 5000:5000 \
    -v registry-data:/var/lib/registry \
    registry
</code></pre>
<p>命令中挂载了一个数据卷registry-data到容器内的&#x2F;var&#x2F;lib&#x2F;registry 目录，这是私有镜像库存放数据的目录。</p>
<p>访问<a target="_blank" rel="noopener" href="http://yourip:5000/v2/_catalog">http://YourIp:5000/v2/_catalog</a> 可以查看当前私有镜像服务中包含的镜像</p>
<p><strong>②带有图形化界面版本</strong></p>
<p>使用DockerCompose部署带有图象界面的DockerRegistry，命令如下：</p>
<pre><code class="yaml">version: &#39;3.0&#39;
services:
  registry:
    image: registry
    volumes:
      - ./registry-data:/var/lib/registry
  ui:
    image: joxit/docker-registry-ui:static
    ports:
      - 8080:80
    environment:
      - REGISTRY_TITLE=烛龙私有仓库
      - REGISTRY_URL=http://registry:5000
    depends_on:
      - registry
</code></pre>
<p><strong>③配置Docker信任地址</strong></p>
<p>我们的私服采用的是http协议，默认不被Docker信任，所以需要做一个配置：</p>
<pre><code class="sh"># 打开要修改的文件
vi /etc/docker/daemon.json
# 添加内容：
&quot;insecure-registries&quot;:[&quot;http://192.168.150.101:8080&quot;]
# 重加载
systemctl daemon-reload
# 重启docker
systemctl restart docker
</code></pre>
<h3 id="8-7-2-私有镜像仓库拉取推送"><a href="#8-7-2-私有镜像仓库拉取推送" class="headerlink" title="8.7.2 私有镜像仓库拉取推送"></a>8.7.2 私有镜像仓库拉取推送</h3><p>①重新tag本地镜像，名称前缀为私有仓库地址：192.168.49.10:8080</p>
<pre><code>docker tag nginx:latest 192.168.49.10:8080/nginx:1.0
</code></pre>
<p>②推送镜像</p>
<pre><code>docker push 192.168.49.10:8080/nginx:1.0
</code></pre>
<p>③拉取镜像</p>
<pre><code>docker pull 192.168.49.10:8080/nginx:1.0
</code></pre>
<h1 id="九、RabbitMQ服务异步通讯"><a href="#九、RabbitMQ服务异步通讯" class="headerlink" title="九、RabbitMQ服务异步通讯"></a>九、RabbitMQ服务异步通讯</h1><h2 id="9-1-同步与异步"><a href="#9-1-同步与异步" class="headerlink" title="9.1. 同步与异步"></a>9.1. 同步与异步</h2><p><strong>同步</strong>调用问题：微服务之间基于Feign的调用就属于同步方式</p>
<ul>
<li>如多个服务之间逐个调用，调用时间过长</li>
<li>如中间调用某一服务宕机，则会将调用卡到此处无法继续调用其他服务</li>
</ul>
<p>会导致：</p>
<ol>
<li>耦合度高<ul>
<li>每次加入新的需求，都要修改原来的代码</li>
</ul>
</li>
<li>性能下降<ul>
<li>调用者需要等待服务提供者响应，如果调用链过长则响应时间等于每次调用时间之和</li>
</ul>
</li>
<li>资源浪费<ul>
<li>调用链中的每个服务在等待响应过程中，不能释放请求占用的资源，高并发场景下回嫉妒浪费系统资源</li>
</ul>
</li>
<li>级联失败<ul>
<li>如果服务提供者出现问题，所有调用方都会跟着出问题，如同多米诺骨牌，迅速导致整个微服务群故障</li>
</ul>
</li>
</ol>
<p>同步调用<strong>优点</strong>：</p>
<ol>
<li>时效性较强，可以立即得到结果</li>
</ol>
<p>同步调用<strong>问题</strong>：</p>
<ol>
<li>耦合度高</li>
<li>性能和吞吐能力下降</li>
<li>有额外的资源消耗</li>
<li>有级联失败问题</li>
</ol>
<p><strong>异步</strong>调用常见实现是事件驱动模式，Broker实现</p>
<p>异步通信的优点：</p>
<ol>
<li>耦合度低</li>
<li>吞吐量提升</li>
<li>故障隔离</li>
<li>流量削峰</li>
</ol>
<p>异步通信缺点：</p>
<ol>
<li>依赖于Broker的可靠性、安全性、吞吐能力</li>
<li>架构复杂，业务没有明显的流程线，不好追踪管理</li>
</ol>
<h2 id="9-2-MQ概念"><a href="#9-2-MQ概念" class="headerlink" title="9.2. MQ概念"></a>9.2. MQ概念</h2><p>MQ（MessageQueue），中文<strong>消息队列</strong>，存放消息的队列，事件驱动架构中的Broker</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">RabbitMQ</th>
<th align="center">ActiveMQ</th>
<th align="center">RocketMQ</th>
<th align="center">Kafka</th>
</tr>
</thead>
<tbody><tr>
<td align="center">公司&#x2F;社区</td>
<td align="center">Rabbit</td>
<td align="center">Apache</td>
<td align="center">阿里</td>
<td align="center">Apache</td>
</tr>
<tr>
<td align="center">开发语言</td>
<td align="center">Erlang</td>
<td align="center">Java</td>
<td align="center">Java</td>
<td align="center">Scala&amp;Java</td>
</tr>
<tr>
<td align="center">协议支持</td>
<td align="center">AMQP,XMPP,SMTP,STOMP</td>
<td align="center">OpenWire,STOMP,REST,XMPP,AMQP</td>
<td align="center">自定义协议</td>
<td align="center">自定义协议</td>
</tr>
<tr>
<td align="center">可用性</td>
<td align="center">高</td>
<td align="center">一般</td>
<td align="center">高</td>
<td align="center">高</td>
</tr>
<tr>
<td align="center">单机吞吐量</td>
<td align="center">一般</td>
<td align="center">差</td>
<td align="center">高</td>
<td align="center">非常高</td>
</tr>
<tr>
<td align="center">消息延迟</td>
<td align="center">微秒级</td>
<td align="center">毫秒级</td>
<td align="center">毫秒级</td>
<td align="center">毫秒以内</td>
</tr>
<tr>
<td align="center">消息可靠性</td>
<td align="center">高</td>
<td align="center">一般</td>
<td align="center">高</td>
<td align="center">一般</td>
</tr>
</tbody></table>
<h2 id="9-3-RabbitMQ部署"><a href="#9-3-RabbitMQ部署" class="headerlink" title="9.3. RabbitMQ部署"></a>9.3. RabbitMQ部署</h2><p><strong>①下载镜像</strong></p>
<ul>
<li><p>本地拉取：将my.tar放进&#x2F;tmp中，执行命令</p>
<pre><code class="bash">docker load -i mq.tar
</code></pre>
</li>
<li><p>在线拉取</p>
<pre><code class="bash">docker pull rabbitmq:3-management
</code></pre>
</li>
</ul>
<p><strong>②安装容器</strong></p>
<pre><code class="bash">执行下面的命令来运行MQ容器：

docker run \
 -e RABBITMQ_DEFAULT_USER=bamboo \
 -e RABBITMQ_DEFAULT_PASS=root \
 --name mq \
 --hostname mq1 \
 -p 15672:15672 \
 -p 5672:5672 \
 -d \
 rabbitmq:3-management
</code></pre>
<p><strong>RabbitMQ中的几个概念</strong></p>
<ul>
<li>channel：操作MQ的工具</li>
<li>exchange：路由消息到队列中</li>
<li>queue：缓存消息</li>
<li>virtual host：虚拟主机，是对queue、excahnge等资源的逻辑分组</li>
</ul>
<h2 id="9-4-常见消息模型"><a href="#9-4-常见消息模型" class="headerlink" title="9.4. 常见消息模型"></a>9.4. 常见消息模型</h2><p>MQ官方文档给出了<strong>五个</strong>MQ的Demo示例，对应了几种不同的用法：</p>
<ul>
<li>基本消息队列（BasicQueue）</li>
<li>工作消息队列（WorkQueue）</li>
<li>发布订阅（Publish、Subscribe），又根据交换机类型不同分为三种：<ul>
<li>Fanout Exchange：广播</li>
<li>Direct Exchange：路由</li>
<li>Topic Exchange：主题</li>
</ul>
</li>
</ul>
<p><strong>HelloWorld案例</strong></p>
<p>官方的HelloWorld是基于最基础的消息队列模型来实现的，只包括三个角色：</p>
<ul>
<li>publisher：消息发布者，将消息发送到队列queue</li>
<li>queue：消息队列，负责接受并缓存消息</li>
<li>consumer：订阅队列，处理队列中的消息，处理完后此消息在队列中被销毁</li>
</ul>
<p>publisher —&gt; queque —&gt; consumer </p>
<p>基本消息队列的消息<strong>发送流程</strong>：</p>
<ol>
<li>建立connection</li>
<li>创建channel</li>
<li>利用channel声明队列</li>
<li>利用channel向队列发送消息</li>
</ol>
<pre><code class="java">package cn.itcast.mq.helloworld;

import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;
import org.junit.Test;

import java.io.IOException;
import java.util.concurrent.TimeoutException;

public class PublisherTest &#123;
    @Test
    public void testSendMessage() throws IOException, TimeoutException &#123;
        // 1.建立连接
        ConnectionFactory factory = new ConnectionFactory();
        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码
        factory.setHost(&quot;192.168.49.10&quot;);
        factory.setPort(5672);
        factory.setVirtualHost(&quot;/&quot;);
        factory.setUsername(&quot;bamboo&quot;);
        factory.setPassword(&quot;root&quot;);
        // 1.2.建立连接
        Connection connection = factory.newConnection();

        // 2.创建通道Channel
        Channel channel = connection.createChannel();

        // 3.创建队列
        String queueName = &quot;simple.queue&quot;;
        channel.queueDeclare(queueName, false, false, false, null);

        // 4.发送消息
        String message = &quot;hello, rabbitmq!&quot;;
        channel.basicPublish(&quot;&quot;, queueName, null, message.getBytes());
        System.out.println(&quot;发送消息成功：【&quot; + message + &quot;】&quot;);

        // 5.关闭通道和连接
        channel.close();
        connection.close();

    &#125;
&#125;
</code></pre>
<p>基本消息队列的消息<strong>接收流程</strong>：</p>
<ol>
<li>建立connection</li>
<li>创建channel</li>
<li>利用channel声明队列</li>
<li>定义consumer的消费行为handleDelivery()</li>
<li>利用channel将消费者与队列绑定</li>
</ol>
<pre><code class="java">package cn.itcast.mq.helloworld;

import com.rabbitmq.client.*;

import java.io.IOException;
import java.util.concurrent.TimeoutException;

public class ConsumerTest &#123;

    public static void main(String[] args) throws IOException, TimeoutException &#123;
        // 1.建立连接
        ConnectionFactory factory = new ConnectionFactory();
        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码
        factory.setHost(&quot;192.168.49.10&quot;);
        factory.setPort(5672);
        factory.setVirtualHost(&quot;/&quot;);
        factory.setUsername(&quot;bamboo&quot;);
        factory.setPassword(&quot;root&quot;);
        // 1.2.建立连接
        Connection connection = factory.newConnection();

        // 2.创建通道Channel
        Channel channel = connection.createChannel();

        // 3.创建队列
        String queueName = &quot;simple.queue&quot;;
        channel.queueDeclare(queueName, false, false, false, null);

        // 4.订阅消息
        channel.basicConsume(queueName, true, new DefaultConsumer(channel)&#123;
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope,
                                       AMQP.BasicProperties properties, byte[] body) throws IOException &#123;
                // 5.处理消息
                String message = new String(body);
                System.out.println(&quot;接收到消息：【&quot; + message + &quot;】&quot;);
            &#125;
        &#125;);
        System.out.println(&quot;等待接收消息。。。。&quot;);
    &#125;
&#125;
</code></pre>
<h2 id="9-5-SpringAMQP"><a href="#9-5-SpringAMQP" class="headerlink" title="9.5. SpringAMQP"></a>9.5. SpringAMQP</h2><p><strong>AMQP</strong>：全称Advanced Message Queuing Protocal（高级消息队列协议），是用于应用程序之间传递业务消息的开放标准。该协议与语言和平台无关，更符合微服务中独立性的要求。</p>
<p><strong>Spring AMQP</strong>是基于AMQP协议定义的一套API规范，提供了模块来发送和接收消息。包含两部分，其中<strong>spring-amqp</strong>是基础抽象，<strong>spring-rabbit</strong>是底层的默认实现。</p>
<p><strong>使用事项</strong></p>
<ul>
<li>发送<ul>
<li>注入RabbitTemplate</li>
<li>调用convertAndSend()方法发送</li>
</ul>
</li>
<li>接收<ul>
<li>创建类添加@Componet组件，方法注入@RabbitListener(queues &#x3D; “simple.queue”)</li>
<li>启动SpringBoot自动接收</li>
</ul>
</li>
</ul>
<p><strong>①引入SpringAMQP依赖</strong></p>
<pre><code class="xml">&lt;!--AMQP依赖，包含RabbitMQ--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p><strong>②编辑application.yml</strong></p>
<pre><code class="yml">spring:
  rabbitmq:
    host: 192.168.49.10 # 主机名
    port: 5672 # 端口号
    virtual-host: / # 虚拟主机
    username: bamboo # 用户名
    password: root # 密码
</code></pre>
<p><strong>③发送&#x2F;接收消息</strong></p>
<h3 id="9-5-1-BasicQueue基本消息队列"><a href="#9-5-1-BasicQueue基本消息队列" class="headerlink" title="9.5.1 BasicQueue基本消息队列"></a>9.5.1 BasicQueue基本消息队列</h3><p><strong>发送</strong>simple.queue</p>
<pre><code class="java">@RunWith(SpringRunner.class)
@SpringBootTest
public class SpringAMQPTest &#123;
    @Autowired
    private RabbitTemplate rabbitTemplate;

    @Test
    public void testSendMessageSimpleQueue() &#123;
        String queueName = &quot;simple.queue&quot;;
        String message = &quot;hello,spring amqp!&quot;;
        rabbitTemplate.convertAndSend(queueName, message);
        System.out.println(&quot;消息发送成功：&quot;);
        System.out.println(&quot;队列名：&quot; + queueName);
        System.out.println(&quot;消息：&quot; + message);
    &#125;
&#125;
</code></pre>
<p><strong>接收</strong>simple.queue</p>
<ol>
<li><p>添加一个组件，接收消息</p>
<pre><code class="java">@Component
public class SpringRabbitListener &#123;

    // basicQueue
    @RabbitListener(queues = &quot;simple.queue&quot;)
    public void listenSimpleQueue(String msg) &#123;
        System.out.println(&quot;消费者接收到simple.queue的消息：【&quot; + msg + &quot;】&quot;);
    &#125;
&#125;
</code></pre>
</li>
<li><p>启动SpringBoot</p>
<pre><code class="java">@SpringBootApplication
public class ConsumerApplication &#123;
    public static void main(String[] args) &#123;
        SpringApplication.run(ConsumerApplication.class, args);
    &#125;
&#125;
</code></pre>
</li>
</ol>
<h3 id="9-5-2-WorkQueue工作消息队列"><a href="#9-5-2-WorkQueue工作消息队列" class="headerlink" title="9.5.2 WorkQueue工作消息队列"></a>9.5.2 WorkQueue工作消息队列</h3><p>可以提高消息处理速度，避免队列消息堆积</p>
<ul>
<li>publisher<ul>
<li>queue<ul>
<li>consumer1</li>
<li>consumer2</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>案例</strong></p>
<p>模拟WorkQueue，实现一个队列绑定多个消费者</p>
<ol>
<li><p>Publisher</p>
<pre><code class="java">@RunWith(SpringRunner.class)
@SpringBootTest
public class SpringAMQPTest &#123;
    @Autowired
    private RabbitTemplate rabbitTemplate;

    @Test
    public void testSendMessageWorkQueue() throws InterruptedException &#123;
        String queueName = &quot;simple.queue&quot;;
        String message = &quot;hello, message__&quot;;
        for (int i = 1; i &lt;= 50; i++) &#123;
            rabbitTemplate.convertAndSend(queueName, message + i);
            Thread.sleep(20);
        &#125;
    &#125;
&#125;
</code></pre>
</li>
<li><p>Consumer</p>
<pre><code class="java">@Component
public class SpringRabbitListener &#123;
    
    // workQueue
    @RabbitListener(queues = &quot;simple.queue&quot;)
    public void listenWorkQueue1(String msg) throws InterruptedException &#123;
        System.out.println(&quot;消费者1接收到消息：【&quot; + msg + &quot;】 &quot; + LocalTime.now());
        Thread.sleep(20);
    &#125;
    @RabbitListener(queues = &quot;simple.queue&quot;)
    public void listenWorkQueue2(String msg) throws InterruptedException &#123;
        System.err.println(&quot;消费者2接收到消息：【&quot; + msg + &quot;】 &quot; + LocalTime.now());
        Thread.sleep(200);
    &#125;
&#125;
</code></pre>
</li>
<li><p>Consumer下的application.yml设置prefetch</p>
<pre><code class="yml">logging:
  pattern:
    dateformat: MM-dd HH:mm:ss:SSS
spring:
  rabbitmq:
    host: 192.168.49.10 # 主机名
    port: 5672 # 端口号
    virtual-host: / # 虚拟主机
    username: bamboo # 用户名
    password: root # 密码
    listener:
      simple:
        prefetch: 1 # 每次只能获取一条消息，处理完成才能获取下一个消息，默认接收消息无限制
</code></pre>
</li>
</ol>
<h3 id="9-5-3-发布订阅（Publish、Subscribe）"><a href="#9-5-3-发布订阅（Publish、Subscribe）" class="headerlink" title="9.5.3 发布订阅（Publish、Subscribe）"></a>9.5.3 发布订阅（Publish、Subscribe）</h3><p>发布订阅模式的特点是允许将同一消息发送给多个消费者，实现方式是加入exchange（交换机），常见exchange类型包括：</p>
<ul>
<li>Fanout：广播</li>
<li>Direct：路由</li>
<li>Topic：话题</li>
</ul>
<p><strong>注意</strong>：exchange负责消息路由，而不是存储，路由失败则消息丢失</p>
<h4 id="①-Fanout-Exchange"><a href="#①-Fanout-Exchange" class="headerlink" title="① Fanout Exchange"></a>① Fanout Exchange</h4><p>Fanout Exchange会将接收到的消息路由到每一个跟其绑定的queue</p>
<ul>
<li>publisher<ul>
<li>excahnge【itcast.fanout】<ul>
<li>fanout.queue1<ul>
<li>consumer1</li>
</ul>
</li>
<li>fanout.queue2<ul>
<li>consumer2</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>①在consumer服务声明Exchange、Queue、Binding作为FanoutConfig</strong></p>
<pre><code class="java">//创建config包下的FanoutConfig类
package cn.itcast.mq.config;

import org.springframework.amqp.core.Binding;
import org.springframework.amqp.core.BindingBuilder;
import org.springframework.amqp.core.FanoutExchange;
import org.springframework.amqp.core.Queue;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/23 13:39
 */
@Configuration
public class FanoutConfig &#123;
    // 声明FanoutExchange交换机
    @Bean
    public FanoutExchange fanoutExchange() &#123;
        return new FanoutExchange(&quot;itcast.fanout&quot;);
    &#125;

    // 声明第一个队列，bean的名称为fanoutQueue1
    @Bean
    public Queue fanoutQueue1() &#123;
        return new Queue(&quot;fanout.queue1&quot;);
    &#125;
    // 绑定队列1和交换机
    @Bean
    public Binding bindingQueue1(Queue fanoutQueue1,FanoutExchange fanoutExchange) &#123;
        return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange);
    &#125;
    // 声明第二个队列
    @Bean
    public Queue fanoutQueue2() &#123;
        return new Queue(&quot;fanout.queue2&quot;);
    &#125;
    // 绑定队列2和交换机
    @Bean
    public Binding bindingQueue2(Queue fanoutQueue2,FanoutExchange fanoutExchange) &#123;
        return BindingBuilder.bind(fanoutQueue2).to(fanoutExchange);
    &#125;
&#125;
</code></pre>
<p><strong>②修改监听组件</strong></p>
<pre><code class="java">package cn.itcast.mq.listener;

import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.stereotype.Component;

import java.time.LocalTime;

/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/22 22:09
 */
@Component
public class SpringRabbitListener &#123;
    // fanout exchange发布订阅
    @RabbitListener(queues = &quot;fanout.queue1&quot;)
    public void listenFanoutQueue1(String msg) &#123;
        System.out.println(&quot;消费者接收到fanout.queue1的消息：【&quot; + msg + &quot;】&quot;);
    &#125;
    @RabbitListener(queues = &quot;fanout.queue2&quot;)
    public void listenFanoutQueue2(String msg) &#123;
        System.out.println(&quot;消费者接收到fanout.queue2的消息：【&quot; + msg + &quot;】&quot;);
    &#125;
&#125;
</code></pre>
<p><strong>③启动consumer服务</strong>等待消息接收</p>
<p><strong>④编写publisher代码</strong>发送消息</p>
<pre><code class="java">@RunWith(SpringRunner.class)
@SpringBootTest
public class SpringAMQPTest &#123;
    @Autowired
    private RabbitTemplate rabbitTemplate;

    // fanout exchange
    @Test
    public void testSendFanoutExchange() &#123;
        // 交换机名称
        String exchangeName = &quot;itcast.fanout&quot;;
        // 消息
        String message = &quot;hello, every one!&quot;;
        // 发送消息，参数分别是：交互机名称、RoutingKey（暂时为空）、消息
        rabbitTemplate.convertAndSend(exchangeName,&quot;&quot;,message);
    &#125;
&#125;
</code></pre>
<p><strong>⑤结果</strong>：publisher发布一次消息，consumer的多个订阅将接收到信息</p>
<h4 id="②-Direct-Exchange"><a href="#②-Direct-Exchange" class="headerlink" title="② Direct Exchange"></a>② Direct Exchange</h4><p>Direct Exchange会将接收到的消息根据规则路由到指定的Queue，因此称为路由模式(routes)</p>
<ul>
<li>每一个Queue都与Exchange设置一个BindingKey</li>
<li>发布者发布消息时，指定消息的RoutingKey</li>
<li>Exchange将消息路由到BindingKey与消息RoutingKey一致的队列</li>
</ul>
<p><strong>@RabbitListenner注解</strong></p>
<p><strong>@Queue注解</strong></p>
<p><strong>@Exchange注解</strong></p>
<p>①使用@RabbitListener设置consumer</p>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/22 22:09
 */
@Component
public class SpringRabbitListener &#123;
    // direct exchange发布订阅
    @RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = &quot;direct.queue1&quot;),
            exchange = @Exchange(name = &quot;itcast.direct&quot;, type = ExchangeTypes.DIRECT),
            key = &#123;&quot;red&quot;, &quot;blue&quot;&#125;
    ))
    public void listenDirectQueue1(String msg) &#123;
        System.out.println(&quot;消费者收到derect.queue1的消息：【&quot; + msg + &quot;】&quot;);
    &#125;
    @RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = &quot;direct.queue2&quot;),
            exchange = @Exchange(name = &quot;itcast.direct&quot;, type = ExchangeTypes.DIRECT),
            key = &#123;&quot;red&quot;, &quot;yellow&quot;&#125;
    ))
    public void listenDirectQueue2(String msg) &#123;
        System.out.println(&quot;消费者收到derect.queue2的消息：【&quot; + msg + &quot;】&quot;);
    &#125;
&#125;
</code></pre>
<p>②publisher发送消息</p>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/22 21:46
 */

@RunWith(SpringRunner.class)
@SpringBootTest
public class SpringAMQPTest &#123;
    @Autowired
    private RabbitTemplate rabbitTemplate;

    @Test
    public void testSendDirectExchange() &#123;
        // 交换机名称
        String exchangeName = &quot;itcast.direct&quot;;
        // 消息
        String message = &quot;hello, direct routes!&quot;;
        // 发送消息
        rabbitTemplate.convertAndSend(exchangeName,&quot;yellow&quot;,message);
    &#125;
&#125;
</code></pre>
<h4 id="③-Topic-Exchange"><a href="#③-Topic-Exchange" class="headerlink" title="③ Topic Exchange"></a>③ Topic Exchange</h4><p>与DirectExchange类似，区别在于routingKey必须是多个单词的列表，并且以<code>.</code>分割。</p>
<p>Queue与Exchange指定BindingKey时可以使用通配符：</p>
<ul>
<li>#：代指0个或多个单词</li>
<li>*：代指一个单词</li>
</ul>
<p><strong>①编写consumer监听</strong></p>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/22 22:09
 */
@Component
public class SpringRabbitListener &#123;

    // topic exchange
    @RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = &quot;topic.queue1&quot;),
            exchange = @Exchange(name = &quot;itcast.topic&quot;, type = ExchangeTypes.TOPIC),
            key = &quot;china.#&quot;
    ))
    public void listenTopicQueue1(String msg) &#123;
        System.out.println(&quot;消费者接收到topic.queue1的消息：【&quot; + msg + &quot;】&quot;);
    &#125;
    @RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = &quot;topic.queue2&quot;),
            exchange = @Exchange(name = &quot;itcast.topic&quot;, type = ExchangeTypes.TOPIC),
            key = &quot;#.news&quot;
    ))
    public void listenTopicQueue2(String msg) &#123;
        System.out.println(&quot;消费者接收到topic.queue2的消息：【&quot; + msg + &quot;】&quot;);
    &#125;
    
&#125;
</code></pre>
<p><strong>②编写publisher代码</strong></p>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/22 21:46
 */

@RunWith(SpringRunner.class)
@SpringBootTest
public class SpringAMQPTest &#123;

    @Autowired
    private RabbitTemplate rabbitTemplate;

    // topic exchange
    @Test
    public void testSendTopicExchange() &#123;
        // 交换机名称
        String exchangeName = &quot;itcast.topic&quot;;
        // 消息
        String message = &quot;hello, china topic!&quot;;
        // 发送消息
        rabbitTemplate.convertAndSend(exchangeName,&quot;china.#&quot;,message);
    &#125;
&#125;
</code></pre>
<h2 id="9-6-SpringAMQP消息转换器"><a href="#9-6-SpringAMQP消息转换器" class="headerlink" title="9.6. SpringAMQP消息转换器"></a>9.6. SpringAMQP消息转换器</h2><p>消息转换器实现序列化和反序列化</p>
<ul>
<li>原生是利用JDK的序列化进行默认实现MessageConverter</li>
<li>注意发送方与接收方必须使用相同的MessageConverter</li>
</ul>
<p><strong>简单测试</strong></p>
<p><strong>发送消息</strong>：注册一个队列bean</p>
<pre><code class="java">package cn.itcast.mq.config;

/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/23 13:39
 */
@Configuration
public class FanoutConfig &#123;
    @Bean
    public Queue objectQueue() &#123;
        return new Queue(&quot;object.queue&quot;);
    &#125;
&#125;
</code></pre>
<p>使用publisher发送object消息</p>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/22 21:46
 */

@RunWith(SpringRunner.class)
@SpringBootTest
public class SpringAMQPTest &#123;
    @Autowired
    private RabbitTemplate rabbitTemplate;
    // basic queue

    // 消息转换器
    @Test
    public void testSendObjectQueue() &#123;
        Map&lt;String, Object&gt; msg = new HashMap&lt;&gt;();
        msg.put(&quot;name&quot;, &quot;柳岩&quot;);
        msg.put(&quot;age&quot;, 21);
        rabbitTemplate.convertAndSend(&quot;object.queue&quot;, msg);
    &#125;
&#125;
</code></pre>
<p>默认序列化成：</p>
<pre><code>rO0ABXNyABFqYXZhLnV0aWwuSGFzaE1hcAUH2sHDFmDRAwACRgAKbG9hZEZhY3RvckkACXRocmVzaG9sZHhwP0AAAAAAAAx3CAAAABAAAAACdAAEbmFtZXQA
Buafs+WyqXQAA2FnZXNyABFqYXZhLmxhbmcuSW50ZWdlchLioKT3gYc4AgABSQAFdmFsdWV4cgAQamF2YS5sYW5nLk51bWJlcoaslR0LlOCLAgAAeHAAAAAV
eA==
</code></pre>
<p><strong>添加MessageConverter</strong></p>
<p>①依赖引入</p>
<ul>
<li><p>父pom引入<strong>或</strong>模块引入都可</p>
</li>
<li><p>父pom引入【父pom基于spring-boot-starter-parent】</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
    &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
</li>
<li><p>模块引入</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt;
    &lt;artifactId&gt;jackson-dataformat-xml&lt;/artifactId&gt;
    &lt;version&gt;2.9.10&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
</li>
</ul>
<p>②在publisher服务声明MessageConverter</p>
<pre><code class="java">package cn.itcast.mq;

import org.springframework.amqp.support.converter.Jackson2JsonMessageConverter;
import org.springframework.amqp.support.converter.MessageConverter;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.annotation.Bean;

@SpringBootApplication
public class PublisherApplication &#123;
    public static void main(String[] args) &#123;
        SpringApplication.run(PublisherApplication.class);
    &#125;

    @Bean
    public MessageConverter messageConverter() &#123;
        return new Jackson2JsonMessageConverter();
    &#125;
&#125;
</code></pre>
<p><strong>接收消息</strong>：重复上述步骤，注册一个MessageConverter的@Bean组件，使用与发送类型相同的类型参数接收信息</p>
<pre><code class="java">package cn.itcast.mq.listener;
/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/22 22:09
 */
@Component
public class SpringRabbitListener &#123;

    //object converter
    @RabbitListener(queues = &quot;object.queue&quot;)
    public void listenObjectQueue(Map&lt;String, Object&gt; msg) &#123;
        System.out.println(&quot;收到消息：【&quot; + msg + &quot;】&quot;);
    &#125;
&#125;
</code></pre>
<h1 id="十、Elasticsearch"><a href="#十、Elasticsearch" class="headerlink" title="十、Elasticsearch"></a>十、Elasticsearch</h1><p>elasticsearch是一款非常强大的开源搜索引擎，可以帮助我们从海量数据中快速找到需要的内容。</p>
<p>elasticsearch是elastic stack (ELK)的核心，负责存储、搜索、分析数据。</p>
<ul>
<li>数据可视化：Kibana</li>
<li>存储、计算、搜索数据：Elasticsearch</li>
<li>数据抓取：Logstash、Beats</li>
</ul>
<p><strong>Elasticsearch底层实现</strong>：Lucene</p>
<ul>
<li>是Apache的开源搜索引擎类库，提供了搜索引擎的核心API</li>
</ul>
<p><strong>elasticsearch的发展</strong> Lucene是一个ava语言的搜索引擎类库，是Apache公司的顶级项目，由DougCutting于1999年研发官网地址: <a target="_blank" rel="noopener" href="https://lucene.apache.org/%E3%80%82">https://lucene.apache.org/。</a></p>
<p>Lucene的<strong>优势</strong>:</p>
<ul>
<li>易扩展</li>
<li>高性能(基于倒排索引)</li>
</ul>
<p>2004年shay Banon基于Lucene开发了Compass</p>
<p>2010年shay Banon 重写了Compass，取名为Elasticsearch。官网地址: <a target="_blank" rel="noopener" href="https://www.elastic.co/cn/">https://www.elastic.co/cn/</a></p>
<p><strong>相比与lucene，elasticsearch具备下列优势</strong></p>
<ul>
<li>支持分布式，可水平扩展</li>
<li>提供Restful接口，可被任何语言调用</li>
</ul>
<h2 id="10-1-概述"><a href="#10-1-概述" class="headerlink" title="10.1. 概述"></a>10.1. 概述</h2><p><strong>正向索引和倒排索引</strong></p>
<p>elasticsearch采用倒排索引:</p>
<p>文档(document):每条数据就是一个文档</p>
<p>词条(term):文档按照语义分成的词语</p>
<p>什么是文档和词条?</p>
<ul>
<li>每一条数据就是一个文档</li>
<li>对文档中的内容分词，得到的词语就是词条</li>
</ul>
<p>什么是正向索引?</p>
<ul>
<li>基于文档id创建索引。查询词条时必须先找到文档，而后判断是否包含词条</li>
</ul>
<p>什么是倒排索引?</p>
<ul>
<li>对文档内容分词，对词条创建索引，并记录词条所在文档的信息。查询时先根据词条查询到文档id，而后获取到文档</li>
</ul>
<p>索引(Index)</p>
<ul>
<li>索引(index):相同类型的文档的集合</li>
<li>映射(mapping):索引中文档的字段约束信息，类似表的结构约束</li>
</ul>
<p><strong>概念对比</strong></p>
<table>
<thead>
<tr>
<th>MySQL</th>
<th>Elasticsearch</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Table</td>
<td>Index</td>
<td>索引(index)，就是文档的集合，类似数据库的表(table)</td>
</tr>
<tr>
<td>Row</td>
<td>Document</td>
<td>文档(Document)，就是一条条的数据，类似数据库中的行(Row)，文档都是JSON格式</td>
</tr>
<tr>
<td>Column</td>
<td>Field</td>
<td>字段(Field)，就是JSON文档中的字段，类似数据库中的列 (Column)</td>
</tr>
<tr>
<td>Schema</td>
<td>Mapping</td>
<td>Mapping(映射)是索引中文档的约束，例如字段类型约束。类似数据库的表结构(Schema)</td>
</tr>
<tr>
<td>SQL</td>
<td>DSL</td>
<td>DSL是eLasticsearch提供的JSON风格的请求语句，用来操作elasticsearch，实现CRUD</td>
</tr>
</tbody></table>
<p><strong>架构</strong></p>
<ul>
<li>Mysql:擅长事务类型操作，可以确保数据的安全和一致性</li>
<li>Elasticsearch:擅长海量数据的搜索、分析、计算</li>
</ul>
<p><strong>总结</strong></p>
<ul>
<li>文档:一条数据就是一个文档，es中是Json格式</li>
<li>字段:Json文档中的字段</li>
<li>索引:同类型文档的集合</li>
<li>映射:索引中文档的约束，比如字段名称、类型</li>
<li>elasticsearch与数据库的关系<ul>
<li>数据库负责事务类型操作</li>
<li>elasticsearch负责海量数据的搜索、分析、计算</li>
</ul>
</li>
</ul>
<h2 id="10-2-安装"><a href="#10-2-安装" class="headerlink" title="10.2. 安装"></a>10.2. 安装</h2><h3 id="10-2-1-部署单点es"><a href="#10-2-1-部署单点es" class="headerlink" title="10.2.1 部署单点es"></a>10.2.1 部署单点es</h3><ol>
<li><p>创建网络：还需要部署kibana容器，因此需要让es和kibana容器互联</p>
<pre><code>docker network create es-net
</code></pre>
</li>
<li><p>加载镜像：这里采用elasticsearch的7.12.1版本的镜像，这个镜像体积非常大，接近1G。不建议pull</p>
<pre><code class="sh"># 导入数据
docker load -i es.tar
</code></pre>
</li>
<li><p>运行：运行docker命令，部署单点es</p>
<pre><code class="sh">docker run -d \
    --name es \
    -e &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; \
    -e &quot;discovery.type=single-node&quot; \
    -v es-data:/usr/share/elasticsearch/data \
    -v es-plugins:/usr/share/elasticsearch/plugins \
    --privileged \
    --network es-net \
    -p 9200:9200 \
    -p 9300:9300 \
elasticsearch:7.12.1
</code></pre>
<ul>
<li><code>-e &quot;cluster.name=es-docker-cluster&quot;</code>：设置集群名称</li>
<li><code>-e &quot;http.host=0.0.0.0&quot;</code>：监听的地址，可以外网访问</li>
<li><code>-e &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;</code>：内存大小</li>
<li><code>-e &quot;discovery.type=single-node&quot;</code>：非集群模式</li>
<li><code>-v es-data:/usr/share/elasticsearch/data</code>：挂载逻辑卷，绑定es的数据目录</li>
<li><code>-v es-logs:/usr/share/elasticsearch/logs</code>：挂载逻辑卷，绑定es的日志目录</li>
<li><code>-v es-plugins:/usr/share/elasticsearch/plugins</code>：挂载逻辑卷，绑定es的插件目录</li>
<li><code>--privileged</code>：授予逻辑卷访问权</li>
<li><code>--network es-net</code> ：加入一个名为es-net的网络中</li>
<li><code>-p 9200:9200</code>：端口映射配置</li>
</ul>
</li>
<li><p>测试：在浏览器中输入：<a target="_blank" rel="noopener" href="http://192.168.49.10:9200/">http://192.168.49.10:9200</a> 即可看到elasticsearch的响应结果</p>
<pre><code class="json">// 20230725160609
// http://192.168.49.10:9200/

&#123;
  &quot;name&quot;: &quot;9d54b23c2bcb&quot;,
  &quot;cluster_name&quot;: &quot;docker-cluster&quot;,
  &quot;cluster_uuid&quot;: &quot;-0wNglZGQtSCxh3oAvAirA&quot;,
  &quot;version&quot;: &#123;
    &quot;number&quot;: &quot;7.12.1&quot;,
    &quot;build_flavor&quot;: &quot;default&quot;,
    &quot;build_type&quot;: &quot;docker&quot;,
    &quot;build_hash&quot;: &quot;3186837139b9c6b6d23c3200870651f10d3343b7&quot;,
    &quot;build_date&quot;: &quot;2021-04-20T20:56:39.040728659Z&quot;,
    &quot;build_snapshot&quot;: false,
    &quot;lucene_version&quot;: &quot;8.8.0&quot;,
    &quot;minimum_wire_compatibility_version&quot;: &quot;6.8.0&quot;,
    &quot;minimum_index_compatibility_version&quot;: &quot;6.0.0-beta1&quot;
  &#125;,
  &quot;tagline&quot;: &quot;You Know, for Search&quot;
&#125;
</code></pre>
</li>
</ol>
<h3 id="10-2-2-部署kibana"><a href="#10-2-2-部署kibana" class="headerlink" title="10.2.2 部署kibana"></a>10.2.2 部署kibana</h3><p>kibana可以给我们提供一个elasticsearch的可视化界面，便于学习</p>
<ol>
<li><p>导入kibana.tar到&#x2F;tmp下</p>
<pre><code class="sh">docker load -i kibana.tar
</code></pre>
</li>
<li><p>部署</p>
<pre><code class="sh">docker run -d \
--name kibana \
-e ELASTICSEARCH_HOSTS=http://es:9200 \
--network=es-net \
-p 5601:5601  \
kibana:7.12.1
# 版本需要与es一致
</code></pre>
<ul>
<li><code>--network es-net</code> ：加入一个名为es-net的网络中，与elasticsearch在同一个网络中</li>
<li><code>-e ELASTICSEARCH_HOSTS=http://es:9200&quot;</code>：设置elasticsearch的地址，因为kibana已经与elasticsearch在一个网络，因此可以用容器名直接访问elasticsearch</li>
<li><code>-p 5601:5601</code>：端口映射配置</li>
</ul>
<p>kibana启动一般比较慢，需要多等待一会，可以通过命令：</p>
<pre><code class="sh">docker logs -f kibana
</code></pre>
<p>查看运行日志，当查看到下面的日志，说明成功</p>
<pre><code>&quot;message&quot;:&quot;http server running at http://0:5601&quot;
</code></pre>
</li>
</ol>
<h3 id="10-2-3-安装IK分词器"><a href="#10-2-3-安装IK分词器" class="headerlink" title="10.2.3 安装IK分词器"></a>10.2.3 安装IK分词器</h3><p><strong>分词器</strong></p>
<p>es在创建倒排索引时需要对文档分词;在搜索时，需要对用户输入内容分词。但默认的分词规则对中文处理并不友好我们在kibana的DevTools中测试：</p>
<pre><code class="json">GET _search
&#123;
  &quot;query&quot;: &#123;
    &quot;match_all&quot;: &#123;&#125;
  &#125;
&#125;
# 测试分词器
GET /_analyze
&#123;
  &quot;text&quot;: &quot;黑马程序员学习Java太棒了！&quot;,
  &quot;analyzer&quot;: &quot;english&quot;
&#125;
</code></pre>
<p>语法说明:</p>
<ul>
<li>POST:请求方式</li>
<li>&#x2F;_analyze: 请求路径，这里省略了<a target="_blank" rel="noopener" href="http://192.168.150.101:9200/">http://192.168.150.101:9200</a>，有kibana帮我们补充</li>
<li>请求参数，json风格：<ul>
<li>analyzer:分词器类型，这里是默认的standard分词器</li>
<li>text:要分词的内容</li>
</ul>
</li>
</ul>
<p><strong>安装IK分词器</strong></p>
<ol>
<li><p>在线安装：</p>
<pre><code class="sh"># 进入容器内部
docker exec -it elasticsearch /bin/bash

# 在线下载并安装
./bin/elasticsearch-plugin  install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.12.1/elasticsearch-analysis-ik-7.12.1.zip

#退出
exit
#重启容器
docker restart elasticsearch
</code></pre>
</li>
<li><p>离线安装【建议】</p>
<ol>
<li><p>查看数据目录</p>
<p>安装插件需要知道elasticsearch的plugins目录位置，而我们用了数据卷挂载，因此需要查看elasticsearch的数据卷目录，通过下面命令查看:</p>
<pre><code>docker volume inspect es-plugins
</code></pre>
<p>显示结果：</p>
<pre><code>[
    &#123;
        &quot;CreatedAt&quot;: &quot;2023-07-25T14:46:01+08:00&quot;,
        &quot;Driver&quot;: &quot;local&quot;,
        &quot;Labels&quot;: null,
        &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/es-plugins/_data&quot;,
        &quot;Name&quot;: &quot;es-plugins&quot;,
        &quot;Options&quot;: null,
        &quot;Scope&quot;: &quot;local&quot;
    &#125;
]
</code></pre>
<p>说明plugins目录被挂载到了：<code>/var/lib/docker/volumes/es-plugins/_data</code>这个目录中。</p>
</li>
<li><p>解压缩分词器安装包</p>
<p>解压ik压缩包，将文件重命名为ik上传到es容器的插件数据卷中也就是<code>/var/lib/docker/volumes/es-plugins/_data</code></p>
</li>
<li><p>重启容器</p>
<pre><code class="shell"># 4、重启容器
docker restart es
</code></pre>
<pre><code class="sh"># 查看es日志
docker logs -f es
</code></pre>
</li>
<li><p>测试</p>
<p>IK分词器包含两种模式：</p>
<ul>
<li><code>ik_smart</code>：最少切分</li>
<li><code>ik_max_word</code>：最细切分</li>
</ul>
<pre><code class="json">GET /_analyze
&#123;
  &quot;analyzer&quot;: &quot;ik_max_word&quot;,
  &quot;text&quot;: &quot;黑马程序员学习java太棒了&quot;
&#125;
</code></pre>
<p>结果：</p>
<pre><code class="json">&#123;
  &quot;tokens&quot; : [
    &#123;
      &quot;token&quot; : &quot;黑马&quot;,
      &quot;start_offset&quot; : 0,
      &quot;end_offset&quot; : 2,
      &quot;type&quot; : &quot;CN_WORD&quot;,
      &quot;position&quot; : 0
    &#125;,
    &#123;
      &quot;token&quot; : &quot;程序员&quot;,
      &quot;start_offset&quot; : 2,
      &quot;end_offset&quot; : 5,
      &quot;type&quot; : &quot;CN_WORD&quot;,
      &quot;position&quot; : 1
    &#125;,
    &#123;
      &quot;token&quot; : &quot;程序&quot;,
      &quot;start_offset&quot; : 2,
      &quot;end_offset&quot; : 4,
      &quot;type&quot; : &quot;CN_WORD&quot;,
      &quot;position&quot; : 2
    &#125;,
    &#123;
      &quot;token&quot; : &quot;员&quot;,
      &quot;start_offset&quot; : 4,
      &quot;end_offset&quot; : 5,
      &quot;type&quot; : &quot;CN_CHAR&quot;,
      &quot;position&quot; : 3
    &#125;,
    &#123;
      &quot;token&quot; : &quot;学习&quot;,
      &quot;start_offset&quot; : 5,
      &quot;end_offset&quot; : 7,
      &quot;type&quot; : &quot;CN_WORD&quot;,
      &quot;position&quot; : 4
    &#125;,
    &#123;
      &quot;token&quot; : &quot;java&quot;,
      &quot;start_offset&quot; : 7,
      &quot;end_offset&quot; : 11,
      &quot;type&quot; : &quot;ENGLISH&quot;,
      &quot;position&quot; : 5
    &#125;,
    &#123;
      &quot;token&quot; : &quot;太棒了&quot;,
      &quot;start_offset&quot; : 11,
      &quot;end_offset&quot; : 14,
      &quot;type&quot; : &quot;CN_WORD&quot;,
      &quot;position&quot; : 6
    &#125;,
    &#123;
      &quot;token&quot; : &quot;太棒&quot;,
      &quot;start_offset&quot; : 11,
      &quot;end_offset&quot; : 13,
      &quot;type&quot; : &quot;CN_WORD&quot;,
      &quot;position&quot; : 7
    &#125;,
    &#123;
      &quot;token&quot; : &quot;了&quot;,
      &quot;start_offset&quot; : 13,
      &quot;end_offset&quot; : 14,
      &quot;type&quot; : &quot;CN_CHAR&quot;,
      &quot;position&quot; : 8
    &#125;
  ]
&#125;
</code></pre>
</li>
<li><p><strong>扩展词词典</strong></p>
<p>随着互联网的发展，“造词运动”也越发的频繁。出现了很多新的词语，在原有的词汇列表中并不存在。比如：“奥力给”，“传智播客” 等。</p>
<p>所以我们的词汇也需要不断的更新，IK分词器提供了扩展词汇的功能。</p>
<ol>
<li><p>打开IK分词器config目录：<code>./ik/config/IKAnalyzer.cfg.xml</code></p>
<pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE properties SYSTEM &quot;http://java.sun.com/dtd/properties.dtd&quot;&gt;
&lt;properties&gt;
        &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt;
        &lt;!--用户可以在这里配置自己的扩展字典 *** 添加扩展词典--&gt;
        &lt;entry key=&quot;ext_dict&quot;&gt;ext.dic&lt;/entry&gt;
&lt;/properties&gt;
</code></pre>
</li>
<li><p>新建一个 ext.dic，可以参考config目录下复制一个配置文件进行修改</p>
<pre><code>传智播客
奥力给
</code></pre>
</li>
<li><p>重启elasticsearch</p>
<pre><code>docker restart es

# 查看 日志
docker logs -f elasticsearch
</code></pre>
</li>
<li><p>测试效果</p>
<pre><code>GET /_analyze
&#123;
  &quot;analyzer&quot;: &quot;ik_max_word&quot;,
  &quot;text&quot;: &quot;传智播客Java就业超过90%,奥力给！&quot;
&#125;
</code></pre>
</li>
</ol>
</li>
<li><p><strong>停用词词典</strong></p>
<p>在互联网项目中，在网络间传输的速度很快，所以很多语言是不允许在网络上传递的，如：关于宗教、政治等敏感词语，那么我们在搜索时也应该忽略当前词汇。</p>
<p>IK分词器也提供了强大的停用词功能，让我们在索引时就直接忽略当前的停用词汇表中的内容。</p>
<ol>
<li><p>IKAnalyzer.cfg.xml配置文件内容添加:</p>
<pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE properties SYSTEM &quot;http://java.sun.com/dtd/properties.dtd&quot;&gt;
&lt;properties&gt;
        &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt;
        &lt;!--用户可以在这里配置自己的扩展字典--&gt;
        &lt;entry key=&quot;ext_dict&quot;&gt;ext.dic&lt;/entry&gt;
         &lt;!--用户可以在这里配置自己的扩展停止词字典  *** 添加停用词词典--&gt;
        &lt;entry key=&quot;ext_stopwords&quot;&gt;stopword.dic&lt;/entry&gt;
&lt;/properties&gt;
</code></pre>
</li>
<li><p>在 stopword.dic 添加停用词</p>
<pre><code>习大大
</code></pre>
</li>
<li><p>重启elasticsearch </p>
<pre><code># 重启服务
docker restart elasticsearch
docker restart kibana

# 查看 日志
docker logs -f elasticsearch
</code></pre>
</li>
<li><p>测试效果：</p>
<pre><code>GET /_analyze
&#123;
  &quot;analyzer&quot;: &quot;ik_max_word&quot;,
  &quot;text&quot;: &quot;传智播客Java就业率超过95%,习大大都点赞,奥力给！&quot;
&#125;
</code></pre>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="10-2-4-部署es集群"><a href="#10-2-4-部署es集群" class="headerlink" title="10.2.4 部署es集群"></a>10.2.4 部署es集群</h3><p>部署es集群可以直接使用docker-compose来完成，不过要求你的Linux虚拟机至少有<strong>4G</strong>的内存空间</p>
<p>首先编写一个docker-compose文件，内容如下：</p>
<pre><code class="sh">version: &#39;2.2&#39;
services:
  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1
    container_name: es01
    environment:
      - node.name=es01
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es02,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data01:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    networks:
      - elastic
  es02:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1
    container_name: es02
    environment:
      - node.name=es02
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data02:/usr/share/elasticsearch/data
    networks:
      - elastic
  es03:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1
    container_name: es03
    environment:
      - node.name=es03
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01,es02
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data03:/usr/share/elasticsearch/data
    networks:
      - elastic

volumes:
  data01:
    driver: local
  data02:
    driver: local
  data03:
    driver: local

networks:
  elastic:
    driver: bridge
</code></pre>
<p>Run <code>docker-compose</code> to bring up the cluster:</p>
<pre><code>docker-compose up
</code></pre>
<h2 id="10-3-索引库"><a href="#10-3-索引库" class="headerlink" title="10.3. 索引库"></a>10.3. 索引库</h2><p><strong>mapping属性</strong></p>
<p>mapping是对索引库中文档的约束，常见的mapping属性包括</p>
<ul>
<li>type:字段数据类型，常见的简单类型有:<ul>
<li>字符串:text (可分词的文本)、keyword (精确值，例如:品牌、国家、ip地址)</li>
<li>数值: long、integer、short、byte、double、float、</li>
<li>布尔: boolean</li>
<li>日期:date</li>
<li>对象:object</li>
</ul>
</li>
<li>index:是否创建索引，默认为true</li>
<li>analyzer:使用哪种分词器</li>
<li>properties:该字段的子字段</li>
</ul>
<h3 id="10-3-1-索引库操作"><a href="#10-3-1-索引库操作" class="headerlink" title="10.3.1 索引库操作"></a>10.3.1 索引库操作</h3><p><strong>创建索引库</strong></p>
<pre><code class="json"># 创建索引库 /heima为索引库名
PUT /heima
&#123;
  &quot;mappings&quot;: &#123;
    &quot;properties&quot;: &#123;
      &quot;info&quot;:&#123;
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;ik_smart&quot;
      &#125;,
      &quot;email&quot;:&#123;
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;index&quot;: false
      &#125;,
      &quot;name&quot;:&#123;
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: &#123;
          &quot;firstName&quot;:&#123;
            &quot;type&quot;: &quot;keyword&quot;
          &#125;,
          &quot;lastName&quot;:&#123;
            &quot;type&quot;:&quot;keyword&quot;
          &#125;
        &#125;
      &#125;
    &#125;
  &#125;
&#125;
</code></pre>
<p><strong>查看、删除索引库</strong></p>
<p><strong>查看</strong>：</p>
<pre><code>GET /索引库名
# 示例
GET /heima
GET /heima/_mapping
</code></pre>
<p><strong>删除</strong>：</p>
<pre><code>DELETE /索引库名
# 示例
DELETE /heima
</code></pre>
<p><strong>修改索引库</strong></p>
<p>索引库和mapping一旦创建无法修改，但是<strong>可以添加新的字段</strong></p>
<pre><code class="json">PUT /索引库名/_mapping
&#123;
    &quot;properties&quot;:&#123;
        &quot;新字段名&quot;:&#123;
            &quot;type&quot;: &quot;integer&quot;
        &#125;
    &#125;
&#125;

# 示例
PUT /索引库名/_mapping
&#123;
    &quot;properties&quot;:&#123;
        &quot;age&quot;:&#123;
            &quot;type&quot;: &quot;integer&quot;
        &#125;
    &#125;
&#125;
</code></pre>
<p><strong>索引库总结</strong>：索引库操作</p>
<ul>
<li>创建索引库 : <code>PUT /索引库名</code></li>
<li>查询索引库 : <code>GET /索引库名</code></li>
<li>删除索引库 : <code>DELETE /索引库名</code></li>
<li>添加字段 : <code>PUT /索引库名/_mapping</code></li>
</ul>
<h3 id="10-3-2-文档操作"><a href="#10-3-2-文档操作" class="headerlink" title="10.3.2 文档操作"></a>10.3.2 文档操作</h3><ul>
<li>添加文档：<code>POST /索引库名/_doc/文档id&#123;json文档&#125;</code></li>
<li>查询文档：<code>GET /索引库名/_doc/文档id</code></li>
<li>删除文档：<code>DELETE /索引库名/_doc/文档id</code></li>
</ul>
<p><strong>增、删、查</strong>DSL语法</p>
<pre><code class="json">POST /索引库名/_doc/文档id
&#123;
    &quot;字段1&quot;: &quot;值1&quot;,
    &quot;字段2&quot;: &quot;值2&quot;,
    &quot;字段3&quot;: &#123;
        &quot;子属性1&quot;: &quot;值3&quot;,
        &quot;子属性2&quot;: &quot;值4&quot;
    &#125;
&#125;

#：
# 插入文档
POST /heima/_doc/1
&#123;
  &quot;info&quot;: &quot;黑马程序员java讲师&quot;,
  &quot;email&quot;: &quot;bamboo@gmail.com&quot;,
  &quot;name&quot;: &#123;
    &quot;firstName&quot;: &quot;竹&quot;,
    &quot;lastName&quot;: &quot;龙&quot;
  &#125;
&#125;

# 查询文档
GET /heima/_doc/1

# 删除文档
DELETE /heima/_doc/1
</code></pre>
<p>修改文档</p>
<ul>
<li>全量修改：既能修改也能新增 <code>PUT /索引库名/_doc/文档id&#123;json文档&#125;</code></li>
<li>增量【局部】修改：<code>POST /索引库名/_update/文档id&#123;&quot;doc&quot;:&#123;字段&#125;&#125;</code></li>
</ul>
<pre><code class="json"># 全局修改
PUT /heima/_doc/1
&#123;
  &quot;info&quot;: &quot;黑马程序员java讲师&quot;,
  &quot;email&quot;: &quot;dragonbamboo@gmail.com&quot;,
  &quot;name&quot;: &#123;
    &quot;firstName&quot;: &quot;竹&quot;,
    &quot;lastName&quot;: &quot;龙&quot;
  &#125;
&#125;

# 增量修改
POST /heima/_update/1
&#123;
  &quot;doc&quot;: &#123;
    &quot;name&quot;: &#123;
      &quot;lastName&quot;: &quot;天&quot;
    &#125;
  &#125;
&#125;
</code></pre>
<p><strong>文档操作总结</strong>：</p>
<ul>
<li>创建文档：<code>POST /索引库名/_doc/文档id&#123;json文档&#125;</code></li>
<li>查询文档：<code>GET /索引库名/_doc/文档id</code></li>
<li>删除文档：<code>DELETE /索引库名/_doc/文档id</code></li>
<li>修改文档<ul>
<li>全量修改：<code>PUT/索引库名/_doc/文档id&#123;json文档&#125;</code></li>
<li>增量修改：<code>POST /索引库名/_update/文档id&#123;&quot;doc&quot;:&#123;字段&#125;&#125;</code></li>
</ul>
</li>
</ul>
<h2 id="10-4-RestClient"><a href="#10-4-RestClient" class="headerlink" title="10.4. RestClient"></a>10.4. RestClient</h2><p><strong>数据库导入</strong></p>
<pre><code class="sql">CREATE TABLE `tb_hotel` (
  `id` bigint(20) NOT NULL COMMENT &#39;酒店id&#39;,
  `name` varchar(255) NOT NULL COMMENT &#39;酒店名称&#39;,
  `address` varchar(255) NOT NULL COMMENT &#39;酒店地址&#39;,
  `price` int(10) NOT NULL COMMENT &#39;酒店价格&#39;,
  `score` int(2) NOT NULL COMMENT &#39;酒店评分&#39;,
  `brand` varchar(32) NOT NULL COMMENT &#39;酒店品牌&#39;,
  `city` varchar(32) NOT NULL COMMENT &#39;所在城市&#39;,
  `star_name` varchar(16) DEFAULT NULL COMMENT &#39;酒店星级，1星到5星，1钻到5钻&#39;,
  `business` varchar(255) DEFAULT NULL COMMENT &#39;商圈&#39;,
  `latitude` varchar(32) NOT NULL COMMENT &#39;纬度&#39;,
  `longitude` varchar(32) NOT NULL COMMENT &#39;经度&#39;,
  `pic` varchar(255) DEFAULT NULL COMMENT &#39;酒店图片&#39;,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 ROW_FORMAT=COMPACT;
</code></pre>
<h3 id="10-4-1-操作索引库"><a href="#10-4-1-操作索引库" class="headerlink" title="10.4.1 操作索引库"></a>10.4.1 操作索引库</h3><p><strong>索引表语法</strong></p>
<pre><code class="json"># 酒店的mapping
PUT /hotel
&#123;
  &quot;mappings&quot;: &#123;
    &quot;properties&quot;: &#123;
      &quot;id&quot;: &#123;
        &quot;type&quot;: &quot;keyword&quot;
      &#125;,
      &quot;name&quot;:&#123;
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;ik_max_word&quot;,
        &quot;copy_to&quot;: &quot;all&quot;
      &#125;,
      &quot;address&quot;: &#123;
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;index&quot;: false
      &#125;,
      &quot;price&quot;: &#123;
        &quot;type&quot;: &quot;integer&quot;
      &#125;,
      &quot;score&quot;: &#123;
        &quot;type&quot;: &quot;integer&quot;
      &#125;,
      &quot;brand&quot;: &#123;
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;copy_to&quot;: &quot;all&quot;
      &#125;,
      &quot;starName&quot;: &#123;
        &quot;type&quot;: &quot;keyword&quot;
      &#125;,
      &quot;business&quot;: &#123;
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;copy_to&quot;: &quot;all&quot;
      &#125;,
      &quot;location&quot;: &#123;
        &quot;type&quot;: &quot;geo_point&quot;
      &#125;,
      &quot;all&quot;:&#123;
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;ik_max_word&quot;
      &#125;
    &#125;
  &#125;
&#125;
</code></pre>
<p>ES中支持两种地理坐标数据类型:</p>
<ul>
<li>geo_point：由纬度(latitude)和经度(longitude)确定的一个点。例如:”32.8752345,120.2981576”</li>
<li>geo_shape：有多个geo_point组成的复杂几何图形。例如一条直线，”LINESTRING(-77.03653 38.8976761, -77.009051 38.889939)”</li>
</ul>
<p>字段拷贝可以使用copy_to属性将当前字段拷贝到指定字段。示例:</p>
<pre><code>&quot;all&quot;: &#123;
    &quot;type&quot;:&quot;text&quot;,
    &quot;analyzer&quot;:&quot;ik max word&quot;
&#125;,
&quot;brand&quot;: &#123;
    &quot;type&quot;: &quot;keyword&quot;,
    &quot;copy_to&quot;: &quot;all&quot;
&#125;
</code></pre>
<p><strong>1）简单应用</strong></p>
<p>①导入依赖</p>
<pre><code class="xml">&lt;!--JavaRestClient--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;
    &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt;
&lt;/dependency&gt;
        
&lt;properties&gt;
    &lt;java.version&gt;1.8&lt;/java.version&gt;
    &lt;elasticsearch.version&gt;7.12.1&lt;/elasticsearch.version&gt;
&lt;/properties&gt;
</code></pre>
<p>②测试</p>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/26 19:57
 */
public class HotelIndexTest &#123;
    private RestHighLevelClient client;

    @Test
    void testInit() &#123;
        System.out.println(client);
    &#125;

    @BeforeEach
    void setUp() &#123;
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create(&quot;http://192.168.49.10:9200&quot;)
        ));
    &#125;

    @AfterEach
    void tearDown() throws IOException &#123;
        this.client.close();
    &#125;
&#125;
</code></pre>
<h4 id="①-创建索引库"><a href="#①-创建索引库" class="headerlink" title="① 创建索引库"></a>① 创建索引库</h4><ol>
<li><p>创建CreateIndexRequest对象</p>
<pre><code class="java">CreateIndexRequest request = new CreateIndexRequest(&quot;hotel&quot;);
</code></pre>
</li>
<li><p>准备请求的参数，DSL语句</p>
<pre><code class="java">request.source(MAPPING_TEMPLATE, XContentType.JSON);
</code></pre>
</li>
<li><p>发送请求</p>
<pre><code class="java">client.indices().create(request, RequestOptions.DEFAULT);
</code></pre>
</li>
</ol>
<p>注意事项：CreateIndexRequest导包易错点</p>
<pre><code class="java">//导入这个包就可以正常运行了
import org.elasticsearch.client.indices.CreateIndexRequest;
</code></pre>
<p>①添加常量</p>
<pre><code class="java">package cn.itcast.hotel.constants;

/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/26 21:44
 */
public class HotelConstants &#123;
    public static final String MAPPING_TEMPLATE = &quot;&#123;\n&quot; +
            &quot;  \&quot;mappings\&quot;: &#123;\n&quot; +
            &quot;    \&quot;properties\&quot;: &#123;\n&quot; +
            &quot;      \&quot;id\&quot;: &#123;\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;keyword\&quot;\n&quot; +
            &quot;      &#125;,\n&quot; +
            &quot;      \&quot;name\&quot;:&#123;\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;text\&quot;,\n&quot; +
            &quot;        \&quot;analyzer\&quot;: \&quot;ik_max_word\&quot;,\n&quot; +
            &quot;        \&quot;copy_to\&quot;: \&quot;all\&quot;\n&quot; +
            &quot;      &#125;,\n&quot; +
            &quot;      \&quot;address\&quot;: &#123;\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;keyword\&quot;,\n&quot; +
            &quot;        \&quot;index\&quot;: false\n&quot; +
            &quot;      &#125;,\n&quot; +
            &quot;      \&quot;price\&quot;: &#123;\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;integer\&quot;\n&quot; +
            &quot;      &#125;,\n&quot; +
            &quot;      \&quot;score\&quot;: &#123;\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;integer\&quot;\n&quot; +
            &quot;      &#125;,\n&quot; +
            &quot;      \&quot;brand\&quot;: &#123;\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;keyword\&quot;,\n&quot; +
            &quot;        \&quot;copy_to\&quot;: \&quot;all\&quot;\n&quot; +
            &quot;      &#125;,\n&quot; +
            &quot;      \&quot;starName\&quot;: &#123;\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;keyword\&quot;\n&quot; +
            &quot;      &#125;,\n&quot; +
            &quot;      \&quot;business\&quot;: &#123;\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;keyword\&quot;,\n&quot; +
            &quot;        \&quot;copy_to\&quot;: \&quot;all\&quot;\n&quot; +
            &quot;      &#125;,\n&quot; +
            &quot;      \&quot;location\&quot;: &#123;\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;geo_point\&quot;\n&quot; +
            &quot;      &#125;,\n&quot; +
            &quot;      \&quot;all\&quot;:&#123;\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;text\&quot;,\n&quot; +
            &quot;        \&quot;analyzer\&quot;: \&quot;ik_max_word\&quot;\n&quot; +
            &quot;      &#125;\n&quot; +
            &quot;    &#125;\n&quot; +
            &quot;  &#125;\n&quot; +
            &quot;&#125;&quot;;
&#125;
</code></pre>
<p>②测试创建索引</p>
<pre><code class="java">package cn.itcast.hotel;

import org.apache.http.HttpHost;
import org.elasticsearch.client.RequestOptions;
import org.elasticsearch.client.RestClient;
import org.elasticsearch.client.RestHighLevelClient;
import org.elasticsearch.client.indices.CreateIndexRequest;
import org.elasticsearch.common.xcontent.XContentType;
import org.junit.jupiter.api.AfterEach;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;

import java.io.IOException;

import static cn.itcast.hotel.constants.HotelConstants.MAPPING_TEMPLATE;

/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/26 19:57
 */
public class HotelIndexTest &#123;
    private RestHighLevelClient client;

    @Test
    void createHotelIndex() throws IOException &#123;
        // 1.创建Request对象
        CreateIndexRequest request = new CreateIndexRequest(&quot;hotel&quot;);
        // 2.准备请求的参数，DSL语句
        request.source(MAPPING_TEMPLATE, XContentType.JSON);
        // 3.发送请求
        client.indices().create(request, RequestOptions.DEFAULT);
    &#125;

    @BeforeEach
    void setUp() &#123;
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create(&quot;http://192.168.49.10:9200&quot;)
        ));
    &#125;

    @AfterEach
    void tearDown() throws IOException &#123;
        this.client.close();
    &#125;
&#125;
</code></pre>
<h4 id="②-删除索引库"><a href="#②-删除索引库" class="headerlink" title="② 删除索引库"></a>② 删除索引库</h4><ol>
<li><p>创建DeleteIndexRequest对象</p>
<pre><code>DeleteIndexRequest request = new DeleteIndexRequest(&quot;hotel&quot;);
</code></pre>
</li>
<li><p>发送请求</p>
<pre><code>client.indices().delete(request, RequestOptions.DEFAULT);
</code></pre>
</li>
</ol>
<pre><code class="java">import static cn.itcast.hotel.constants.HotelConstants.MAPPING_TEMPLATE;

/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/26 19:57
 */
public class HotelIndexTest &#123;
    private RestHighLevelClient client;

    @Test
    void deleteHotelIndex() throws IOException &#123;
        // 1.创建Request对象
        DeleteIndexRequest request = new DeleteIndexRequest(&quot;hotel&quot;);
        // 2.发送请求
        client.indices().delete(request, RequestOptions.DEFAULT);
    &#125;

    @BeforeEach
    void setUp() &#123;
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create(&quot;http://192.168.49.10:9200&quot;)
        ));
    &#125;

    @AfterEach
    void tearDown() throws IOException &#123;
        this.client.close();
    &#125;
&#125;
</code></pre>
<h4 id="③-判断索引库是否存在"><a href="#③-判断索引库是否存在" class="headerlink" title="③ 判断索引库是否存在"></a>③ 判断索引库是否存在</h4><ol>
<li><p>创建GetIndexRequest对象</p>
<pre><code>GetIndexRequest request = new GetIndexRequest(&quot;hotel&quot;);
</code></pre>
</li>
<li><p>发送请求</p>
<pre><code>boolean exists = client.indices().exists(request, RequestOptions.DEFAULT);
</code></pre>
</li>
</ol>
<pre><code class="java">import static cn.itcast.hotel.constants.HotelConstants.MAPPING_TEMPLATE;

/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/26 19:57
 */
public class HotelIndexTest &#123;
    private RestHighLevelClient client;

    @Test
    void existsHotelIndex() throws IOException &#123;
        // 1.创建Request对象
        GetIndexRequest request = new GetIndexRequest(&quot;hotel&quot;);
        // 2.发送请求
        boolean exists = client.indices().exists(request, RequestOptions.DEFAULT);
        // 3.输出
        System.err.println(exists);
    &#125;

    @BeforeEach
    void setUp() &#123;
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create(&quot;http://192.168.49.10:9200&quot;)
        ));
    &#125;

    @AfterEach
    void tearDown() throws IOException &#123;
        this.client.close();
    &#125;
&#125;
</code></pre>
<h4 id="④-总结"><a href="#④-总结" class="headerlink" title="④ 总结"></a>④ 总结</h4><p>索引库操作的基本步骤：</p>
<ul>
<li>初始化RestHighLevelClient</li>
<li>创建XxxlndexRequest。XXX是CREATE、Get、Delete</li>
<li>准备DSL (CREATE时需要)</li>
<li>发送请求。调用RestHighLevelClient#indices().xxx()方法xxx是create、exists、delete</li>
</ul>
<h3 id="10-4-2-操作文档"><a href="#10-4-2-操作文档" class="headerlink" title="10.4.2 操作文档"></a>10.4.2 操作文档</h3><h4 id="①-新建文档"><a href="#①-新建文档" class="headerlink" title="① 新建文档"></a>① 新建文档</h4><ol>
<li><p>准备Request对象</p>
<pre><code>IndexRequest request = new IndexRequest(&quot;hotel&quot;).id(hotel.getId().toString());
</code></pre>
</li>
<li><p>准备Json文档</p>
<pre><code>request.source(JSON.toJSONString(hotelDoc), XContentType.JSON);
</code></pre>
</li>
<li><p>发送请求</p>
<pre><code>client.index(request, RequestOptions.DEFAULT);
</code></pre>
</li>
</ol>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/26 19:57
 */
@SpringBootTest
public class HotelDocumentTest &#123;

    @Autowired
    private HotelService hotelService;

    private RestHighLevelClient client;

    @Test
    void testAddDocument() throws IOException &#123;
        // 根据Id查询酒店数据
        Hotel hotel = hotelService.getById(394796L);
        // 转换为文档类型
        HotelDoc hotelDoc = new HotelDoc(hotel);

        // 1.准备Request对象
        IndexRequest request = new IndexRequest(&quot;hotel&quot;).id(hotel.getId().toString());
        // 2.准备Json文档
        request.source(JSON.toJSONString(hotelDoc), XContentType.JSON);
        // 3.发送请求
        client.index(request, RequestOptions.DEFAULT);
        // 测试：GET /hotel/_doc/394796
    &#125;


    @BeforeEach
    void setUp() &#123;
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create(&quot;http://192.168.49.10:9200&quot;)
        ));
    &#125;

    @AfterEach
    void tearDown() throws IOException &#123;
        this.client.close();
    &#125;
&#125;
</code></pre>
<h4 id="②-查询文档"><a href="#②-查询文档" class="headerlink" title="② 查询文档"></a>② 查询文档</h4><ol>
<li><p>准备Request</p>
<pre><code>GetRequest request = new GetRequest(&quot;hotel&quot;,&quot;394796&quot;);
</code></pre>
</li>
<li><p>发送请求，得到响应</p>
<pre><code>GetResponse response = client.get(request, RequestOptions.DEFAULT);
</code></pre>
</li>
<li><p>解析响应结果</p>
<pre><code>String json = response.getSourceAsString();
</code></pre>
</li>
<li><p>JSON处理数据为Object</p>
<pre><code>HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
</code></pre>
</li>
</ol>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/26 19:57
 */
@SpringBootTest
public class HotelDocumentTest &#123;

    @Autowired
    private HotelService hotelService;

    private RestHighLevelClient client;

    @Test
    void testGetDocumentById() throws IOException &#123;
        // 1.准备Request
        GetRequest request = new GetRequest(&quot;hotel&quot;,&quot;394796&quot;);
        // 2.发送请求，得到响应
        GetResponse response = client.get(request, RequestOptions.DEFAULT);
        // 3.解析响应结果
        String json = response.getSourceAsString();

        HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
        System.out.println(hotelDoc);
    &#125;

    @BeforeEach
    void setUp() &#123;
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create(&quot;http://192.168.49.10:9200&quot;)
        ));
    &#125;

    @AfterEach
    void tearDown() throws IOException &#123;
        this.client.close();
    &#125;
&#125;
</code></pre>
<h4 id="③-修改文档"><a href="#③-修改文档" class="headerlink" title="③ 修改文档"></a>③ 修改文档</h4><p>修改文档数据有两种方式:</p>
<ul>
<li>方式一：全量更新。再次写入id一样的文档，就会删除旧文档，添加新文档</li>
<li>方式二：局部更新。只更新部分字段，我们演示方式二</li>
</ul>
<p><strong>方式</strong></p>
<ol>
<li><p>准备Request对象</p>
<pre><code class="java">UpdateRequest request = new UpdateRequest(&quot;hotel&quot;, &quot;394796&quot;);
</code></pre>
</li>
<li><p>准备请求参数</p>
<pre><code class="java">request.doc(
    &quot;price&quot;,&quot;9999&quot;,
    &quot;starName&quot;,&quot;超星级&quot;
);
</code></pre>
</li>
<li><p>发送请求</p>
<pre><code>client.update(request, RequestOptions.DEFAULT);
</code></pre>
</li>
</ol>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/26 19:57
 */
@SpringBootTest
public class HotelDocumentTest &#123;

    @Autowired
    private HotelService hotelService;

    private RestHighLevelClient client;

    @Test
    void testUpdateDocument() throws IOException &#123;
        // 1.准备Request对象
        UpdateRequest request = new UpdateRequest(&quot;hotel&quot;, &quot;394796&quot;);
        // 2.准备请求参数
        request.doc(
                &quot;price&quot;,&quot;9999&quot;,
                &quot;starName&quot;,&quot;超星级&quot;
        );
        // 3.发送请求
        client.update(request, RequestOptions.DEFAULT);
    &#125;


    @BeforeEach
    void setUp() &#123;
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create(&quot;http://192.168.49.10:9200&quot;)
        ));
    &#125;

    @AfterEach
    void tearDown() throws IOException &#123;
        this.client.close();
    &#125;
&#125;
</code></pre>
<h4 id="④-删除文档"><a href="#④-删除文档" class="headerlink" title="④ 删除文档"></a>④ 删除文档</h4><ol>
<li><p>准备Request</p>
<pre><code>DeleteRequest request = new DeleteRequest(&quot;hotel&quot;,&quot;394796&quot;);
</code></pre>
</li>
<li><p>发送请求</p>
<pre><code>client.delete(request, RequestOptions.DEFAULT);
</code></pre>
</li>
</ol>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/26 19:57
 */
@SpringBootTest
public class HotelDocumentTest &#123;

    @Autowired
    private HotelService hotelService;

    private RestHighLevelClient client;

    @Test
    void testDeleteDocument() throws IOException &#123;
        // 1.准备Request
        DeleteRequest request = new DeleteRequest(&quot;hotel&quot;,&quot;394796&quot;);
        // 2.发送请求
        client.delete(request, RequestOptions.DEFAULT);
    &#125;

    @BeforeEach
    void setUp() &#123;
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create(&quot;http://192.168.49.10:9200&quot;)
        ));
    &#125;

    @AfterEach
    void tearDown() throws IOException &#123;
        this.client.close();
    &#125;
&#125;
</code></pre>
<h4 id="⑤-批量导入文档"><a href="#⑤-批量导入文档" class="headerlink" title="⑤ 批量导入文档"></a>⑤ 批量导入文档</h4><ul>
<li>使用Bulk批处理，实现批量新增文档</li>
<li>批量查询：<code>GET /hotel/_search</code></li>
</ul>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/26 19:57
 */
@SpringBootTest
public class HotelDocumentTest &#123;

    @Autowired
    private HotelService hotelService;

    private RestHighLevelClient client;

    @Test
    void testBulkRequest() throws IOException &#123;
        // 批量查询酒店数据
        List&lt;Hotel&gt; hotels = hotelService.list();
        // 1.创建Request
        BulkRequest request = new BulkRequest();
        // 2.准备参数，添加多个新增的Request
        for (Hotel hotel : hotels) &#123;
            // 转换为文档类型HotelDoc
            HotelDoc hotelDoc = new HotelDoc(hotel);
            // 创建新增文档的Request对象
            request.add(new IndexRequest(&quot;hotel&quot;)
                    .id(hotelDoc.getId().toString())
                    .source(JSON.toJSONString(hotelDoc), XContentType.JSON));
        &#125;
        // 3.发送请求
        client.bulk(request, RequestOptions.DEFAULT);
    &#125;

    @BeforeEach
    void setUp() &#123;
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create(&quot;http://192.168.49.10:9200&quot;)
        ));
    &#125;

    @AfterEach
    void tearDown() throws IOException &#123;
        this.client.close();
    &#125;
&#125;
</code></pre>
<h4 id="⑥-总结"><a href="#⑥-总结" class="headerlink" title="⑥ 总结"></a>⑥ 总结</h4><p>文档操作的基本步骤</p>
<ul>
<li>初始化RestHighLevelClient</li>
<li>创建XxxRequest。XXX是Index、Get、Update、Delete</li>
<li>准备参数 (Index和Update时需要)</li>
<li>发送请求。调用RestHighLevelClient#.xxx()方法，xxx是index、get、update、delete</li>
<li>解析结果 (Get时需要)</li>
</ul>
<h2 id="10-5-DSL语法"><a href="#10-5-DSL语法" class="headerlink" title="10.5. DSL语法"></a>10.5. DSL语法</h2><h3 id="10-5-1-DSL语法"><a href="#10-5-1-DSL语法" class="headerlink" title="10.5.1 DSL语法"></a>10.5.1 DSL语法</h3><p>Elasticsearch提供了基于JSON的DSL（Domain Specific Language）来定义查询。常见的查询类型包括：</p>
<ol>
<li>查询所有</li>
<li>全文检索（full text）</li>
<li>精确查询</li>
<li>地理（geo）查询</li>
<li>复合（compound）查询</li>
</ol>
<p><strong>①查询所有</strong>：查询出所有数据，一般用于测试。例如：match_all</p>
<pre><code>GET /indexName/_search
&#123;
    &quot;query&quot;: &#123;
        &quot;查询类型&quot;: &#123;
            &quot;查询条件&quot;: &quot;条件值&quot;
        &#125;
    &#125;
&#125;

# 示例：查询所有
GET /hotel/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;match_all&quot;: &#123;&#125;
  &#125;
&#125;
</code></pre>
<p><strong>②全文检索（full text）查询</strong>：利用分词器对用户输入内容粉刺，然后去倒排索引库中匹配。例如：</p>
<ul>
<li><p>match_query</p>
<pre><code># match查询
GET /indexName/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;match&quot;: &#123;
      &quot;FIELD&quot;: &quot;TEXT&quot;
    &#125;
  &#125;
&#125;

# 示例：match查询
GET /hotel/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;match&quot;: &#123;
      &quot;all&quot;: &quot;外滩&quot;
    &#125;
  &#125;
&#125;
</code></pre>
</li>
<li><p>multi_match_query：与match查询相似，但允许同时查询多个字段</p>
<pre><code># multi_match查询
GET /indexName/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;multi_match&quot;: &#123;
      &quot;query&quot;: &quot;TEXT&quot;,
      &quot;fields&quot;: [&quot;FIELD1&quot;,&quot;FIELD2&quot;]
    &#125;
  &#125;
&#125;

# 示例
GET /hotel/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;multi_match&quot;: &#123;
      &quot;query&quot;: &quot;外滩如家&quot;,
      &quot;fields&quot;: [&quot;brand&quot;,&quot;name&quot;,&quot;business&quot;]
    &#125;
  &#125;
&#125;
</code></pre>
</li>
<li><p>【意见】：建议使用copy_to拷贝多个属性到一个字段中，使用match查询；multi_match查询是根据多个字段查询，参与查询字段越多，查询性能越差。</p>
</li>
</ul>
<p><strong>③精确查询</strong>：根据精确词条值查找数据，一般是查找keyword、数值、日志、boolean等类型字段。例如：</p>
<ul>
<li><p>range：根据值的范围查询（数值、日期的范围）</p>
<pre><code># range查询
GET /indexName/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;range&quot;: &#123;
      &quot;FIELD&quot;: &#123;
        &quot;gte&quot;: 10,
        &quot;lte&quot;: 20
      &#125;
    &#125;
  &#125;
&#125;

# 示例
GET /hotel/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;range&quot;: &#123;
      &quot;price&quot;: &#123;
        &quot;gte&quot;: 100,
        &quot;lte&quot;: 300
      &#125;
    &#125;
  &#125;
&#125;
</code></pre>
</li>
<li><p>term：根据词条精确值查询（keyword类型、数值类型、布尔类型、日期类型字段）</p>
<pre><code># term查询
GET /indexName/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;term&quot;: &#123;
      &quot;FIELD&quot;: &#123;
        &quot;value&quot;: &quot;VALUE&quot;
      &#125;
    &#125;
  &#125;
&#125;

# 示例
GET /hotel/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;term&quot;: &#123;
      &quot;city&quot;: &#123;
        &quot;value&quot;: &quot;上海&quot;
      &#125;
    &#125;
  &#125;
&#125;
</code></pre>
</li>
</ul>
<p><strong>④地理（geo）查询</strong>：根据经纬度查询。例如：</p>
<ul>
<li><p>geo_distance【常用】：半径查询，即以坐标为原点半径以内的数据被检索</p>
<pre><code># distance查询
GET /indexName/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;geo_distance&quot;:&#123;
      &quot;distance&quot;: &quot;15km&quot;,
      &quot;location&quot;: &quot;31.21,121.5&quot;
    &#125;
  &#125;
&#125;

# 示例
GET /hotel/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;geo_distance&quot;:&#123;
      &quot;distance&quot;: &quot;15km&quot;,
      &quot;location&quot;: &quot;31.21,121.5&quot;
    &#125;
  &#125;
&#125;
</code></pre>
</li>
<li><p>geo_bounding_box：矩形坐标，以<strong>左顶点</strong>和<strong>右底点</strong>为界化成的矩形内数据被检索</p>
<pre><code>GET /indexName/_search
&#123;
    &quot;query&quot;: &#123;
        &quot;geo_bounding_box&quot;: &#123;
            &quot;FIELD&quot;: &#123;
                &quot;top_left&quot;: &#123;
                    &quot;lat&quot;: 31.1,
                    &quot;lon&quot;: 121.5
                &#125;,
                &quot;bottom_right&quot;: &#123;
                    &quot;lat&quot;: 30.9,
                    &quot;lon&quot;: 121.7
                &#125;
            &#125;
        &#125;
    &#125;
&#125;
</code></pre>
</li>
</ul>
<p><strong>⑤复合（compound）查询</strong>：复合查询可以将上述各种查询条件组合起来，合并查询条件。例如：</p>
<ul>
<li><p>bool</p>
<ul>
<li>一个或多个查询子句的组合。组合方式有：<ul>
<li>must：必须匹配每个子查询，类似“与”</li>
<li>should：选择性匹配子查询，类似“或”</li>
<li>must_not：必须不匹配，<strong>不参与算分</strong>，类似“非”</li>
<li>filter：必须匹配，<strong>不参与算分</strong></li>
</ul>
</li>
</ul>
<pre><code>GET /hotel/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;bool&quot;: &#123;
      &quot;must&quot;: [
        &#123;
          &quot;match&quot;: &#123;
            &quot;name&quot;: &quot;如家&quot;
          &#125;
        &#125;
      ],
      &quot;must_not&quot;: [
        &#123;
          &quot;range&quot;: &#123;
            &quot;price&quot;: &#123;
              &quot;gt&quot;: 400
            &#125;
          &#125;
        &#125;
      ],
      &quot;filter&quot;: [
        &#123;
          &quot;geo_distance&quot;: &#123;
            &quot;distance&quot;: &quot;10km&quot;,
            &quot;location&quot;: &#123;
              &quot;lat&quot;: 31.21,
              &quot;lon&quot;: 121.5
            &#125;
          &#125;
        &#125;
      ]
    &#125;
  &#125;
&#125;
</code></pre>
</li>
<li><p>function_score</p>
<ul>
<li>定义的三要素<ul>
<li>过滤条件：哪些文档要加分</li>
<li>算分函数：如何计算Function score</li>
<li>加权方式：function score 与 query score如何运算</li>
</ul>
</li>
</ul>
<pre><code>GET /indexName/_search
&#123;
    &quot;query&quot;: &#123;
        &quot;function_score&quot;: &#123;
            // 原始查询条件，搜索文档并根据相关性打分（query score）
            &quot;query&quot;: &#123; &quot;match&quot;: &#123;&quot;all&quot;:&quot;外滩&quot;&#125;&#125;,
            &quot;functions&quot;: [
                &#123;
                    // 过滤条件，符合条件的文档才会被重新打分
                    &quot;filter&quot;: &#123;&quot;term&quot;: &#123;&quot;id&quot;: &quot;1&quot;&#125;&#125;,
                    // 算分函数，算分函数的结果称为function score,将来会与query score运算得到新算分，常见算分函数有：
                    // weight: 给一个常量值，作为函数结果（function score）
                    // field_value_factor: 用文档中某个字段作为函数结果
                    // random_score: 随机生成一个值，作为函数结果
                    // script_score: 自定义计算公式，公式结果作为函数结果
                    &quot;weight&quot;: 10
                &#125;
            ],
            // 加权模式，定义function score与query score的运算方式，包括：
            // multiply: 两者相乘，默认使用
            // replace: 永function score替换query score
            // 其他: sum、avg、max、min
            &quot;boost_mode&quot;: &quot;multiply&quot;
        &#125;
    &#125;
&#125;


# function_score查询
GET /hotel/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;function_score&quot;: &#123;
      &quot;query&quot;: &#123;
        &quot;match&quot;: &#123;
          &quot;all&quot;: &quot;外滩&quot;
        &#125;
      &#125;,
      &quot;functions&quot;: [ // 算分函数
        &#123;
          &quot;filter&quot;: &#123; // 满足的条件
            &quot;term&quot;: &#123;
              &quot;brand&quot;: &quot;如家&quot;
            &#125;
          &#125;,
          &quot;weight&quot;: 10 // 算分权重2
        &#125;
      ],
      &quot;boost_mode&quot;: &quot;sum&quot;
    &#125;
  &#125;
&#125;
</code></pre>
<ul>
<li>算分函数查询，可以控制文档相关性算分，控制文档排名。</li>
<li>相关性打分算法<ul>
<li>利用match查询时，文档结果会根据与搜索词的关联度打分（_score），返回结果按照分值降序排列</li>
<li>TF-IDF：在es5.0之前，随着词频增加而越来越大</li>
<li>BM25：在es5.0之后，随着词频增加而增大，但增长曲线会趋于水平。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="10-5-2-DSL搜索结果处理"><a href="#10-5-2-DSL搜索结果处理" class="headerlink" title="10.5.2 DSL搜索结果处理"></a>10.5.2 DSL搜索结果处理</h3><ol>
<li>排序</li>
<li>分页</li>
<li>高亮</li>
</ol>
<h4 id="①排序"><a href="#①排序" class="headerlink" title="①排序"></a>①排序</h4><p>elasticsearch支持对搜索结果排序，默认是根据相关度算分（_score）来排序。可以排序字段类型有：keyword类型、数值类型、地理坐标类型、日期类型等。</p>
<pre><code>GET /indexName/_search
&#123;
    &quot;query&quot;: &#123;
        &quot;match_all&quot;: &#123;&#125;
    &#125;,
    &quot;sort&quot;: &#123;
        &quot;FIELD&quot;: &quot;desc&quot; // 排序字段和排序方式ASC、DESC
    &#125;
&#125;
# 地理排序
GET /indexName/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;match_all&quot;: &#123;&#125;
  &#125;,
  &quot;sort&quot;: [
    &#123;
      &quot;_geo_distance&quot;: &#123;
        &quot;FIELD&quot;: &quot;纬度,经度&quot;,
        &quot;order&quot;: &quot;desc&quot;,
        &quot;unit&quot;: &quot;km&quot;
      &#125;
    &#125;
  ]
&#125;

# 示例1
GET /hotel/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;match_all&quot;: &#123;&#125;
  &#125;,
  &quot;sort&quot;: [
    &#123;
      &quot;score&quot;: &quot;desc&quot;
    &#125;,
    &#123;
      &quot;price&quot;: &quot;asc&quot;
    &#125;
  ]
&#125;
# 示例2
GET /hotel/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;match_all&quot;: &#123;&#125;
  &#125;,
  &quot;sort&quot;: [
    &#123;
      &quot;_geo_distance&quot;: &#123;
        &quot;location&quot;: &#123;
          &quot;lat&quot;: 31.034661,
          &quot;lon&quot;: 121.612282
        &#125;, 
        &quot;order&quot;: &quot;asc&quot;,
        &quot;unit&quot;: &quot;km&quot;
      &#125;
    &#125;
  ]
&#125;
</code></pre>
<h4 id="②分页"><a href="#②分页" class="headerlink" title="②分页"></a>②分页</h4><p>elasticsearch默认情况下只返回top10的数据。而如果要查询更多数据就需要修改分页参数，elasticsearch中通过修改from、size参数控制返回的分页结果：</p>
<pre><code>GET /hotel/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;match_all&quot;: &#123;&#125;
  &#125;,
  &quot;from&quot;: 100, // 分页开始的位置，默认0
  &quot;size&quot;: 20, // 期望获取的文档总数
  &quot;sort&quot;: [
    &#123;
      &quot;price&quot;: &quot;asc&quot;
    &#125;
  ]
&#125;
</code></pre>
<p><strong>深度分页问题</strong>：ES是分布式的，会面临深度分页问题，例如按price排序后，获取from&#x3D;990，size&#x3D;10的数据：</p>
<ol>
<li>在ES集群中每个数据分片上都排序查询前1000条文档</li>
<li>所有节点结果聚合，在内存中重新排序选出前1000条文档</li>
<li>最后从这1000条中，选取从990开始的10条文档</li>
</ol>
<p>注：如搜索页数过深，或者结果集（from+size）越大，对内存和CPU的消耗也越高。因此ES设定结果集查询的上限是10000，超出会报错</p>
<p><strong>深度分页解决方案</strong>：</p>
<ul>
<li>search after：分页时需要排序，原理是从上一次排序的排序值开始，查询下一页数据。【官方推荐】</li>
<li>scroll：原理将排序数据形成快照，保存在内存。【不推荐】</li>
</ul>
<p><strong>from+size</strong></p>
<ul>
<li>优点：支持随机反野</li>
<li>缺点：深度分页问题，默认查询上限（from+size）是10000</li>
<li>场景：百度、京东、谷歌、淘宝这样的随机反野搜索</li>
</ul>
<p><strong>after search</strong></p>
<ul>
<li>优点：没有查询上限（单词查询的size不超过10000）</li>
<li>缺点：只能向后逐页查询，不支持随机翻页</li>
<li>场景：没有随机翻页需求的搜索，例如手机乡下滚动翻页</li>
</ul>
<p><strong>scroll</strong></p>
<ul>
<li>优点：没有查询上限（单词查询的size不超过10000）</li>
<li>缺点：会有额外内存消耗，并且搜索结果是非实时的</li>
<li>场景：海量数据的获取和迁移。从ES7.1开始不推荐，建议使用after search方案</li>
</ul>
<h4 id="③高亮"><a href="#③高亮" class="headerlink" title="③高亮"></a>③高亮</h4><p>搜索结果中把搜索关键字突出显示</p>
<p>原理：搜索结果关键字用<strong>标签标记</strong>出来，在页面中给标签添加css样式</p>
<pre><code>GET /hotel/search
&#123;
  &quot;query&quot;: &#123;
    &quot;match&quot;: &#123;
      &quot;FIELD&quot;: &quot;TEXT&quot;
    &#125;
  &#125;,
  &quot;highlight&quot;: &#123;
    &quot;fields&quot;: &#123;  // 指定要高亮的字段
      &quot;FIELD&quot;: &#123;
        &quot;pre_tags&quot;: &quot;&lt;em&gt;&quot;,  // 用来标记高亮字段的前置标签
        &quot;post_tags&quot;: &quot;&lt;/em&gt;&quot;  // 用来标记高亮字段的后置标签
      &#125;
    &#125;
  &#125;
&#125;

# 示例，默认采取em标签
GET /hotel/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;match&quot;: &#123;
      &quot;all&quot;: &quot;如家&quot;
    &#125;
  &#125;,
  &quot;highlight&quot;: &#123;
    &quot;fields&quot;: &#123;
      &quot;name&quot;: &#123;
        &quot;require_field_match&quot;: &quot;false&quot; // 取消ES搜索字段必须与高亮字段一致
      &#125;
    &#125;
  &#125;
&#125;
</code></pre>
<p><strong>④搜索结果处理总结</strong></p>
<pre><code>GET /hotel/_search
&#123;
  &quot;query&quot;: &#123;
    &quot;match&quot;: &#123;
      &quot;name&quot;: &quot;如家&quot;
    &#125;
  &#125;,
  &quot;from&quot;: 0, // 分页开始的位置
  &quot;size&quot;: 20, // 期望获取的文档总数
  &quot;sort&quot;: [
    &#123; &quot;price&quot;: &quot;asc&quot; &#125;, // 普通排序
    &#123;
      &quot;_geo_distance&quot;: &#123; // 距离排序
        &quot;location&quot;: &quot;31.040699,121.618075&quot;,
        &quot;order&quot;: &quot;asc&quot;,
        &quot;unit&quot;: &quot;km&quot;
      &#125;
    &#125;
  ],
  &quot;highlight&quot;: &#123;
    &quot;fields&quot;: &#123; // 高亮字段
      &quot;name&quot;: &#123;
        &quot;pre_tags&quot;: &quot;&lt;em&gt;&quot;,  // 用来标记高亮字段的前置标签
        &quot;post_tags&quot;: &quot;&lt;/em&gt;&quot; // 用来标记高亮字段的后置标签
      &#125;
    &#125;
  &#125;
&#125;
</code></pre>
<h3 id="10-5-3-RestClient查询文档【高级】"><a href="#10-5-3-RestClient查询文档【高级】" class="headerlink" title="10.5.3 RestClient查询文档【高级】"></a>10.5.3 RestClient查询文档【高级】</h3><h4 id="①-match-all查询"><a href="#①-match-all查询" class="headerlink" title="① match_all查询"></a>① match_all查询</h4><p>查询基本步骤：</p>
<ol>
<li>创建SearchRequest对象</li>
<li>准备Requesst.source()，也就是DSL<ul>
<li>QueryBuilders来构建查询条件</li>
<li>传入Request.source()的query()方法</li>
</ul>
</li>
<li>发送请求，得到结果</li>
<li>解析结果（参考JSON结果，从外到内，逐层解析）</li>
</ol>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/26 19:57
 */
@SpringBootTest
public class HotelSearchTest &#123;

    @Autowired
    private HotelService hotelService;

    private RestHighLevelClient client;

    @Test
    void testMatchAll() throws IOException &#123;
        // 1.准备request
        SearchRequest request = new SearchRequest(&quot;hotel&quot;);
        // 2.组织DSL参数
        request.source()
                .query(QueryBuilders.matchAllQuery());
        // 3.发送请求，得到响应结果
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        // 4.解析结果
        SearchHits searchHits = response.getHits();
        // 4.1查询的总条数
        long total = searchHits.getTotalHits().value;
        System.out.println(&quot;共搜索到&quot; + total + &quot;条数据&quot;);
        // 4.2 查询的结果数组
        SearchHit[] hits = searchHits.getHits();
        for (SearchHit hit : hits) &#123;
            // 4.3得到source
            String json = hit.getSourceAsString();
            // 4.4反序列化
            HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
            System.out.println(hotelDoc);
        &#125;
    &#125;

    @BeforeEach
    void setUp() &#123;
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create(&quot;http://192.168.49.10:9200&quot;)
        ));
    &#125;

    @AfterEach
    void tearDown() throws IOException &#123;
        this.client.close();
    &#125;
&#125;
</code></pre>
<p>RestAPI中，其中构建DSL是通过HighLevelRestClient中的resource()来实现的，其中包含了查询、排序、分页、高亮等所有功能。</p>
<h4 id="②-抽离结果处理Ctrl-Alt-M"><a href="#②-抽离结果处理Ctrl-Alt-M" class="headerlink" title="② 抽离结果处理Ctrl Alt M"></a>② 抽离结果处理Ctrl Alt M</h4><pre><code class="java">private static void handleResponse(SearchResponse response) &#123;
        // 4.解析结果
        SearchHits searchHits = response.getHits();
        // 4.1查询的总条数
        long total = searchHits.getTotalHits().value;
        System.out.println(&quot;共搜索到&quot; + total + &quot;条数据&quot;);
        // 4.2 查询的结果数组
        SearchHit[] hits = searchHits.getHits();
        for (SearchHit hit : hits) &#123;
            // 4.3得到source
            String json = hit.getSourceAsString();
            // 4.4反序列化
            HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
            System.out.println(hotelDoc);
        &#125;
    &#125;
</code></pre>
<h4 id="③-全文检索查询"><a href="#③-全文检索查询" class="headerlink" title="③ 全文检索查询"></a>③ 全文检索查询</h4><p>全文检索的match和multi_match查询与match_all的API基本一致。差别是查询条件，也就是query的部分。</p>
<pre><code class="java">// 单字段查询
QueryBuilders.matchQuery(&quot;all&quot;,&quot;如家&quot;);
// 多字段查询
QueryBuilders.mulitMatchQuery(&quot;如家&quot;,&quot;name&quot;,&quot;business&quot;);
</code></pre>
<p>代码实现：</p>
<pre><code class="java">    void testMatch() throws IOException &#123;
        // 1.准备request
        SearchRequest request = new SearchRequest(&quot;hotel&quot;);
        // 2.组织DSL参数
        request.source()
                .query(QueryBuilders.matchQuery(&quot;all&quot;,&quot;如家&quot;));
        // 3.发送请求，得到响应结果
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        handleResponse(response);
    &#125;
</code></pre>
<h4 id="④-精确查询"><a href="#④-精确查询" class="headerlink" title="④ 精确查询"></a>④ 精确查询</h4><p>常见有term查询和range查询，同样利用QueryBuilders实现</p>
<pre><code class="java">// 词条查询
QueryBuilders.termQuery(&quot;city&quot;,&quot;杭州&quot;);
// 范围查询
QueryBuilders.rangeQuery(&quot;price&quot;).gte(100).lte(150);
</code></pre>
<p>代码实现：</p>
<pre><code class="java">    @Test
    void testTermMatch() throws IOException &#123;
        // 1.准备request
        SearchRequest request = new SearchRequest(&quot;hotel&quot;);
        // 2.组织DSL参数
        request.source()
                .query(QueryBuilders.termQuery(&quot;city&quot;, &quot;杭州&quot;));
        // 3.发送请求，得到响应结果
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        handleResponse(response);
    &#125;

    @Test
    void testRangeMatch() throws IOException &#123;
        // 1.准备request
        SearchRequest request = new SearchRequest(&quot;hotel&quot;);
        // 2.组织DSL参数
        request.source()
                .query(QueryBuilders.rangeQuery(&quot;price&quot;).gte(100).lte(150));
        // 3.发送请求，得到响应结果
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        handleResponse(response);
    &#125;
</code></pre>
<h4 id="⑤-复合查询"><a href="#⑤-复合查询" class="headerlink" title="⑤ 复合查询"></a>⑤ 复合查询</h4><pre><code class="java">// 创建布尔查询
BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();
// 添加must条件
boolQuery.must(QueryBuilders.termQuery(&quot;city&quot;,&quot;杭州&quot;));
// 添加filter条件
boolQuery.filter(QueryBuilders.rangeQuery(&quot;price&quot;).lte(250));
</code></pre>
<p>代码实现：</p>
<pre><code class="java">    @Test
    void testBool() throws IOException &#123;
        // 1.准备request
        SearchRequest request = new SearchRequest(&quot;hotel&quot;);
        // 2.组织DSL参数
        BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();
        boolQuery.must(QueryBuilders.termQuery(&quot;city&quot;, &quot;杭州&quot;));
        boolQuery.filter(QueryBuilders.rangeQuery(&quot;price&quot;).lte(250));
        request.source().query(boolQuery);
        // 3.发送请求，得到响应结果
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        handleResponse(response);
    &#125;
</code></pre>
<p><strong>总结</strong>：要构建查询条件时，只需要认准QueryBuilders</p>
<h4 id="⑥-排序和分页"><a href="#⑥-排序和分页" class="headerlink" title="⑥ 排序和分页"></a>⑥ 排序和分页</h4><p>搜索结果的排序和分页是与query同级的参数，对应API如下：</p>
<pre><code class="java">// 查询
request.source().query(QueryBuilders.matchAllQuery());
// 分页
request.source().from(0).size(5);
// 价格排序
request.source().sort(&quot;price&quot;,SortOrder.ASC);
</code></pre>
<p>代码实现：</p>
<pre><code class="java">    @Test
    void testPageAndSort() throws IOException &#123;
        // 页码，每页大小
        int page = 1, size = 5;
        // 1.准备request
        SearchRequest request = new SearchRequest(&quot;hotel&quot;);
        // 2.组织DSL参数
        request.source().query(QueryBuilders.matchAllQuery());
        // 2.1排序
        request.source().sort(&quot;price&quot;, SortOrder.ASC);
        // 2.2分页 from、size
        request.source().from((page - 1) * size).size(size);
        // 3.发送请求，得到响应结果
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        handleResponse(response);
    &#125;
</code></pre>
<h4 id="⑦-高亮"><a href="#⑦-高亮" class="headerlink" title="⑦ 高亮"></a>⑦ 高亮</h4><p>高亮API包括请求DSL构建和结果解析两部分</p>
<p><strong>构建</strong></p>
<pre><code class="java">request.source().highlighter(new HighlightBuilder()
    .field(&quot;name&quot;)
    // 是否需要与查询字段匹配
    .requireFieldMatch(false)
);
</code></pre>
<p><strong>高亮结果解析</strong></p>
<pre><code class="java">// 解析结果
SearchHits searchHits = response.getHits();
SearchHit[] hits = searchHits.getHits();
for (SearchHit hit : hits) &#123;
    // 获取文档source
    String json = hit.getSourceAsString();
    // 反序列化
    HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
    // 获取高亮结果
    Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields();
    if (!CollectionUtils.isEmpty(highlightFields)) &#123;
        // 根据字段名获取高亮结果
        HighlightField highlightField = highlightFields.get(&quot;name&quot;);
        if (highlightField != null) &#123;
        // 获取高亮值
        String name = highlightField.getFragments()[0].string();
        // 覆盖非高亮结果
        hotelDoc.setName(name);
        &#125;
    &#125;
    System.out.println(&quot;hotelDoc = &quot; + hotelDoc);
&#125;
</code></pre>
<p>代码实现：</p>
<pre><code class="java"> @Test
    void testHighlight() throws IOException &#123;
        // 1.准备request
        SearchRequest request = new SearchRequest(&quot;hotel&quot;);
        // 2.组织DSL参数
        request.source().query(QueryBuilders.matchQuery(&quot;all&quot;, &quot;如家&quot;));
        // 高亮
        request.source().highlighter(new HighlightBuilder().field(&quot;name&quot;).requireFieldMatch(false));
        // 3.发送请求，得到响应结果
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        // 4.解析结果
        SearchHits searchHits = response.getHits();
        // 4.1查询的总条数
        long total = searchHits.getTotalHits().value;
        System.out.println(&quot;共搜索到&quot; + total + &quot;条数据&quot;);
        // 4.2 查询的结果数组
        SearchHit[] hits = searchHits.getHits();
        for (SearchHit hit : hits) &#123;
            // 4.3获取文档source
            String json = hit.getSourceAsString();
            // 4.4反序列化
            HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
            // 获取高亮结果
            Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields();
            if (!CollectionUtils.isEmpty(highlightFields)) &#123;
                // 根据字段名获取高亮结果
                HighlightField highlightField = highlightFields.get(&quot;name&quot;);
                if (highlightField != null) &#123;
                    // 获取高亮值
                    String name = highlightField.getFragments()[0].string();
                    // 覆盖非高亮结果
                    hotelDoc.setName(name);
                &#125;
            &#125;
            System.out.println(&quot;hotelDoc = &quot; + hotelDoc);
        &#125;
    &#125;
</code></pre>
<p>高亮结果解析参考JSON结果，逐层解析</p>
<p><strong>应用</strong></p>
<pre><code class="java">@Service
public class HotelService extends ServiceImpl&lt;HotelMapper, Hotel&gt; implements IHotelService &#123;

    @Autowired
    private RestHighLevelClient client;

    @Override
    public PageResult search(RequestParams params) &#123;
        try &#123;
            // 1.准备Request
            SearchRequest request = new SearchRequest(&quot;hotel&quot;);
            // 2.准备DSL
            buildBasicQuery(params, request);
            // 2.2 分页
            Integer page = params.getPage();
            Integer size = params.getSize();
            request.source().from((page - 1) * size).size(size);
            // 2.3 排序
            String location = params.getLocation();
            if (location != null &amp;&amp; !location.equals(&quot;&quot;)) &#123;
                request.source().sort(SortBuilders
                        .geoDistanceSort(&quot;location&quot;, new GeoPoint(location))
                        .order(SortOrder.ASC)
                        .unit(DistanceUnit.KILOMETERS)
                );
            &#125;
            // 3.发送请求得到响应
            SearchResponse response = client.search(request, RequestOptions.DEFAULT);
            // 4.解析响应
            return handleResponse(response);
        &#125; catch (IOException e) &#123;
            throw new RuntimeException(e);
        &#125;
    &#125;

    private static void buildBasicQuery(RequestParams params, SearchRequest request) &#123;
        // 构建BoolQueryBuilder
        BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();
        // 关键字搜索
        String key = params.getKey();
        if (key == null || &quot;&quot;.equals(key)) &#123;
            boolQuery.must(QueryBuilders.matchAllQuery());
        &#125; else &#123;
            boolQuery.must(QueryBuilders.matchQuery(&quot;all&quot;, key));
        &#125;
        // 城市条件
        if (params.getCity() != null &amp;&amp; !params.getCity().equals(&quot;&quot;)) &#123;
            boolQuery.filter(QueryBuilders.termQuery(&quot;city&quot;, params.getCity()));
        &#125;
        // 品牌条件
        if (params.getBrand() != null &amp;&amp; !params.getBrand().equals(&quot;&quot;)) &#123;
            boolQuery.filter(QueryBuilders.termQuery(&quot;brand&quot;, params.getBrand()));
        &#125;
        // 星级条件
        if (params.getStarName() != null &amp;&amp; !params.getStarName().equals(&quot;&quot;)) &#123;
            boolQuery.filter(QueryBuilders.termQuery(&quot;starName&quot;, params.getStarName()));
        &#125;
        // 价格
        if (params.getMinPrice() != null &amp;&amp; params.getMaxPrice() != null) &#123;
            boolQuery.filter(QueryBuilders
                    .rangeQuery(&quot;price&quot;).gte(params.getMinPrice()).lte(params.getMaxPrice()));
        &#125;
        // 算分控制
        FunctionScoreQueryBuilder functionScoreQuery =
                QueryBuilders.functionScoreQuery(
                        // 原始查询，相关性算分的查询
                        boolQuery,
                        // function score的数组
                        new FunctionScoreQueryBuilder.FilterFunctionBuilder[]&#123;
                                // 其中一个function score元素
                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(
                                        // 过滤条件
                                        QueryBuilders.termQuery(&quot;isAD&quot;, true),
                                        // 算分函数
                                        ScoreFunctionBuilders.weightFactorFunction(10)
                                )
                        &#125;
                );
        // 封装
        request.source().query(functionScoreQuery);
    &#125;

    private static PageResult handleResponse(SearchResponse response) &#123;
        // 解析结果
        SearchHits searchHits = response.getHits();
        // 查询的总条数
        long total = searchHits.getTotalHits().value;
        // 查询的结果数组
        SearchHit[] hits = searchHits.getHits();
        // 遍历
        List&lt;HotelDoc&gt; hotels = new ArrayList&lt;&gt;();
        for (SearchHit hit : hits) &#123;
            // 得到source
            String json = hit.getSourceAsString();
            // 反序列化
            HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
            // 获取排序值
            Object[] sortValues = hit.getSortValues();
            if (sortValues.length &gt; 0) &#123;
                Object sortValue = sortValues[0];
                hotelDoc.setDistance(sortValue);
            &#125;
            hotels.add(hotelDoc);
        &#125;
        // 封装返回
        return new PageResult(total, hotels);
    &#125;
&#125;
</code></pre>
<h2 id="10-6-数据聚合"><a href="#10-6-数据聚合" class="headerlink" title="10.6. 数据聚合"></a>10.6. 数据聚合</h2><p><strong>聚合的分类</strong></p>
<p>聚合（aggregations）可以实现对文档数据的统计、分析、运算。聚合常见的有三类:</p>
<ul>
<li>桶（Bucket）聚合:用来对文档做分组<ul>
<li>TermAggregation：按照文档字段值分组</li>
<li>Date Histogram：按照日期阶梯分组，例如一周为一组，或者一月为一组</li>
</ul>
</li>
<li>度量 （Metric）聚合：用以计算一些值，比如：最大值、最小值、平均值等<ul>
<li>Avg：求平均值</li>
<li>Max：求最大值</li>
<li>Min：求最小值</li>
<li>Stats：同时求max、min、avg、sum等</li>
</ul>
</li>
<li>管道 （pipeline）聚合: 其它聚合的结果为基础做聚合</li>
</ul>
<p>参与聚合的字段类型：keyword、数值、日期、布尔</p>
<h3 id="10-6-1-Bucket聚合"><a href="#10-6-1-Bucket聚合" class="headerlink" title="10.6.1 Bucket聚合"></a>10.6.1 Bucket聚合</h3><pre><code># 聚合功能
GET /hotel/_search
&#123;
  &quot;size&quot;: 0,
  &quot;aggs&quot;: &#123;
    &quot;brandAgg&quot;: &#123;
      &quot;terms&quot;: &#123;
        &quot;field&quot;: &quot;brand&quot;,
        &quot;size&quot;: 20
      &#125;
    &#125;
  &#125;
&#125;
</code></pre>
<p><strong>聚合结果排序</strong>：默认情况下Bucket聚合会统计Bucket内的文档数量，记为<code>_count</code>，并且按照<code>_count</code>降序排序</p>
<pre><code># 聚合功能，自定义排序规则
GET /hotel/_search
&#123;
  &quot;size&quot;: 0,
  &quot;aggs&quot;: &#123;
    &quot;brandAgg&quot;: &#123;
      &quot;terms&quot;: &#123;
        &quot;field&quot;: &quot;brand&quot;,
        &quot;size&quot;: 20,
        # 排序
        &quot;order&quot;: &#123;
          &quot;_count&quot;: &quot;asc&quot;
        &#125;
      &#125;
    &#125;
  &#125;
&#125;
</code></pre>
<p><strong>限定聚合范围</strong>：默认情况下Bucket聚合对索引库所有文档做聚合，我们可以先定要聚合的文档范围，只需要增加query条件即可</p>
<pre><code># 聚合功能，限定聚合范围
GET /hotel/_search
&#123;
  # 限定聚合范围
  &quot;query&quot;: &#123;
    &quot;range&quot;: &#123;
      &quot;price&quot;: &#123;
        &quot;lte&quot;: 200
      &#125;
    &#125;
  &#125;, 
  &quot;size&quot;: 0,
  &quot;aggs&quot;: &#123;
    &quot;brandAgg&quot;: &#123;
      &quot;terms&quot;: &#123;
        &quot;field&quot;: &quot;brand&quot;,
        &quot;size&quot;: 20
      &#125;
    &#125;
  &#125;
&#125;
</code></pre>
<p>aggs代表聚合，与query同级，此时query的作用：</p>
<ul>
<li>限定聚合的的文档范围</li>
</ul>
<p>聚合必须的三要素：</p>
<ul>
<li>聚合名称</li>
<li>聚合类型</li>
<li>聚合字段</li>
</ul>
<p>聚合可配置属性有：</p>
<ul>
<li>size：指定聚合结果数量</li>
<li>order：指定聚合结果排序方式</li>
<li>field:：指定聚合字段</li>
</ul>
<h3 id="10-6-2-Metrics聚合"><a href="#10-6-2-Metrics聚合" class="headerlink" title="10.6.2 Metrics聚合"></a>10.6.2 Metrics聚合</h3><p>例：获取每个品牌的用户评分的min、max、avg等值，可以利用stats聚合：</p>
<pre><code># 嵌套聚合metric
GET /hotel/_search
&#123;
  &quot;size&quot;: 0,
  &quot;aggs&quot;: &#123;
    &quot;brandAgg&quot;: &#123;
      &quot;terms&quot;: &#123;
        &quot;field&quot;: &quot;brand&quot;,
        &quot;size&quot;: 20,
        &quot;order&quot;: &#123; # 对metrics聚合排序
          &quot;scoreAgg.avg&quot;: &quot;desc&quot;
        &#125;
      &#125;,
      &quot;aggs&quot;: &#123; # brands聚合的子聚合，也就是分组后对每组分别计算
        &quot;scoreAgg&quot;: &#123; # 聚合名称
          &quot;stats&quot;: &#123; # 聚合类型，这里的stats可以计算min、max、avg等
            &quot;field&quot;: &quot;score&quot; # 聚合字段，这里是score
          &#125;
        &#125;
      &#125;
    &#125;
  &#125;
&#125;
</code></pre>
<h3 id="10-6-3-RestClient实现聚合"><a href="#10-6-3-RestClient实现聚合" class="headerlink" title="10.6.3 RestClient实现聚合"></a>10.6.3 RestClient实现聚合</h3><p><strong>聚合条件</strong></p>
<pre><code class="java">request.source().aggregation(AggregationBuilders
    .terms(&quot;brandAgg&quot;)
    .field(&quot;brand&quot;)
    .size(10)
);
</code></pre>
<p><strong>聚合结果解析</strong></p>
<pre><code class="java">// 4.解析结果
Aggregations aggregations = response.getAggregations();
// 4.1.根据聚合名称获取聚合结果
Terms brandTerms = aggregations.get(&quot;brandAgg&quot;);
// 4.2.获取buckets
List&lt;? extends Terms.Bucket&gt; buckets = brandTerms.getBuckets();
// 4.3.遍历
for (Terms.Bucket bucket : buckets) &#123;
// 4.4.获取key
String key = bucket.getKeyAsString();
System.out.println(key);
&#125;
</code></pre>
<p>代码实现：</p>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/26 19:57
 */
@SpringBootTest
public class HotelSearchTest &#123;

    private RestHighLevelClient client;

    @Test
    void testAggregation() throws IOException &#123;
        // 1.准备Request
        SearchRequest request = new SearchRequest(&quot;hotel&quot;);
        // 2.准备DSL
        // 2.1.设置size
        request.source().size(0);
        // 2.2.聚合
        request.source().aggregation(AggregationBuilders
                .terms(&quot;brandAgg&quot;)
                .field(&quot;brand&quot;)
                .size(10)
        );
        // 3.发出请求
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        // 4.解析结果
        Aggregations aggregations = response.getAggregations();
        // 4.1.根据聚合名称获取聚合结果
        Terms brandTerms = aggregations.get(&quot;brandAgg&quot;);
        // 4.2.获取buckets
        List&lt;? extends Terms.Bucket&gt; buckets = brandTerms.getBuckets();
        // 4.3.遍历
        for (Terms.Bucket bucket : buckets) &#123;
            // 4.4.获取key
            String key = bucket.getKeyAsString();
            System.out.println(key);
        &#125;
    &#125;

    @BeforeEach
    void setUp() &#123;
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create(&quot;http://192.168.49.10:9200&quot;)
        ));
    &#125;

    @AfterEach
    void tearDown() throws IOException &#123;
        this.client.close();
    &#125;
&#125;
</code></pre>
<h2 id="10-7-自动补全"><a href="#10-7-自动补全" class="headerlink" title="10.7. 自动补全"></a>10.7. 自动补全</h2><p>网页搜索框自动补全</p>
<p><strong>安装拼音分词器</strong></p>
<p>网站：<a target="_blank" rel="noopener" href="https://github.com/medcl/elasticsearch-analysis-pinyin">https://github.com/medcl/elasticsearch-analysis-pinyin</a></p>
<p>① 解压elasticsearch-analysis-pinyin-7.12.1.zip到挂载目录下&#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes&#x2F;es-plugins&#x2F;_data&#x2F;py</p>
<p>② docker restart es 重启</p>
<p>③ DSL测试</p>
<pre><code>POST /_analyze
&#123;
  &quot;text&quot;: [&quot;如家酒店还不错&quot;],
  &quot;analyzer&quot;: &quot;pinyin&quot;
&#125;
</code></pre>
<p><strong>自定义分词器</strong></p>
<p>elasticsearch中分词器 (analyzer) 的组成包含三部分：</p>
<ul>
<li>character filters：在tokenizer之前对文本进行处理。例如删除字符、替换字符</li>
<li>tokenizer：将文本按照一定的规则切割成词条 (term)。例如keyword，就是不分词；还有ik_smart</li>
<li>tokenizer filter：将tokenizer输出的词条做进一步处理。例如大小写转换、同义词处理、拼音处理等</li>
</ul>
<p><strong>使用</strong></p>
<p>创建索引库时，通过settings来配置自定义的analyzer（分词器）</p>
<pre><code>PUT /test
&#123;
  &quot;settings&quot;: &#123;
    &quot;analysis&quot;: &#123;
      &quot;analyzer&quot;: &#123; 
        &quot;my_analyzer&quot;: &#123; // 自定义分词器
          &quot;tokenizer&quot;: &quot;ik_max_word&quot;, // 分词器名称
          &quot;filter&quot;: &quot;py&quot;
        &#125;
      &#125;,
      &quot;filter&quot;: &#123; // 自定义tokenizer filter
        &quot;py&quot;: &#123;  // 过滤器名称
          &quot;type&quot;: &quot;pinyin&quot;, // 过滤器类型，这里是pinyin
          &quot;keep_full_pinyin&quot;: false,
          &quot;keep_joined_full_pinyin&quot;: true,
          &quot;keep_original&quot;: true,
          &quot;limit_first_letter_length&quot;: 16,
          &quot;remove_duplicated_term&quot;: true,
          &quot;none_chinese_pinyin_tokenize&quot;: false
        &#125;
      &#125;
    &#125;
  &#125;
&#125;
</code></pre>
<p>拼音分词器适合在创建倒排索引的时候使用，但不能在搜索的时候使用。</p>
<p>因此，字段在创建倒排索引时应该使用my_analyzer分词器，字段在搜索时应该使用ik_smart分词器</p>
<pre><code>PUT /test
&#123;
  &quot;settings&quot;: &#123;
    &quot;analysis&quot;: &#123;
      &quot;analyzer&quot;: &#123; 
        &quot;my_analyzer&quot;: &#123; 
          &quot;tokenizer&quot;: &quot;ik_max_word&quot;,
          &quot;filter&quot;: &quot;py&quot;
        &#125;
      &#125;,
      &quot;filter&quot;: &#123;
        &quot;py&quot;: &#123; 
          &quot;type&quot;: &quot;pinyin&quot;,
          &quot;keep_full_pinyin&quot;: false,
          &quot;keep_joined_full_pinyin&quot;: true,
          &quot;keep_original&quot;: true,
          &quot;limit_first_letter_length&quot;: 16,
          &quot;remove_duplicated_term&quot;: true,
          &quot;none_chinese_pinyin_tokenize&quot;: false
        &#125;
      &#125;
    &#125;
  &#125;,
  &quot;mappings&quot;: &#123;
    &quot;properties&quot;: &#123;
      &quot;name&quot;: &#123;
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;my_analyzer&quot;,
        &quot;search_analyzer&quot;: &quot;ik_smart&quot;
      &#125;
    &#125;
  &#125;
&#125;
</code></pre>
<p><strong>completion suggester查询</strong></p>
<p>elasticsearch提供了Completion Suggester查询来实现自动补全功能。这个查询会匹配以用户输入内容开头的词条返回。为了提高补全查询的效率，对于文档中字段的类型有一些约束：</p>
<ul>
<li>参与补全查询的字段必须是completion类型</li>
<li>字段的内容一般是用来补全的多个词条形成的数组。</li>
</ul>
<pre><code># 创建索引库：自动补全的索引库
PUT test2
&#123;
  &quot;mappings&quot;: &#123;
    &quot;properties&quot;: &#123;
      &quot;title&quot;:&#123;
        &quot;type&quot;: &quot;completion&quot;
      &#125;
    &#125;
  &#125;
&#125;
# 示例数据
POST test2/_doc
&#123;
  &quot;title&quot;: [&quot;Sony&quot;, &quot;WH-1000XM3&quot;]
&#125;
POST test2/_doc
&#123;
  &quot;title&quot;: [&quot;SK-II&quot;, &quot;PITERA&quot;]
&#125;
POST test2/_doc
&#123;
  &quot;title&quot;: [&quot;Nintendo&quot;, &quot;switch&quot;]
&#125;
</code></pre>
<p>查询语法如下：</p>
<pre><code># 自动补全查询
GET /test2/_search
&#123;
  &quot;suggest&quot;: &#123;
    &quot;titleSuggest&quot;: &#123;
      &quot;text&quot;: &quot;s&quot;, # 查询关键字
      &quot;completion&quot;: &#123;
        &quot;field&quot;: &quot;title&quot;, # 补全查询的字段
        &quot;skip_duplicates&quot;: true, # 跳过重复的
        &quot;size&quot;: 10 # 获取前10条结果
      &#125;
    &#125;
  &#125;
&#125;
</code></pre>
<p>自动补全对字段的要求：</p>
<ul>
<li>类型是completion类型</li>
<li>字段值是多词条的数组</li>
</ul>
<p>代码应用：</p>
<pre><code>PUT /hotel
&#123;
  &quot;settings&quot;: &#123;
    &quot;analysis&quot;: &#123;
      &quot;analyzer&quot;: &#123;
        &quot;text_anlyzer&quot;: &#123;
          &quot;tokenizer&quot;: &quot;ik_max_word&quot;,
          &quot;filter&quot;: &quot;py&quot;
        &#125;,
        &quot;completion_analyzer&quot;: &#123;
          &quot;tokenizer&quot;: &quot;keyword&quot;,
          &quot;filter&quot;: &quot;py&quot;
        &#125;
      &#125;,
      &quot;filter&quot;: &#123;
        &quot;py&quot;: &#123;
          &quot;type&quot;: &quot;pinyin&quot;,
          &quot;keep_full_pinyin&quot;: false,
          &quot;keep_joined_full_pinyin&quot;: true,
          &quot;keep_original&quot;: true,
          &quot;limit_first_letter_length&quot;: 16,
          &quot;remove_duplicated_term&quot;: true,
          &quot;none_chinese_pinyin_tokenize&quot;: false
        &#125;
      &#125;
    &#125;
  &#125;,
  &quot;mappings&quot;: &#123;
    &quot;properties&quot;: &#123;
      &quot;id&quot;:&#123;
        &quot;type&quot;: &quot;keyword&quot;
      &#125;,
      &quot;name&quot;:&#123;
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;text_anlyzer&quot;,
        &quot;search_analyzer&quot;: &quot;ik_smart&quot;,
        &quot;copy_to&quot;: &quot;all&quot;
      &#125;,
      &quot;address&quot;:&#123;
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;index&quot;: false
      &#125;,
      &quot;price&quot;:&#123;
        &quot;type&quot;: &quot;integer&quot;
      &#125;,
      &quot;score&quot;:&#123;
        &quot;type&quot;: &quot;integer&quot;
      &#125;,
      &quot;brand&quot;:&#123;
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;copy_to&quot;: &quot;all&quot;
      &#125;,
      &quot;city&quot;:&#123;
        &quot;type&quot;: &quot;keyword&quot;
      &#125;,
      &quot;starName&quot;:&#123;
        &quot;type&quot;: &quot;keyword&quot;
      &#125;,
      &quot;business&quot;:&#123;
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;copy_to&quot;: &quot;all&quot;
      &#125;,
      &quot;location&quot;:&#123;
        &quot;type&quot;: &quot;geo_point&quot;
      &#125;,
      &quot;pic&quot;:&#123;
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;index&quot;: false
      &#125;,
      &quot;all&quot;:&#123;
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;text_anlyzer&quot;,
        &quot;search_analyzer&quot;: &quot;ik_smart&quot;
      &#125;,
      &quot;suggestion&quot;:&#123;
          &quot;type&quot;: &quot;completion&quot;,
          &quot;analyzer&quot;: &quot;completion_analyzer&quot;
      &#125;
    &#125;
  &#125;
&#125;
</code></pre>
<p><strong>RestAPI实现自动补全</strong></p>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/7/26 19:57
 */
@SpringBootTest
public class HotelSearchTest &#123;

    private RestHighLevelClient client;

    @Test
    void testSuggest() throws IOException &#123;
        // 1.准备Request
        SearchRequest request = new SearchRequest(&quot;hotel&quot;);
        // 2.准备DSL
        request.source().suggest(new SuggestBuilder().addSuggestion(
            &quot;suggestions&quot;,
                SuggestBuilders.completionSuggestion(&quot;suggestion&quot;)
                        .prefix(&quot;h&quot;)
                        .skipDuplicates(true)
                        .size(10)
        ));
        // 3.发送请求
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        // 4.解析结果
        Suggest suggest = response.getSuggest();
        // 4.1.根据补全内容查询名称，获取补全结果
        CompletionSuggestion suggestions = suggest.getSuggestion(&quot;suggestions&quot;);
        // 4.2.获取options
        List&lt;CompletionSuggestion.Entry.Option&gt; options = suggestions.getOptions();
        // 4.3.遍历
        for (CompletionSuggestion.Entry.Option option : options) &#123;
            String text = option.getText().toString();
            System.out.println(text);
        &#125;
    &#125;

    @BeforeEach
    void setUp() &#123;
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create(&quot;http://192.168.49.10:9200&quot;)
        ));
    &#125;

    @AfterEach
    void tearDown() throws IOException &#123;
        this.client.close();
    &#125;
&#125;
</code></pre>
<h2 id="10-8-数据同步"><a href="#10-8-数据同步" class="headerlink" title="10.8. 数据同步"></a>10.8. 数据同步</h2><p>elasticsearch中的酒店数据来自于mysql数据库，因此mysql数据发生改变时，elasticsearch也必须跟着改变，这个就是elasticsearch与mysgl之间的数据同步。</p>
<p><strong>数据同步方式</strong>：</p>
<ul>
<li>方案一：同步调用<ul>
<li>MySQL和ES中同时更新</li>
<li>优点：实现简单，粗暴</li>
<li>缺点：业务耦合度高</li>
</ul>
</li>
<li>方案二：异步通知<ul>
<li>通过MQ去监听修改消息，异步更新MySQL和ES</li>
<li>优点：低耦合，实现难度一般</li>
<li>缺点：依赖mq的可靠性</li>
</ul>
</li>
<li>方案三：监听binlog<ul>
<li>MySQL中启动binlog，在MySQL中数据被修改会存入binlog中，使用canal中间件监听binlog，通知Consumer更新ES</li>
<li>优点：完全解除服务间耦合</li>
<li>缺点：开启binlog增加数据库负担、实现复杂度高</li>
</ul>
</li>
</ul>
<p><strong>实现：</strong></p>
<p>① Consumer和Publisher导入mq依赖</p>
<pre><code class="xml">        &lt;!--mq--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>
<p>② 修改Consumer和Publisher的yml</p>
<pre><code class="yml">spring:
  rabbitmq:
    host: 192.168.49.10
    port: 5672
    username: bamboo
    password: root
    virtual-host: /
</code></pre>
<p>③ Consumer声明队列和交换机代码</p>
<ol>
<li><p>常量【Publisher也放入一份】</p>
<pre><code class="java">package cn.itcast.hotel.constants;

/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/8/3 12:14
 */
public class MqConstants &#123;
    /**
     * 交换机
     */
    public final static String HOTEL_EXCHANGE = &quot;hotel.topic&quot;;
    /**
     * 监听新增和修改队列
     */
    public final static String HOTEL_INSERT_QUEUE = &quot;hotel.insert.queue&quot;;
    /**
     * 监听删除队列
     */
    public final static String HOTEL_DELETE_QUEUE = &quot;hotel.delete.queue&quot;;
    /**
     * 新增和修改的RoutingKey
     */
    public final static String HOTEL_INSERT_KEY = &quot;hotel.insert&quot;;
    /**
     * 删除的RoutingKey
     */
    public final static String HOTEL_DELETE_KEY = &quot;hotel.delete&quot;;

&#125;
</code></pre>
</li>
<li><p>声明</p>
<pre><code class="java">package cn.itcast.hotel.config;

import cn.itcast.hotel.constants.MqConstants;
import org.springframework.amqp.core.Binding;
import org.springframework.amqp.core.BindingBuilder;
import org.springframework.amqp.core.Queue;
import org.springframework.amqp.core.TopicExchange;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/8/3 12:19
 */
@Configuration
public class MqConfig &#123;

    @Bean
    public TopicExchange topicExchange() &#123;
        return new TopicExchange(MqConstants.HOTEL_EXCHANGE, true, false);
    &#125;

    @Bean
    public Queue insertQueue() &#123;
        return new Queue(MqConstants.HOTEL_INSERT_QUEUE, true);
    &#125;

    @Bean
    public Queue deleteQueue() &#123;
        return new Queue(MqConstants.HOTEL_DELETE_QUEUE, true);
    &#125;

    @Bean
    public Binding insertQueueBinding() &#123;
        return BindingBuilder.bind(insertQueue()).to(topicExchange()).with(MqConstants.HOTEL_INSERT_KEY);
    &#125;

    @Bean
    public Binding deleteQueueBinding() &#123;
        return BindingBuilder.bind(deleteQueue()).to(topicExchange()).with(MqConstants.HOTEL_DELETE_KEY);
    &#125;
&#125;
</code></pre>
</li>
</ol>
<p>④ Publisher编写Controller，注入RabbitTemplate，实现<strong>消息发送</strong></p>
<pre><code class="java">@RestController
@RequestMapping(&quot;hotel&quot;)
public class HotelController &#123;

    @Autowired
    private IHotelService hotelService;

    @Autowired
    private RabbitTemplate rabbitTemplate;

    @GetMapping(&quot;/&#123;id&#125;&quot;)
    public Hotel queryById(@PathVariable(&quot;id&quot;) Long id)&#123;
        return hotelService.getById(id);
    &#125;

    @GetMapping(&quot;/list&quot;)
    public PageResult hotelList(
            @RequestParam(value = &quot;page&quot;, defaultValue = &quot;1&quot;) Integer page,
            @RequestParam(value = &quot;size&quot;, defaultValue = &quot;1&quot;) Integer size
    )&#123;
        Page&lt;Hotel&gt; result = hotelService.page(new Page&lt;&gt;(page, size));

        return new PageResult(result.getTotal(), result.getRecords());
    &#125;

    @PostMapping
    public void saveHotel(@RequestBody Hotel hotel)&#123;
        hotelService.save(hotel);
        rabbitTemplate.convertAndSend(MqConstants.HOTEL_EXCHANGE, MqConstants.HOTEL_INSERT_KEY, hotel.getId());
    &#125;

    @PutMapping()
    public void updateById(@RequestBody Hotel hotel)&#123;
        if (hotel.getId() == null) &#123;
            throw new InvalidParameterException(&quot;id不能为空&quot;);
        &#125;
        hotelService.updateById(hotel);
        rabbitTemplate.convertAndSend(MqConstants.HOTEL_EXCHANGE, MqConstants.HOTEL_INSERT_KEY, hotel.getId());
    &#125;

    @DeleteMapping(&quot;/&#123;id&#125;&quot;)
    public void deleteById(@PathVariable(&quot;id&quot;) Long id) &#123;
        hotelService.removeById(id);
        rabbitTemplate.convertAndSend(MqConstants.HOTEL_EXCHANGE, MqConstants.HOTEL_DELETE_KEY, id);
    &#125;
&#125;
</code></pre>
<p>⑤ Consumer完成<strong>消息监听</strong>，并更新ES数据</p>
<ol>
<li><p>消息监听组件</p>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/8/3 12:43
 */
@Component
public class HotelListener &#123;

    @Autowired
    private IHotelService hotelService;

    /**
     * 监听酒店新增或修改的业务
     * @param id
     */
    @RabbitListener(queues = MqConstants.HOTEL_INSERT_QUEUE)
    public void listenHotelInsertOrUpdate(Long id) &#123;
        hotelService.insertById(id);
    &#125;

    /**
     * 监听酒店删除的业务
     * @param id
     */
    @RabbitListener(queues = MqConstants.HOTEL_DELETE_QUEUE)
    public void listenHotelDelete(Long id) &#123;
        hotelService.deleteById(id);
    &#125;
&#125;
</code></pre>
</li>
<li><p>Service层处理方法</p>
<pre><code class="java">@Service
public class HotelService extends ServiceImpl&lt;HotelMapper, Hotel&gt; implements IHotelService &#123;

    @Autowired
    private RestHighLevelClient client;

    @Override
    public void insertById(Long id) &#123;
        try &#123;
            Hotel hotel = getById(id);
            HotelDoc hotelDoc = new HotelDoc(hotel);
            // 1.准备Request
            IndexRequest request = new IndexRequest(&quot;hotel&quot;).id(hotel.getId().toString());
            // 2.准备DSL
            request.source(JSON.toJSONString(hotelDoc), XContentType.JSON);
            // 3.发送请求
            client.index(request, RequestOptions.DEFAULT);
        &#125; catch (IOException e) &#123;
            throw new RuntimeException(e);
        &#125;
    &#125;

    @Override
    public void deleteById(Long id) &#123;
        try &#123;
            // 1.准备Request
            DeleteRequest request = new DeleteRequest(&quot;hotel&quot;, id.toString());
            // 2.发送请求
            client.delete(request, RequestOptions.DEFAULT);
        &#125; catch (IOException e) &#123;
            throw new RuntimeException(e);
        &#125;
    &#125;
    // 其余业务代码...
&#125;
</code></pre>
</li>
</ol>
<h2 id="10-9-elasticsearch集群"><a href="#10-9-elasticsearch集群" class="headerlink" title="10.9. elasticsearch集群"></a>10.9. elasticsearch集群</h2><p>单机的elasticsearch做数据存储，必然面临两个问题:海量数据存储问题、单点故障问题</p>
<ul>
<li>海量数据存储问题: 将索引库从逻辑上拆分为N个分片 (shard)，存储到多个节点</li>
<li>单点故障问题:将分片数据在不同节点备份 (replica )</li>
</ul>
<h3 id="10-9-1-创建ES集群"><a href="#10-9-1-创建ES集群" class="headerlink" title="10.9.1 创建ES集群"></a>10.9.1 创建ES集群</h3><p>① 上传docker-compose.yml至&#x2F;root</p>
<pre><code>version: &#39;2.2&#39;
services:
  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1
    container_name: es01
    environment:
      - node.name=es01
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es02,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data01:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    networks:
      - elastic
  es02:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1
    container_name: es02
    environment:
      - node.name=es02
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data02:/usr/share/elasticsearch/data
    networks:
      - elastic
  es03:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1
    container_name: es03
    environment:
      - node.name=es03
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01,es02
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data03:/usr/share/elasticsearch/data
    networks:
      - elastic

volumes:
  data01:
    driver: local
  data02:
    driver: local
  data03:
    driver: local

networks:
  elastic:
    driver: bridge
</code></pre>
<p>② 修改linux配置</p>
<ol>
<li><p>修改<code>/etc/sysctl.conf</code>文件：</p>
<pre><code class="sh">vi /etc/sysctl.conf
</code></pre>
</li>
<li><p>添加以下内容：</p>
<pre><code class="sh">vm.max_map_count=262144
</code></pre>
</li>
<li><p>执行命令使其配置生效：</p>
<pre><code class="sh">sysctl -p
</code></pre>
</li>
</ol>
<h3 id="10-9-2-集群状态监控【cerebro】"><a href="#10-9-2-集群状态监控【cerebro】" class="headerlink" title="10.9.2 集群状态监控【cerebro】"></a>10.9.2 集群状态监控【cerebro】</h3><p>kibana可以监控es集群，不过新版本需要依赖es的x-pack功能，配置复杂</p>
<p>推荐使用<strong>【cerebro】</strong>来监控es集群状态，官方网址：<a target="_blank" rel="noopener" href="https://github.com/lmenezes/cerebro">https://github.com/lmenezes/cerebro</a></p>
<p>① windows下解压cerebro，运行<code>bin/cerebro.bat</code>即可</p>
<p>② 输入地址：<code>http://localhost:9000</code>进行访问</p>
<p>③ 选择地址<code>http://192.168.49.10:9200</code>进行es集群连接</p>
<p>④ 创建分片【索引库】：</p>
<ul>
<li>选择more -&gt; create index </li>
<li>修改名称：name : bamboo</li>
<li>设置分片数：number of shards : 3</li>
<li>设置副本数量：number of replicas : 1</li>
<li>创建：create</li>
</ul>
<p><strong>ES集群的节点角色</strong></p>
<p>elasticsearch中集群节点有不同的职责划分：</p>
<table>
<thead>
<tr>
<th align="center">节点类型</th>
<th align="center">配置参数</th>
<th align="center">默认值</th>
<th align="center">节点职责</th>
</tr>
</thead>
<tbody><tr>
<td align="center">master eligible</td>
<td align="center">node.master</td>
<td align="center">true</td>
<td align="center">备选主节点：主节点可以管理和记录集群状态、决定分片在哪个节点、处理创建和删除索引库的请求</td>
</tr>
<tr>
<td align="center">data</td>
<td align="center">node.data</td>
<td align="center">true</td>
<td align="center">数据节点：存储数据、搜索、聚合、CRUD</td>
</tr>
<tr>
<td align="center">ingest</td>
<td align="center">node.ingest</td>
<td align="center">true</td>
<td align="center">数据存储之前的预处理</td>
</tr>
<tr>
<td align="center">coordinating</td>
<td align="center">上面3个参数都为false时，则为coordinating节点</td>
<td align="center">无</td>
<td align="center">路由请求到其他节点，合并其他节点处理的结果，返回给用户</td>
</tr>
</tbody></table>
<p><strong>ES集群的分布式查询</strong></p>
<p>elasticsearch中的每个节点角色都有自己不同的职责，因此建议集群部署时，每个节点都有独立的角色。</p>
<p>User</p>
<ul>
<li>LB<ul>
<li>coordinating</li>
<li>coordinating</li>
<li>coordinating<ul>
<li>data</li>
<li>data</li>
<li>data</li>
<li>data</li>
<li>data<ul>
<li>※master-eligible</li>
<li>master-eligible</li>
<li>master-eligible</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>elasticsearch的查询分成两个阶段：</p>
<ul>
<li>scatter phase：分散阶段，coordinating node会把请求分发到每一个分片</li>
<li>gather phase：聚集阶段，coordinating node汇总data node的搜索结果，并处理为最终结果集返回给用户</li>
</ul>
<p><strong>ES集群的脑裂</strong></p>
<p>默认情况下，每个节点都是mastereligible节点，因此一旦master节点宕机，其它候选节点会选举一个成为主节点。当主节点与其他节点网</p>
<p>络故障时，可能发生脑裂问题。</p>
<p>为了避免脑裂，需要要求选票超过（eligible节点数量+1）&#x2F;2才能当选为主，因此eligible节点数量最好是奇数。</p>
<p>对应配置项是discovery.zen.minimum_master_nodes，在es7.0以后，已经成为默认配置，因此一般不会发生脑裂问题。</p>
<p><strong>ES集群的分布式存储</strong></p>
<p>当新增文档时，应该保存到不同分片，保证数据均衡，那么coordinating的elasticsearch会通过hash算法来计算文档应该存储到哪个分</p>
<p>片：<code>shard = hash(_routing) % number_of_shards</code></p>
<p>说明：</p>
<ul>
<li>_routing默认是文档的id</li>
<li>算法与分片数量有关，因此索引库一旦创建，分片数量不能修改</li>
</ul>
<p><strong>ES集群的故障转移</strong></p>
<p>集群的master节点会监控集群中的节点状态，如果发现有节点岩机，会立即将宕机节点的分片数据迁移到其它节点，确保数据安全，这个</p>
<p>叫做故障转移。</p>
<ul>
<li>master宕机后，EligibleMaster选举为新的主节点</li>
<li>master节点监控分片、节点状态，将故障节点上的分片转移到正常节点，确保数据安全</li>
</ul>
<h3 id="10-9-3-Insomnia工具使用"><a href="#10-9-3-Insomnia工具使用" class="headerlink" title="10.9.3 Insomnia工具使用"></a>10.9.3 Insomnia工具使用</h3><p>使用HttpRequest进行发送请求</p>
<p>① 添加数据</p>
<ul>
<li><p>方式：POST</p>
</li>
<li><p>地址：<a target="_blank" rel="noopener" href="http://192.168.49.10:9200/bamboo/_doc/6">http://192.168.49.10:9200/bamboo/_doc/6</a></p>
</li>
<li><p>JSON数值：</p>
<pre><code class="json">&#123;
    &quot;title&quot;: &quot;试着插入一条数据 id = 3&quot;
&#125;
</code></pre>
</li>
</ul>
<p>② 查询数据</p>
<ul>
<li><p>方式：GET</p>
</li>
<li><p>地址：<a target="_blank" rel="noopener" href="http://192.168.49.10:9200/bamboo/_search">http://192.168.49.10:9200/bamboo/_search</a></p>
</li>
<li><p>JSON数值：</p>
<pre><code class="json">&#123;
    &quot;explain&quot;: true, # 开启后可查看数据所在分片
    &quot;query&quot;: &#123;
        &quot;match_all&quot;: &#123;&#125;
    &#125;
&#125;
</code></pre>
</li>
<li><p>返回值</p>
<pre><code class="json">&#123;
    &quot;took&quot;: 1095,
    &quot;timed_out&quot;: false,
    &quot;_shards&quot;: &#123;
        &quot;total&quot;: 3,
        &quot;successful&quot;: 3,
        &quot;skipped&quot;: 0,
        &quot;failed&quot;: 0
    &#125;,
    &quot;hits&quot;: &#123;
        &quot;total&quot;: &#123;
            &quot;value&quot;: 4,
            &quot;relation&quot;: &quot;eq&quot;
        &#125;,
        &quot;max_score&quot;: 1.0,
        &quot;hits&quot;: [
            &#123;
                &quot;_shard&quot;: &quot;[bamboo][0]&quot;, # 数据所在分片
                &quot;_node&quot;: &quot;5mLs1IqST3GCewoZEZku9g&quot;,
                &quot;_index&quot;: &quot;bamboo&quot;,
                &quot;_type&quot;: &quot;_doc&quot;,
                &quot;_id&quot;: &quot;5&quot;,
                &quot;_score&quot;: 1.0,
                &quot;_source&quot;: &#123;
                    &quot;title&quot;: &quot;试着插入一条数据 id = 5&quot;
                &#125;,
                &quot;_explanation&quot;: &#123;
                    &quot;value&quot;: 1.0,
                    &quot;description&quot;: &quot;*:*&quot;,
                    &quot;details&quot;: []
                &#125;
            &#125;,
            &#123;
                &quot;_shard&quot;: &quot;[bamboo][1]&quot;,
                &quot;_node&quot;: &quot;nJUAL_EqSbOdm6lpFx_Y6A&quot;,
                &quot;_index&quot;: &quot;bamboo&quot;,
                &quot;_type&quot;: &quot;_doc&quot;,
                &quot;_id&quot;: &quot;3&quot;,
                &quot;_score&quot;: 1.0,
                &quot;_source&quot;: &#123;
                    &quot;title&quot;: &quot;试着插入一条数据 id = 3&quot;
                &#125;,
                &quot;_explanation&quot;: &#123;
                    &quot;value&quot;: 1.0,
                    &quot;description&quot;: &quot;*:*&quot;,
                    &quot;details&quot;: []
                &#125;
            &#125;,
            &#123;
                &quot;_shard&quot;: &quot;[bamboo][2]&quot;,
                &quot;_node&quot;: &quot;nJUAL_EqSbOdm6lpFx_Y6A&quot;,
                &quot;_index&quot;: &quot;bamboo&quot;,
                &quot;_type&quot;: &quot;_doc&quot;,
                &quot;_id&quot;: &quot;1&quot;,
                &quot;_score&quot;: 1.0,
                &quot;_source&quot;: &#123;
                    &quot;title&quot;: &quot;试着插入一条数据 id = 1&quot;
                &#125;,
                &quot;_explanation&quot;: &#123;
                    &quot;value&quot;: 1.0,
                    &quot;description&quot;: &quot;*:*&quot;,
                    &quot;details&quot;: []
                &#125;
            &#125;,
            &#123;
                &quot;_shard&quot;: &quot;[bamboo][2]&quot;,
                &quot;_node&quot;: &quot;nJUAL_EqSbOdm6lpFx_Y6A&quot;,
                &quot;_index&quot;: &quot;bamboo&quot;,
                &quot;_type&quot;: &quot;_doc&quot;,
                &quot;_id&quot;: &quot;6&quot;,
                &quot;_score&quot;: 1.0,
                &quot;_source&quot;: &#123;
                    &quot;title&quot;: &quot;试着插入一条数据 id = 6&quot;
                &#125;,
                &quot;_explanation&quot;: &#123;
                    &quot;value&quot;: 1.0,
                    &quot;description&quot;: &quot;*:*&quot;,
                    &quot;details&quot;: []
                &#125;
            &#125;
        ]
    &#125;
&#125;
</code></pre>
</li>
</ul>
<h1 id="十一、Sentinel【微服务保护】"><a href="#十一、Sentinel【微服务保护】" class="headerlink" title="十一、Sentinel【微服务保护】"></a>十一、Sentinel【微服务保护】</h1><p><strong>雪崩问题</strong> 微服务调用链路中的某个服务故障，引起整个链路中的所有微服务都不可用，这就是雪崩。</p>
<p><strong>解决雪崩</strong>问题的常见方式有四种：</p>
<p>超时处理【服务故障而引发的雪崩】：设定超时时间，请求超过一定时间没有响应就返回错误信息，不会无休止等待。</p>
<p>舱壁模式【服务故障而引发的雪崩】：限定每个业务能使用的线程数，避免耗尽整个tomcat的资源，因此也叫线程隔离。</p>
<p>熔断降级【服务故障而引发的雪崩】：由<strong>断路器</strong>统计业务执行的异常比例，如果超出阈值则会<strong>熔断</strong>该业务，拦截访问该业务的一切请求。</p>
<p>流量控制【避免因瞬间高并发流量而导致服务故障】：限制业务访问的QPS，避免服务因流量的突增而故障。</p>
<p><strong>服务保护技术对比</strong></p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">Sentinel</th>
<th align="center">Hystrix</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>隔离策略</strong></td>
<td align="center">信号量隔离</td>
<td align="center">线程池隔离&#x2F;信号量隔离</td>
</tr>
<tr>
<td align="center"><strong>熔断降级策略</strong></td>
<td align="center">基于慢调用比例或异常比例</td>
<td align="center">基于失败比例</td>
</tr>
<tr>
<td align="center">实施指标实现</td>
<td align="center">滑动窗口</td>
<td align="center">滑动窗口（基于 RxJava）</td>
</tr>
<tr>
<td align="center">规则配置</td>
<td align="center">支持多种数据源</td>
<td align="center">支持多种数据源</td>
</tr>
<tr>
<td align="center">扩展性</td>
<td align="center">多个扩展点</td>
<td align="center">插件的形式</td>
</tr>
<tr>
<td align="center">基于注解的支持</td>
<td align="center">支持</td>
<td align="center">支持</td>
</tr>
<tr>
<td align="center"><strong>限流</strong></td>
<td align="center">基于QPS，支持基于调用关系的限流</td>
<td align="center">有限的支持</td>
</tr>
<tr>
<td align="center"><strong>流量整形</strong></td>
<td align="center">支持慢启动、匀速排队模式</td>
<td align="center">不支持</td>
</tr>
<tr>
<td align="center">系统自适应保护</td>
<td align="center">支持</td>
<td align="center">不支持</td>
</tr>
<tr>
<td align="center"><strong>控制台</strong></td>
<td align="center">开箱即用，可配置规则、查看秒级监控、机器发现等</td>
<td align="center">不完善</td>
</tr>
<tr>
<td align="center">常见框架的适配</td>
<td align="center">Servlet、Spring Cloud、Dubbo、gRPC等</td>
<td align="center">Servlet、Spring Cloud Netflix</td>
</tr>
</tbody></table>
<p><strong>认识Sentinel</strong> Sentinel是阿里巴巴开源的一款微服务流量控制组件。官网地址: <a target="_blank" rel="noopener" href="https://sentinelguard.io/zh-cn/index.html">https://sentinelguard.io/zh-cn/index.html</a></p>
<p>Sentinel具有以下特征:</p>
<ul>
<li><strong>丰富的应用场景</strong>：Sentinel承接了阿里巴巴近10年的双十一大促流量的核心场景，例如秒杀(即突发流量控制在系统容量可以承受的范围)、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等</li>
<li><strong>完备的实时监控</strong>：Sentinel同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至500台以下规模的集群的汇总运行情况。</li>
<li><strong>广泛的开源生态</strong>：Sentinel提供开箱即用的与其它开源框架&#x2F;库的整合模块，例如与 Spring Cloud、Dubbo、gRPC的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。</li>
<li><strong>完善的 SPI 扩展点</strong>：Sentinel提供简单易用、完善的 SPI 扩展接口。您可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等。</li>
</ul>
<p><strong>安装Sentinel控制台</strong> sentinel官方提供了UI控制台，方便我们对系统做限流设置。可以在GitHub下载。【sentinel-dashboard-1.8.1.jar】</p>
<ul>
<li>将其拷贝到一个非中文目录，然后运行命令:<code>java -jar sentinel-dashboard-1.8.1.jar</code></li>
<li>然后访问：<code>localhost:8080</code>即可看到控制台页面，默认的账户和密码都是sentinel</li>
</ul>
<table>
<thead>
<tr>
<th align="center">配置项</th>
<th align="center">默认值</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">server.port</td>
<td align="center">8080</td>
<td align="center">服务端口</td>
</tr>
<tr>
<td align="center">sentinel.dashboard.auth.username</td>
<td align="center">sentinel</td>
<td align="center">默认用户名</td>
</tr>
<tr>
<td align="center">sentinel.dashboard.auth.password</td>
<td align="center">sentinel</td>
<td align="center">默认密码</td>
</tr>
</tbody></table>
<p>举例：<code>java -jar sentinel-dashboard-1.8.1.jar -Dserver.port=8090</code></p>
<p><strong>应用sentinel</strong></p>
<p>结合微服务使用Sentinel，使用一个SpringCloud工厂</p>
<p>项目结构：</p>
<ul>
<li>gateway</li>
<li>user-uservice【Publisher】：用户服务，包含用户CRUD</li>
<li>order-service【Consumer】：订单服务，调用user-service</li>
<li>feign-api：用户服务对外暴露的feign客户端、实体类</li>
</ul>
<p>① Consumer引入依赖</p>
<pre><code class="xml">        &lt;!--引入sentinel依赖--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>
<p>② Consumer配置yml</p>
<pre><code class="yml">spring:
  cloud:
    sentinel:
      transport:
        dashboard: localhost:8080 # sentinel控制台地址
</code></pre>
<p>③ 访问微服务任意端点，触发sentinel监控</p>
<h2 id="11-1-限流规则"><a href="#11-1-限流规则" class="headerlink" title="11.1. 限流规则"></a>11.1. 限流规则</h2><h3 id="11-1-1-簇点链路"><a href="#11-1-1-簇点链路" class="headerlink" title="11.1.1 簇点链路"></a>11.1.1 簇点链路</h3><p>簇点链路：就是项目内的调用链路，链路中<strong>被监控</strong>的每个接口就是一个资源。默认情况下sentinel会监控SpringMVC的每一个端点 (Endpoint)，因此SpringMVC的每一个端点 (Endpoint)就是调用链路中的一个资源。</p>
<p>流控、熔断等都是针对簇点链路中的资源来设置的，因此我们可以点击对应资源后面的按钮来设置规则:</p>
<ul>
<li>簇点链路 &#x3D;》接口&#x3D;》流控</li>
</ul>
<h3 id="11-1-2-JMeter测试"><a href="#11-1-2-JMeter测试" class="headerlink" title="11.1.2 JMeter测试"></a>11.1.2 JMeter测试</h3><p>利用jmeter测试服务器压力</p>
<h3 id="11-1-3-流控模式"><a href="#11-1-3-流控模式" class="headerlink" title="11.1.3 流控模式"></a>11.1.3 流控模式</h3><p>在添加限流规则时，点击高级选项，可以选择<strong>三种</strong>流控模式：</p>
<ul>
<li>直接：统计当前资源的请求，触发阈值时对当前资源直接限流，也是默认的模式</li>
<li>关联：统计与当前资源相关的另一个资源，触发阈值时，对当前资源限流</li>
<li>链路：统计从指定链路访问到本资源的请求，触发阈值时，对指定链路限流</li>
</ul>
<h4 id="①-流控模式——关联"><a href="#①-流控模式——关联" class="headerlink" title="① 流控模式——关联"></a>① 流控模式——关联</h4><p>关联模式：统计与当前资源相关的另一个资源，触发阈值时，对当前资源限流 使用场景：比如用户支付时需要修改订单状态，同时用户要查询订单。查询和修改操作会争抢数据库锁，产生竞争。业务需求是有限支付和更新订单的业务，因此当修改订单业务触发闻值时，需要对查询订单业务限流。</p>
<p><strong>例</strong>：配置资源名<code>/read</code>，关联资源<code>/write</code>，则当<code>/write</code>访问量触发阈值时，就会对<code>/read</code>资源限流</p>
<p><strong>案例</strong>：</p>
<ul>
<li>在OrderController中设置<code>/order/query</code>和<code>/order/update</code></li>
<li>配置流控规则，当<code>/order/update</code>资源被访问的QPS超过5时，对<code>/order/query</code>请求限流</li>
</ul>
<h4 id="②-流控模式——链路"><a href="#②-流控模式——链路" class="headerlink" title="② 流控模式——链路"></a>② 流控模式——链路</h4><p>链路模式：只针对从指定链路访问到本资源的请求做统计，判断是否超过阈值。例如有两条请求链路。</p>
<ul>
<li>&#x2F;test1 &#x3D;》&#x2F;common</li>
<li>&#x2F;test2 &#x3D;》&#x2F;common</li>
</ul>
<p>如果只希望统计从&#x2F;test2进入到&#x2F;common的请求，则可以这样配置：</p>
<p><strong>例</strong>：配置流控规则，设置资源名为<code>/common</code>，流控模式为<strong>链路</strong>，入口资源为<code>/test2</code>，这样就只会拦截test2</p>
<p><strong>案例</strong>：</p>
<ul>
<li><p>Sentinel默认只标记Controller中的方法为资源，如果要标记其它方法，需要利用@SentinelResource注解，示例：</p>
<pre><code class="java">// service层代码
@SentinelResource(&quot;goods&quot;)
public void queryGoods()&#123;
    System.err.println(&quot;查询商品&quot;);
&#125;
</code></pre>
</li>
<li><p>Sentinel默认会将Controller方法做context整合，导致链路模式的流控失效，需要修改application.yml，添加配置：</p>
<pre><code class="yml">spring:
  cloud:
    sentinel:
      web-context-unify: false # 关闭context整合
</code></pre>
</li>
<li><p>Controller中的映射直接调用被标注@SentinelResource注解的方法即可</p>
</li>
</ul>
<h3 id="11-1-4-流控效果"><a href="#11-1-4-流控效果" class="headerlink" title="11.1.4 流控效果"></a>11.1.4 流控效果</h3><p>流控效果是指请求达到流控阈值时应该采取的措施，包括<strong>三种</strong>：</p>
<ul>
<li>快速失败：达到阈值后，新的请求会被立即拒绝并抛出FIowException异常。是默认的处理方式。</li>
<li>warm up：预热模式，对超出阈值的请求同样是拒绝并抛出异常。但这种模式阈值会动态变化，从一个较小值逐渐增加到最大阈值。</li>
<li>排队等待：让所有的请求按照先后次序排队执行，两个请求的间隔不能小于指定时长</li>
</ul>
<h4 id="①-流控效果-warm-up"><a href="#①-流控效果-warm-up" class="headerlink" title="① 流控效果-warm up"></a>① 流控效果-warm up</h4><p>warmup也叫预热模式，是应对服务冷启动的一种方案。请求阈值初始值是 threshold&#x2F;coldFactor，持续指定时长后，逐渐提高到threshold值。而coldFactor的默认值是3。</p>
<p>例如，我设置QPS的threshold为10，预热时间为5秒，那么初始阈值就是 10&#x2F;3，也就是3，然后在5秒后逐渐增长到10。</p>
<h4 id="②-流控效果-排队等待"><a href="#②-流控效果-排队等待" class="headerlink" title="② 流控效果-排队等待"></a>② 流控效果-排队等待</h4><p>当请求超过QPS阈值时，快速失败和warm up 会拒绝新的请求并抛出异常。而排队等待则是让所有请求进入一个队列中，然后按照阈值允许的时间间隔依次执行。后来的请求必须等待前面执行完成，如果请求预期的等待时间超出最大时长，则会被拒绝。</p>
<p><strong>例如</strong>:QPS&#x3D;5，意味着每200ms处理一个队列中的请求，timeout&#x3D; 2000，意味着预期等待超过2000ms的请求会被拒绝并抛出异常。</p>
<h3 id="11-1-5-热点参数限流"><a href="#11-1-5-热点参数限流" class="headerlink" title="11.1.5 热点参数限流"></a>11.1.5 热点参数限流</h3><p>之前的限流是统计访问某个资源的所有请求，判断是否超过QPS阈值。而热点参数限流是分别统计参数值相同的请求判断是否超过QPS阈值。</p>
<p>例：</p>
<ul>
<li>请求参数：<ul>
<li><code>id = 1</code></li>
<li><code>id = 1</code></li>
<li><code>id = 1</code></li>
<li><code>id = 1</code></li>
</ul>
</li>
<li>QPS<ul>
<li>3 : <code>id = 1</code></li>
<li>1：<code>id = 2</code></li>
</ul>
</li>
</ul>
<p>配置：参数索引设置0，单机阈值设置5，统计窗口时长设置1</p>
<p><strong>高级选项</strong>：可以对部分参数设置例外配置</p>
<ul>
<li>参数类型</li>
<li>参数值</li>
<li>限流阈值</li>
</ul>
<p>注：热点参数限流对默认SpringMVC资源无效，需要在controller层的映射中增加@SentinelResource(“hot”)注解</p>
<p>应用：</p>
<pre><code class="java">    @SentinelResource(&quot;hot&quot;)
    @GetMapping(&quot;&#123;orderId&#125;&quot;)
    public Order queryOrderByUserId(@PathVariable(&quot;orderId&quot;) Long orderId) &#123;
        // 根据id查询订单并返回
        return orderService.queryOrderById(orderId);
    &#125;
</code></pre>
<p>配置Sentinel：</p>
<ul>
<li>热点规则 &#x3D; 》<ul>
<li>资源名hot，参数索引0，单机阈值2，统计窗口时长1</li>
<li>参数例外项：参数类型long，参数值：102&#x2F;4和103&#x2F;10</li>
</ul>
</li>
</ul>
<h2 id="11-2-隔离和降级"><a href="#11-2-隔离和降级" class="headerlink" title="11.2. 隔离和降级"></a>11.2. 隔离和降级</h2><p>虽然限流可以尽量避免因高并发而引起的服务故障，但服务还会因为其它原因而故障。而要将这些故障控制在一定范围避免雪崩，就要靠线程隔离(舱壁模式)和熔断降级手段了。</p>
<p>不管是线程隔离还是熔断降级，都是对**客户端 (调用方)**的保护。</p>
<h3 id="11-2-1-Feign整合Sentinel"><a href="#11-2-1-Feign整合Sentinel" class="headerlink" title="11.2.1 Feign整合Sentinel"></a>11.2.1 Feign整合Sentinel</h3><p>SpringCloud中，微服务调用都是通过Feign来实现的，因此做客户端保护必须整合Feign和Sentinel。</p>
<ol>
<li><p>修改OrderService【Consumer】的application.yml文件，开启Feign的Sentinel功能</p>
<pre><code class="yml">feign:
  sentinel:
    enabled: true # 开启feign对sentinel的支持
</code></pre>
</li>
<li><p>给FeignClient编写失败后的降级逻辑</p>
<ul>
<li><p>方式一：FallbackClass，无法对远程调用的异常做处理</p>
</li>
<li><p>方式二：FallbackFactory，可以对远程调用的异常做处理【推荐】</p>
</li>
<li><p>① 在feign-api中定义类，实现<code>FallBackFactory</code>接口：</p>
<pre><code class="java">@Slf4j
public class UserClientFallbackFactory implements FallbackFactory&lt;UserClient&gt; &#123;
    @Override
    public UserClient create(Throwable throwable) &#123;
        return new UserClient() &#123;
            @Override
            public User findById(Long id) &#123;
                log.error(&quot;查询用户异常&quot;, throwable);
                return new User();
            &#125;
        &#125;;
    &#125;
&#125;
</code></pre>
</li>
<li><p>② 在feign-api项目中的DefaultFeignConfiguration类中将UserClientFallbackFactory注册为一个Bean：</p>
<pre><code class="java">public class DefaultFeignConfiguration &#123;
    @Bean
    public Logger.Level logLevel()&#123;
        return Logger.Level.BASIC;
    &#125;

    @Bean
    public UserClientFallbackFactory userClientFallbackFactory()&#123;
        return new UserClientFallbackFactory();
    &#125;
&#125;
</code></pre>
</li>
<li><p>③ 在feign-api中的UserClient接口中使用UserClientFallbackFactory：</p>
<pre><code class="java">@FeignClient(value = &quot;userservice&quot;, fallbackFactory = UserClientFallbackFactory.class)
public interface UserClient &#123;

    @GetMapping(&quot;/user/&#123;id&#125;&quot;)
    User findById(@PathVariable(&quot;id&quot;) Long id);
&#125;
</code></pre>
</li>
</ul>
</li>
</ol>
<h3 id="11-2-2-线程隔离"><a href="#11-2-2-线程隔离" class="headerlink" title="11.2.2 线程隔离"></a>11.2.2 线程隔离</h3><p>线程隔离有两种方式实现：</p>
<ul>
<li>线程池隔离<ul>
<li>优点：<ul>
<li>支持主动超时</li>
<li>支持异步调用</li>
</ul>
</li>
<li>缺点：线程的额外开销比较大</li>
<li>场景：低扇出</li>
</ul>
</li>
<li>信号量隔离（Sentinel默认采用）<ul>
<li>优点：轻量级，无额外开销</li>
<li>缺点：<ul>
<li>不支持主动超时</li>
<li>不支持异步调用</li>
</ul>
</li>
<li>场景<ul>
<li>高频调用</li>
<li>高扇出</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="①-线程隔离-舱壁模式"><a href="#①-线程隔离-舱壁模式" class="headerlink" title="① 线程隔离 (舱壁模式)"></a>① 线程隔离 (舱壁模式)</h4><p>在添加限流规则时，可以选择两种阈值类型：</p>
<ul>
<li>OPS：就是每秒的请求数。</li>
<li>线程数：是该资源能使用的tomcat线程数的最大值。也就是通过限制线程数量，实现舱壁模式。</li>
</ul>
<h3 id="11-2-3-熔断降级"><a href="#11-2-3-熔断降级" class="headerlink" title="11.2.3 熔断降级"></a>11.2.3 熔断降级</h3><p>熔断降级是解决雪崩问题的重要手段。其思路是由<strong>断路器</strong>统计服务调用的异常比例、慢请求比例，如果超出阈值则会熔断该服务。即拦截访问该服务的一切请求；而当服务恢复时，断路器会放行访问该服务的请求。</p>
<h4 id="①-熔断策略——慢调用"><a href="#①-熔断策略——慢调用" class="headerlink" title="① 熔断策略——慢调用"></a>① 熔断策略——慢调用</h4><p>慢调用：业务的响应时长(RT response time)大于指定时长的请求认定为慢调用请求。在指定时间内，如果请求数量超过设定的最小数量，慢调用比例大于设定的阈值，则触发熔断。例如：</p>
<ul>
<li>熔断策略：慢调用比例</li>
<li>最大RT：500ms</li>
<li>比例阈值：0.5</li>
<li>熔断时长：5s</li>
<li>最小请求数：10</li>
<li>统计时长：10000ms</li>
</ul>
<p>解读：RT超过500ms的调用是慢调用，统计最近10000ms内的请求，如果请求量超过10次，并且慢调用比例不低于0.5则触发熔断，熔断时长为5秒。然后进入half-open状态，放行一次请求做测试。</p>
<h4 id="②-熔断策略——异常比例、异常数"><a href="#②-熔断策略——异常比例、异常数" class="headerlink" title="② 熔断策略——异常比例、异常数"></a>② 熔断策略——异常比例、异常数</h4><p>异常比例或异常数：统计指定时间内的调用，如果调用次数超过指定请求数，并且出现异常的比例达到设定的比例阈值(或超过指定异常数)，则触发熔断。例如:</p>
<ul>
<li>异常比例策略<ul>
<li>熔断策略：异常比例</li>
<li>比例阈值：0.4</li>
<li>熔断时长：5s</li>
<li>最小请求数：10</li>
<li>统计时长1000s</li>
</ul>
</li>
<li>异常数策略<ul>
<li>熔断策略：异常数</li>
<li>异常数：2</li>
<li>熔断时长：5s</li>
<li>最小请求数：10</li>
<li>统计时长1000s</li>
</ul>
</li>
</ul>
<p>解读：统计最近1000ms内的请求，如果请求量超过10次，并且异常比例不低于0.5，则触发熔断，熔断时长为5秒。然后进入half-open状态，放行一次请求做测试.</p>
<h2 id="11-3-授权规则"><a href="#11-3-授权规则" class="headerlink" title="11.3. 授权规则"></a>11.3. 授权规则</h2><p>授权规则可以对调用方的来源做控制，有白名单和黑名单两种方式。</p>
<ul>
<li>白名单：来源 (origin)在白名单内的调用者允许访问</li>
<li>黑名单：来源(origin)在黑名单内的调用者不允许访问</li>
</ul>
<p>主要是配合网关gateway进行实现。</p>
<h3 id="11-3-1-网关授权"><a href="#11-3-1-网关授权" class="headerlink" title="11.3.1 网关授权"></a>11.3.1 网关授权</h3><p>Sentinel是通过RequestOriginParser这个接口的parseOrigin来获取请求的来源的。</p>
<pre><code class="java">public interface RequestOriginParser &#123;
    // 从请求var1对象中获取origin，获取方式自定义
    String parseOrigin(HttpServletRequest var1);
&#125;
</code></pre>
<p><strong>例</strong>：从var1中获取一个名为origin的请求头，作为origin的值</p>
<p>① 在Consumer中添加此类</p>
<pre><code class="java">package cn.itcast.order.sentinel;

@Component
public class HeaderOriginParser implements RequestOriginParser &#123;
    @Override
    public String parseOrigin(HttpServletRequest request) &#123;
        // 1.获取请求头
        String origin = request.getHeader(&quot;origin&quot;);
        // 2.非空判断
        if (StringUtils.isEmpty(origin)) &#123;
            origin = &quot;blank&quot;;
        &#125;
        return origin;
    &#125;
&#125;
</code></pre>
<p>② 在gateway服务中，利用网关的过滤器添加名为gateway的origin头</p>
<pre><code class="yml">spring:
  cloud:
    gateway:
      default-filters:
        - AddRequestHeader=origin,gateway # 添加名为origin的请求头，值为gateway
</code></pre>
<p>③ 在sentinel给<code>/order/&#123;orderId&#125;</code>配置<strong>授权</strong>规则</p>
<ul>
<li>资源名：<code>/order/&#123;orderId&#125;</code></li>
<li>流控应用：gateway</li>
<li>授权类型：白名单</li>
</ul>
<h3 id="11-3-2-自定义异常结果"><a href="#11-3-2-自定义异常结果" class="headerlink" title="11.3.2 自定义异常结果"></a>11.3.2 自定义异常结果</h3><p>默认情况下，发生限流、降级、授权拦截时，都会抛出异常到调用放。自定义异常时返回结果，需要实现BlockExceptionHandler接口</p>
<pre><code class="java">public interface BlockExceptionHandler &#123;
    // 处理请求被限流、降级、授权拦截时抛出的异常：BlockException
    void handle(HttpServletRequest var1, HttpServletResponse var2, BlockException var3) throws Exception;
&#125;
</code></pre>
<table>
<thead>
<tr>
<th align="center">异常</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">FlowException</td>
<td align="center">限流异常</td>
</tr>
<tr>
<td align="center">ParamFlowException</td>
<td align="center">热点参数限流的异常</td>
</tr>
<tr>
<td align="center">DegradeException</td>
<td align="center">降级异常</td>
</tr>
<tr>
<td align="center">AuthorityException</td>
<td align="center">授权规则异常</td>
</tr>
<tr>
<td align="center">SystemBlockException</td>
<td align="center">系统规则异常</td>
</tr>
</tbody></table>
<p>实现：在Consumer服务者进行定义</p>
<pre><code class="java">package cn.itcast.order.sentinel;

@Component
public class SentinelExceptionHandler implements BlockExceptionHandler &#123;
    @Override
    public void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception &#123;
        String msg = &quot;未知异常&quot;;
        int status = 429;

        if (e instanceof FlowException) &#123;
            msg = &quot;请求被限流了&quot;;
        &#125; else if (e instanceof ParamFlowException) &#123;
            msg = &quot;请求被热点参数限流&quot;;
        &#125; else if (e instanceof DegradeException) &#123;
            msg = &quot;请求被降级了&quot;;
        &#125; else if (e instanceof AuthorityException) &#123;
            msg = &quot;没有权限访问&quot;;
            status = 401;
        &#125;

        response.setContentType(&quot;application/json;charset=utf-8&quot;);
        response.setStatus(status);
        response.getWriter().println(&quot;&#123;\&quot;msg\&quot;: &quot; + msg + &quot;, \&quot;status\&quot;: &quot; + status + &quot;&#125;&quot;);
    &#125;
&#125;
</code></pre>
<h2 id="11-4-规则持久化"><a href="#11-4-规则持久化" class="headerlink" title="11.4. 规则持久化"></a>11.4. 规则持久化</h2><h3 id="11-4-1-规则管理模式"><a href="#11-4-1-规则管理模式" class="headerlink" title="11.4.1 规则管理模式"></a>11.4.1 规则管理模式</h3><p>Sentinel的控制台规则管理有三种模式：</p>
<ul>
<li>原始模式：Sentinel的默认模式，将规则保存在内存，重启服务会丢失</li>
<li>pull模式：控制台将配置的规则推送到Sentinel客户端，而客户端会将配置规则保存在本地文件或数据库中。以后会定时去本地文件或数据库中查询，更新本地规则。</li>
<li>push模式【推荐】：控制台将配置规则推送到远程配置中心，例如Nacos。Sentinel客户端监听Nacos，获取配置变更的推送消息，完成本地配置更新。</li>
</ul>
<h3 id="11-4-2-push模式应用"><a href="#11-4-2-push模式应用" class="headerlink" title="11.4.2 push模式应用"></a>11.4.2 push模式应用</h3><p><strong>（1）修改OrderService，让其监听Nacos中的sentinel规则配置。</strong></p>
<p>① 引入依赖</p>
<p>在order-service中引入sentinel监听nacos的依赖：</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt;
    &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>② 配置nacos地址</p>
<p>在order-service中的application.yml文件配置nacos地址及监听的配置信息：</p>
<pre><code class="yaml">spring:
  cloud:
    sentinel:
      datasource:
        flow:
          nacos:
            server-addr: localhost:8848 # nacos地址
            dataId: orderservice-flow-rules
            groupId: SENTINEL_GROUP
            rule-type: flow # 还可以是：degrade、authority、param-flow
</code></pre>
<p><strong>（2）修改sentinel-dashboard源码</strong></p>
<p>① IDEA打开sentinel.zip解压后的项目</p>
<p>② 修改nacos依赖</p>
<p>在sentinel-dashboard源码的pom文件中，nacos的依赖默认的scope是test，只能在测试时使用，这里要去除</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt;
    &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>③ 添加nacos依赖</p>
<p>在sentinel-dashboard的test包下，已经编写了对nacos的支持，我们需要将其拷贝到main下。</p>
<ul>
<li>将maven中<code>src\main\test</code>下的<code>com/alibaba/csp/sentinel/dashboard/rule/nacos</code>包内所有文件移入<code>src\main\java</code>中</li>
</ul>
<p>④ 修改nacos地址</p>
<ul>
<li><p>修改测试代码中的NacosConfig类，修改其中的nacos地址，让其读取application.properties中的配置</p>
<pre><code class="java">package com.alibaba.csp.sentinel.dashboard.rule.nacos;
/**
 * @author Eric Zhao
 * @since 1.4.0
 */
@Configuration
@ConfigurationProperties(prefix = &quot;nacos&quot;)
public class NacosConfig &#123;

    // nacos地址
    private String addr;

    @Bean
    public Converter&lt;List&lt;FlowRuleEntity&gt;, String&gt; flowRuleEntityEncoder() &#123;
        return JSON::toJSONString;
    &#125;

    @Bean
    public Converter&lt;String, List&lt;FlowRuleEntity&gt;&gt; flowRuleEntityDecoder() &#123;
        return s -&gt; JSON.parseArray(s, FlowRuleEntity.class);
    &#125;

    @Bean
    public ConfigService nacosConfigService() throws Exception &#123;
        return ConfigFactory.createConfigService(addr);
    &#125;

    public String getAddr() &#123;
        return addr;
    &#125;

    public void setAddr(String addr) &#123;
        this.addr = addr;
    &#125;
&#125;
</code></pre>
</li>
<li><p>在sentinel-dashboard的application.properties中添加nacos地址配置</p>
<pre><code class="properties">nacos.addr=localhost:8848
</code></pre>
</li>
</ul>
<p>⑤ 配置nacos数据源</p>
<p>修改<code>com.alibaba.csp.sentinel.dashboard.controller.v2</code>包下的<code>FlowControllerV2</code>类</p>
<pre><code class="java">    @Autowired
    @Qualifier(&quot;flowRuleNacosProvider&quot;)
    private DynamicRuleProvider&lt;List&lt;FlowRuleEntity&gt;&gt; ruleProvider;
    @Autowired
    @Qualifier(&quot;flowRuleNacosPublisher&quot;)
    private DynamicRulePublisher&lt;List&lt;FlowRuleEntity&gt;&gt; rulePublisher;
</code></pre>
<p>⑥ 修改前端页面</p>
<p>修改前端页面，添加一个支持nacos的菜单</p>
<p>修改<code>src/main/webapp/resources/app/scripts/directives/sidebar/</code>目录下的<code>sidebar.html</code>文件</p>
<pre><code class="html">&lt;!--将以下注释部分打开并修改--&gt;
&lt;!--&lt;li ui-sref-active=&quot;active&quot; ng-if=&quot;entry.appType==0&quot;&gt;--&gt;
    &lt;!--&lt;a ui-sref=&quot;dashboard.flow(&#123;app: entry.app&#125;)&quot;&gt;--&gt;
    &lt;!--&lt;i class=&quot;glyphicon glyphicon-filter&quot;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;流控规则 V1&lt;/a&gt;--&gt;
&lt;!--&lt;/li&gt;--&gt;

&lt;!--修改后如下--&gt;
&lt;li ui-sref-active=&quot;active&quot; ng-if=&quot;entry.appType==0&quot;&gt;
    &lt;a ui-sref=&quot;dashboard.flow(&#123;app: entry.app&#125;)&quot;&gt;
    &lt;i class=&quot;glyphicon glyphicon-filter&quot;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;流控规则-NACOS&lt;/a&gt;
&lt;/li&gt;
</code></pre>
<p>⑦ 重新编译打包Sentinel-Dashboard模块</p>
<ol>
<li>选择Maven中Toggle ‘Skip Tests’ Mode，去掉测试模块</li>
<li>运行package打包</li>
</ol>
<p>⑧ 启动</p>
<p>启动方式跟官方一样：</p>
<pre><code class="sh">java -jar sentinel-dashboard.jar
</code></pre>
<p>如果要修改nacos地址，需要添加参数：</p>
<pre><code class="sh">java -jar -Dnacos.addr=localhost:8848 sentinel-dashboard.jar
</code></pre>
<h1 id="十二、Seata【分布式事务】"><a href="#十二、Seata【分布式事务】" class="headerlink" title="十二、Seata【分布式事务】"></a>十二、Seata【分布式事务】</h1><p><strong>事务的ACID原则</strong>：</p>
<ul>
<li>原子性：事务中的所有操作，要么全部成功，要么全部失败</li>
<li>一致性：要保证数据库内部完全性约束、声明性约束</li>
<li>隔离性：对同一资源操作的事务不能同时发生</li>
<li>持久性：对数据库做的一切修改将永久保存，不管是否出现故障</li>
</ul>
<p><strong>分布式服务的事务问题</strong></p>
<p>在分布式系统下，一个业务跨越多个服务或数据源，每个服务都是一个分支事务，要保证所有分支事务最终状态一致，这样的事务就是<strong>分布式事务</strong>。</p>
<h2 id="12-1-理论基础"><a href="#12-1-理论基础" class="headerlink" title="12.1. 理论基础"></a>12.1. 理论基础</h2><h3 id="12-1-1-CAP定理"><a href="#12-1-1-CAP定理" class="headerlink" title="12.1.1 CAP定理"></a>12.1.1 CAP定理</h3><p>1998年，加州大学的计算机科学家 Eric Brewer 提出，分布式系统有三个指标：</p>
<ul>
<li>Consistency(一致性)：用户访问分布式系统中的任意节点，得到的数据必须一致。</li>
<li>Availability (可用性)：用户访问集群中的任意健康节点，必须能得到响应，而不是超时或拒绝。</li>
<li>Partition tolerance (分区容错性)<ul>
<li>Partition（分区）：因为网络故障或其他原因导致分布式系统中的部分节点与其他节点失去连接，形成独立分区。</li>
<li>Tolerance（容错）：在集群出现分区时，整个系统也要持续对外提供服务。</li>
</ul>
</li>
</ul>
<p>Eric Brewer 说，分布式系统无法同时满足这三个指标。</p>
<p>这个结论就叫做 CAP 定理。</p>
<p><strong>结论</strong></p>
<ul>
<li>分布式系统节点通过网络连接，一定会出现分区问题（P）</li>
<li>当分区出现时，系统的一致性（C）和可用性（A）就无法同时满足</li>
<li>ES集群出现分区时，故障节点会被剔除集群，数据分片会重新分配到其他节点，保证数据一致。因此是低可用性，高一致性，属于CP</li>
</ul>
<h3 id="12-1-2-BASE理论"><a href="#12-1-2-BASE理论" class="headerlink" title="12.1.2 BASE理论"></a>12.1.2 BASE理论</h3><p>BASE理论是对CAP的一种解决思路，包含三个思想：</p>
<ul>
<li>Basically Available (基本可用)：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。</li>
<li>Soft state (软状态)：在一定时间内，允许出现中间状态，比如临时的不一致状态。</li>
<li>Eventually Consistent(最终一致性)：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。</li>
</ul>
<p>而分布式事务最大的问题是各个子事务的一致性问题，因此可以借鉴CAP定理和BASE理论：</p>
<ul>
<li>AP模式：各子事务分别执行和提交，允许出现结果不一致，然后采用弥补措施恢复数据即可，实现<strong>最终一致</strong>。</li>
<li>CP模式：各个子事务执行后互相等待，同时提交，同时回滚，达成<strong>强一致</strong>。但事务等待过程中，处于弱可用状态。</li>
</ul>
<p>分布式事务模型：</p>
<p>解决分布式事务，各个子系统之间必须能感知到彼此的事务状态，才能保证状态一致，因此需要一个<strong>事务协调者</strong>来协调每一个事务的参与者(子系统事务)。 这里的子系统事务，称为<strong>分支事务</strong>；有关联的各个分支事务在一起称为<strong>全局事务</strong></p>
<h2 id="12-2-Seata搭建"><a href="#12-2-Seata搭建" class="headerlink" title="12.2. Seata搭建"></a>12.2. Seata搭建</h2><p>Seata是 2019年1月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案。致力于提供高性能和简单易用的分布式事务服务，为用户打造一站式的分布式解决方案。</p>
<p>官网地址:<a target="_blank" rel="noopener" href="http://seata.io/%EF%BC%8C%E5%85%B6%E4%B8%AD%E7%9A%84%E6%96%87%E6%A1%A3%E3%80%81%E6%92%AD%E5%AE%A2%E4%B8%AD%E6%8F%90%E4%BE%9B%E4%BA%86%E5%A4%A7%E9%87%8F%E7%9A%84%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%E3%80%81%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%82">http://seata.io/，其中的文档、播客中提供了大量的使用说明、源码分析。</a></p>
<p><strong>seata架构</strong> Seata事务管理中有三个重要的角色：</p>
<ul>
<li>TC(Transaction Coordinator) - 事务协调者：维护全局和分支事务的状态，协调全局事务提交或回滚。</li>
<li>TM(Transaction Manaer) - 事务管理器：定义全局事务的范围、开始全局事务、提交或回滚全局事务。</li>
<li>RM(Resource Manager) - 资源管理器：管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。</li>
</ul>
<p>Seata提供了<strong>四种</strong>不同的<strong>分布式事务解决方案</strong></p>
<ul>
<li>XA模式：强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入。</li>
<li>TCC模式：最终一致的分阶段事务模式，有业务侵入。</li>
<li>AT模式：最终一致的分阶段事务模式，无业务侵入，也是Seata的默认模式。</li>
<li>SAGA模式：长事务模式，有业务侵入。</li>
</ul>
<h3 id="12-2-1-部署TC服务"><a href="#12-2-1-部署TC服务" class="headerlink" title="12.2.1 部署TC服务"></a>12.2.1 部署TC服务</h3><p>① 下载seata-server包</p>
<p>官方地址：<a target="_blank" rel="noopener" href="http://seata.io/zh-cn/blog/download.html">http</a><a target="_blank" rel="noopener" href="http://seata.io/zh-cn/blog/download.html">:&#x2F;&#x2F;seata.io&#x2F;zh-cn&#x2F;blog&#x2F;download</a><a target="_blank" rel="noopener" href="http://seata.io/zh-cn/blog/download.html">.</a><a target="_blank" rel="noopener" href="http://seata.io/zh-cn/blog/download.html">html</a></p>
<p>② 解压</p>
<p>在非中文目录下解压，目录结构：</p>
<ul>
<li>bin：运行脚本</li>
<li>conf：配置文件</li>
<li>lib：依赖库</li>
</ul>
<p>③ 修改配置</p>
<p>修改conf目录下的registry.conf</p>
<pre><code class="properties">registry &#123;
  # tc服务的注册中心类，这里选择nacos，也可以是eureka、zookeeper等
  type = &quot;nacos&quot;

  nacos &#123;
    # seata tc 服务注册到 nacos的服务名称，可以自定义
    application = &quot;seata-tc-server&quot;
    serverAddr = &quot;127.0.0.1:8848&quot;
    group = &quot;DEFAULT_GROUP&quot;
    namespace = &quot;&quot;
    cluster = &quot;SH&quot;
    username = &quot;nacos&quot;
    password = &quot;nacos&quot;
  &#125;
&#125;

config &#123;
  # 读取tc服务端的配置文件的方式，这里是从nacos配置中心读取，这样如果tc是集群，可以共享配置
  type = &quot;nacos&quot;
  # 配置nacos地址等信息
  nacos &#123;
    serverAddr = &quot;127.0.0.1:8848&quot;
    namespace = &quot;&quot;
    group = &quot;SEATA_GROUP&quot;
    username = &quot;nacos&quot;
    password = &quot;nacos&quot;
    dataId = &quot;seataServer.properties&quot;
  &#125;
&#125;
</code></pre>
<p>④ 在nacos中添加配置</p>
<ul>
<li><p>url：<a target="_blank" rel="noopener" href="http://localhost:8848/nacos">http://localhost:8848/nacos</a></p>
</li>
<li><p>Data ID：seataServer.properties</p>
</li>
<li><p>Group：DEFAULT_GROUP</p>
</li>
<li><p>配置格式：Properties</p>
</li>
<li><p>配置内容：</p>
<pre><code class="properties"># 数据存储方式，db代表数据库
store.mode=db
store.db.datasource=druid
store.db.dbType=mysql
store.db.driverClassName=com.mysql.jdbc.Driver
store.db.url=jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;rewriteBatchedStatements=true
store.db.user=root
store.db.password=root
store.db.minConn=5
store.db.maxConn=30
store.db.globalTable=global_table
store.db.branchTable=branch_table
store.db.queryLimit=100
store.db.lockTable=lock_table
store.db.maxWait=5000
# 事务、日志等配置
server.recovery.committingRetryPeriod=1000
server.recovery.asynCommittingRetryPeriod=1000
server.recovery.rollbackingRetryPeriod=1000
server.recovery.timeoutRetryPeriod=1000
server.maxCommitRetryTimeout=-1
server.maxRollbackRetryTimeout=-1
server.rollbackRetryTimeoutUnlockEnable=false
server.undo.logSaveDays=7
server.undo.logDeletePeriod=86400000

# 客户端与服务端传输方式
transport.serialization=seata
transport.compressor=none
# 关闭metrics功能，提高性能
metrics.enabled=false
metrics.registryType=compact
metrics.exporterList=prometheus
metrics.exporterPrometheusPort=9898
</code></pre>
</li>
</ul>
<p>⑤ 创建数据库表</p>
<p>特别注意：tc服务在管理分布式事务时，需要记录事务相关数据到数据库中，你需要提前创建好这些表。</p>
<p>新建一个名为seata的数据库</p>
<pre><code class="mysql">SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- 分支事务表
-- ----------------------------
DROP TABLE IF EXISTS `branch_table`;
CREATE TABLE `branch_table`  (
  `branch_id` bigint(20) NOT NULL,
  `xid` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `transaction_id` bigint(20) NULL DEFAULT NULL,
  `resource_group_id` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `resource_id` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `branch_type` varchar(8) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `status` tinyint(4) NULL DEFAULT NULL,
  `client_id` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `application_data` varchar(2000) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `gmt_create` datetime(6) NULL DEFAULT NULL,
  `gmt_modified` datetime(6) NULL DEFAULT NULL,
  PRIMARY KEY (`branch_id`) USING BTREE,
  INDEX `idx_xid`(`xid`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- 全局事务表
-- ----------------------------
DROP TABLE IF EXISTS `global_table`;
CREATE TABLE `global_table`  (
  `xid` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `transaction_id` bigint(20) NULL DEFAULT NULL,
  `status` tinyint(4) NOT NULL,
  `application_id` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `transaction_service_group` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `transaction_name` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `timeout` int(11) NULL DEFAULT NULL,
  `begin_time` bigint(20) NULL DEFAULT NULL,
  `application_data` varchar(2000) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `gmt_create` datetime NULL DEFAULT NULL,
  `gmt_modified` datetime NULL DEFAULT NULL,
  PRIMARY KEY (`xid`) USING BTREE,
  INDEX `idx_gmt_modified_status`(`gmt_modified`, `status`) USING BTREE,
  INDEX `idx_transaction_id`(`transaction_id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

SET FOREIGN_KEY_CHECKS = 1;
</code></pre>
<p>⑥ 启动TC服务</p>
<p>进入bin目录，运行其中的seata-server.bat即可</p>
<p>打开浏览器，访问nacos地址：<a target="_blank" rel="noopener" href="http://localhost:8848/">http://localhost:8848</a>，然后进入服务列表页面，可以看到seata-tc-server的信息。</p>
<h3 id="12-2-2-集成seata"><a href="#12-2-2-集成seata" class="headerlink" title="12.2.2 集成seata"></a>12.2.2 集成seata</h3><p>① 在微服务中引入seata依赖：</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt;
    &lt;exclusions&gt;
        &lt;!--版本较低，1.3.0，因此排除--&gt;
        &lt;exclusion&gt;
            &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt;
            &lt;groupId&gt;io.seata&lt;/groupId&gt;
        &lt;/exclusion&gt;
    &lt;/exclusions&gt;
&lt;/dependency&gt;
&lt;!--seata starter 采用1.4.2版本--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;io.seata&lt;/groupId&gt;
    &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;$&#123;seata.version&#125;&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>② 修改yml配置文件</p>
<pre><code class="yml">seata:
  registry: # TC服务注册中心的配置，微服务根据这些信息去注册中心获取tc服务地址
    # 参考tc服务自己的registry.conf中的配置
    # 包括：地址、namespace、group、application-name、cluster
    type: nacos
    nacos:
      server-addr: 127.0.0.1:8848
      namespace: &quot;&quot;
      group: DEFAULT_GROUP
      application: seata-tc-server # tc服务在nacos中的服务名称
      username: nacos
      password: nacos
  tx-service-group: seata-demo # 事务组，根据这个获取tc服务的cluster名称
  service:
    vgroup-mapping: # 事务组与TC服务cluster的映射关系
      seata-demo: SH
</code></pre>
<p><strong>总结</strong></p>
<p>nacos服务名称组成包括：</p>
<ul>
<li>namespace</li>
<li>group</li>
<li>serviceName</li>
<li>cluster</li>
</ul>
<p>seata客户端获取tc的cluster名称方式</p>
<ul>
<li>以tx-group-service的值为key到vgroupMapping中查找</li>
</ul>
<h2 id="12-3-Seata解决方案"><a href="#12-3-Seata解决方案" class="headerlink" title="12.3. Seata解决方案"></a>12.3. Seata解决方案</h2><table>
<thead>
<tr>
<th align="center"></th>
<th align="center">XA</th>
<th align="center">AT</th>
<th align="center">TCC</th>
<th align="center">SAGA</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>一致性</strong></td>
<td align="center">强一致</td>
<td align="center">弱一致</td>
<td align="center">弱一致</td>
<td align="center">最终一致</td>
</tr>
<tr>
<td align="center"><strong>隔离性</strong></td>
<td align="center">完全隔离</td>
<td align="center">基于全局锁隔离</td>
<td align="center">基于资源预留隔离</td>
<td align="center">无隔离</td>
</tr>
<tr>
<td align="center"><strong>代码侵入</strong></td>
<td align="center">无</td>
<td align="center">无</td>
<td align="center">有，需要编写三个接口</td>
<td align="center">有，需要编写状态机和补偿业务</td>
</tr>
<tr>
<td align="center"><strong>性能</strong></td>
<td align="center">差</td>
<td align="center">好</td>
<td align="center">非常好</td>
<td align="center">非常好</td>
</tr>
<tr>
<td align="center"><strong>场景</strong></td>
<td align="center">对一致性、隔离性有高要求的业务</td>
<td align="center">基于关系型数据库的大多数分布式事务场景都可以</td>
<td align="center">对性能要求较高的事务；有非关系型数据库要参与的事务</td>
<td align="center">业务流程长、业务流程多；参与者包含其他公司或遗留系统服务，无法提供TCC模式要求的三个接口</td>
</tr>
</tbody></table>
<h3 id="12-3-1-XA模式"><a href="#12-3-1-XA模式" class="headerlink" title="12.3.1 XA模式"></a>12.3.1 XA模式</h3><p><strong>原理</strong>：XA规范是X&#x2F;Open 组织定义的分布式事务处理 (DTP，Distributed Transaction Processing)标准，XA 规范描述了全局的TM与局部的RM之间的接口，几平所有主流的数据库都对XA规范提供了支持。</p>
<h4 id="①-XA模式共分为两阶段运行"><a href="#①-XA模式共分为两阶段运行" class="headerlink" title="① XA模式共分为两阶段运行"></a>① XA模式共分为两阶段运行</h4><ul>
<li>第一阶段：事务协调者与RM进行交互<ul>
<li>事务协调者对RM进行prepare准备</li>
<li>RM返回给事务协调者ready就绪或fail失败</li>
</ul>
</li>
<li>第二阶段：事务协调者再次与RM交互<ul>
<li>提交或回滚事务</li>
</ul>
</li>
</ul>
<h4 id="②-seata的XA模式做了一些调整"><a href="#②-seata的XA模式做了一些调整" class="headerlink" title="② seata的XA模式做了一些调整"></a>② seata的XA模式做了一些调整</h4><ul>
<li>RM一阶段的工作：<ol>
<li>注册分支事务到TC</li>
<li>执行分支业务SQL但不提交</li>
<li>报告执行状态到TC</li>
</ol>
</li>
<li>TC二阶段的工作【TC检测各分支事务执行状态】：<ul>
<li>都成功，通知所有RM提交事务</li>
<li>有失败，通知所有RM回滚事务</li>
</ul>
</li>
<li>RM二阶段的工作：<ul>
<li>接收TC指令，提交或回滚事务</li>
</ul>
</li>
</ul>
<h4 id="③-XA模式优缺点"><a href="#③-XA模式优缺点" class="headerlink" title="③ XA模式优缺点"></a>③ XA模式优缺点</h4><p>XA模式的优点：</p>
<ul>
<li>事务的强一致性，满足ACID原则。</li>
<li>常用数据库都支持，实现简单，并且没有代码侵入。</li>
</ul>
<p>XA模式的缺点：</p>
<ul>
<li>因为一阶段需要锁定数据库资源，等待二阶段结束才释放，性能较差。</li>
<li>依赖关系型数据库实现事务。</li>
</ul>
<h4 id="④-实现XA模式"><a href="#④-实现XA模式" class="headerlink" title="④ 实现XA模式"></a>④ 实现XA模式</h4><ol>
<li><p>修改yml配置文件（每个参与事务的微服务），开启XA模式：</p>
<pre><code class="yml">seata:
  data-source-proxy-mode: XA # 开启数据源代理的XA模式
</code></pre>
</li>
<li><p>给发起全局事务的入口方法添加@GlobalTransactional注解</p>
<pre><code class="java">@Slf4j
@Service
public class OrderServiceImpl implements OrderService &#123;

    private final AccountClient accountClient;
    private final StorageClient storageClient;
    private final OrderMapper orderMapper;

    public OrderServiceImpl(AccountClient accountClient, StorageClient storageClient, OrderMapper orderMapper) &#123;
        this.accountClient = accountClient;
        this.storageClient = storageClient;
        this.orderMapper = orderMapper;
    &#125;

    @Override
    // 开启XA模式事务
    @GlobalTransactional
    public Long create(Order order) &#123;
        // 创建订单
        orderMapper.insert(order);
        try &#123;
            // 扣用户余额
            accountClient.deduct(order.getUserId(), order.getMoney());
            // 扣库存
            storageClient.deduct(order.getCommodityCode(), order.getCount());

        &#125; catch (FeignException e) &#123;
            log.error(&quot;下单失败，原因:&#123;&#125;&quot;, e.contentUTF8(), e);
            throw new RuntimeException(e.contentUTF8(), e);
        &#125;
        return order.getId();
    &#125;
&#125;
</code></pre>
</li>
</ol>
<h3 id="12-3-2-AT模式"><a href="#12-3-2-AT模式" class="headerlink" title="12.3.2 AT模式"></a>12.3.2 AT模式</h3><p><strong>原理</strong>：AT模式同样是分阶段提交的事务模型，不过缺弥补了XA模型中资源锁定周期过长的缺陷。</p>
<p>阶段一RM的工作：</p>
<ul>
<li>注册分支事务</li>
<li>记录undo-log (数据快照)</li>
<li>执行业务sql并提交</li>
<li>报告事务状态</li>
</ul>
<p>阶段二提交时RM的工作：</p>
<ul>
<li>删除undo-log即可</li>
</ul>
<p>阶段二回滚时RM的工作：</p>
<ul>
<li>根据undo-log恢复数据到更新前</li>
</ul>
<h4 id="①-简述AT模式与XA模式最大的区别"><a href="#①-简述AT模式与XA模式最大的区别" class="headerlink" title="① 简述AT模式与XA模式最大的区别"></a>① 简述AT模式与XA模式最大的区别</h4><ul>
<li>XA模式一阶段不提交事务，锁定资源；AT模式一阶段直接提交，不锁定资源。</li>
<li>XA模式依赖数据库机制实现回滚；AT模式利用数据快照实现数据回滚。</li>
<li>XA模式强一致；AT模式最终一致。</li>
</ul>
<h4 id="②-AT模式脏写问题"><a href="#②-AT模式脏写问题" class="headerlink" title="② AT模式脏写问题"></a>② AT模式脏写问题</h4><p>多个事务执行时触发的快照问题，无法回滚到正确的快照。</p>
<p>AT模式的写隔离：使用全局锁解决脏写问题</p>
<ul>
<li>全局锁：由TC记录当前正在操作某行数据的事务，该事务持有全局锁，具备执行权。</li>
</ul>
<h4 id="③-AT模式优缺点"><a href="#③-AT模式优缺点" class="headerlink" title="③ AT模式优缺点"></a>③ AT模式优缺点</h4><p>AT模式的优点：</p>
<ul>
<li>一阶段完成直接提交事务，释放数据库资源，性能比较好利用全局锁实现读写隔离。</li>
<li>没有代码侵入，框架自动完成回滚和提交。</li>
</ul>
<p>AT模式的缺点：</p>
<ul>
<li>两阶段之间属于软状态，属于最终一致。</li>
<li>框架的快照功能会影响性能，但比XA模式要好很多。</li>
</ul>
<h4 id="④-实现AT模式"><a href="#④-实现AT模式" class="headerlink" title="④ 实现AT模式"></a>④ 实现AT模式</h4><p>AT模式中的快照生成、回滚动作都是由框架自动完成，没有任何代码侵入</p>
<ol>
<li><p>导入sql文件</p>
<ul>
<li><p>lock_table导入到TC服务关联的数据库</p>
<pre><code class="mysql">-- ----------------------------
-- Table structure for lock_table
-- ----------------------------
DROP TABLE IF EXISTS `lock_table`;
CREATE TABLE `lock_table`  (
  `row_key` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `xid` varchar(96) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `transaction_id` bigint(20) NULL DEFAULT NULL,
  `branch_id` bigint(20) NOT NULL,
  `resource_id` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `table_name` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `pk` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `gmt_create` datetime NULL DEFAULT NULL,
  `gmt_modified` datetime NULL DEFAULT NULL,
  PRIMARY KEY (`row_key`) USING BTREE,
  INDEX `idx_branch_id`(`branch_id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;
</code></pre>
</li>
<li><p>undo_log表导入到微服务关联的数据库</p>
<pre><code class="mysql">-- ----------------------------
-- Table structure for undo_log
-- ----------------------------
DROP TABLE IF EXISTS `undo_log`;
CREATE TABLE `undo_log`  (
  `branch_id` bigint(20) NOT NULL COMMENT &#39;branch transaction id&#39;,
  `xid` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT &#39;global transaction id&#39;,
  `context` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT &#39;undo_log context,such as serialization&#39;,
  `rollback_info` longblob NOT NULL COMMENT &#39;rollback info&#39;,
  `log_status` int(11) NOT NULL COMMENT &#39;0:normal status,1:defense status&#39;,
  `log_created` datetime(6) NOT NULL COMMENT &#39;create datetime&#39;,
  `log_modified` datetime(6) NOT NULL COMMENT &#39;modify datetime&#39;,
  UNIQUE INDEX `ux_undo_log`(`xid`, `branch_id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = &#39;AT transaction mode undo table&#39; ROW_FORMAT = Compact;

-- ----------------------------
-- Records of undo_log
-- ----------------------------
</code></pre>
</li>
</ul>
</li>
<li><p>修改yml配置文件，将事务模式修改为AT模式</p>
<pre><code class="yml">seata:
  data-source-proxy-mode: AT # 开启数据源代理的AT模式
</code></pre>
</li>
</ol>
<h3 id="12-3-3-TCC模式"><a href="#12-3-3-TCC模式" class="headerlink" title="12.3.3 TCC模式"></a>12.3.3 TCC模式</h3><p>TCC模式与AT模式非常相似，每阶段都是独立事务，不同的是TCC通过人工编码来实现数据恢复。需要实现三个方法：</p>
<ul>
<li>Try：资源的检测和预留。</li>
<li>Confirm：完成资源操作业务;要求Try 成功 Confirm一定要能成功。</li>
<li>Cancel：预留资源释放，可以理解为try的反向操作。</li>
</ul>
<h4 id="①-作用及其优缺点"><a href="#①-作用及其优缺点" class="headerlink" title="① 作用及其优缺点"></a>① 作用及其优缺点</h4><p>TCC模式的每个阶段的作用</p>
<ul>
<li>Try：资源检查和预留</li>
<li>Confirm：业务执行和提交</li>
<li>Cancel：预留资源的释放</li>
</ul>
<p>TCC的优点</p>
<ul>
<li>一阶段完成直接提交事务，释放数据库资源，性能好</li>
<li>相比AT模型，无需生成快照，无需使用全局锁，性能最强</li>
<li>不依赖数据库事务，而是依赖补偿操作，可以用于非事务型数据库</li>
</ul>
<p>TCC的缺点</p>
<ul>
<li>有代码侵入，需要人为编写try、Confirm和Cancel接口，太麻烦</li>
<li>软状态，事务是最终一致</li>
<li>需要考虑Confirm和Cancel的失败情况，做好幂等处理</li>
</ul>
<h4 id="②-应用案例"><a href="#②-应用案例" class="headerlink" title="② 应用案例"></a>② 应用案例</h4><p><strong>需求</strong>：改造account-service服务，利用TCC实现分布式事务</p>
<ul>
<li>修改account-service，编写try、confirm、cancel逻辑</li>
<li>try业务：添加冻结金额，扣减可用金额</li>
<li>confirm业务：删除冻结金额</li>
<li>cancel业务：删除冻结金额，恢复可用金额</li>
<li>保证confirm、cancel接口的<strong>幂等性</strong></li>
<li>允许<strong>空回滚</strong></li>
<li>拒绝<strong>业务悬挂</strong></li>
</ul>
<p><strong>业务分析</strong>：为了实现空回滚、防止业务悬挂，以及幂等性要求。我们必须在数据库记录冻结金额的同时，记录当前事务id和执行状态，为此设计了一张表，将此表插入微服务数据库中：</p>
<pre><code class="mysql">-- ----------------------------
-- Table structure for account_freeze_tbl
-- ----------------------------
DROP TABLE IF EXISTS `account_freeze_tbl`;
CREATE TABLE `account_freeze_tbl`  (
  `xid` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `user_id` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `freeze_money` int(11) UNSIGNED NULL DEFAULT 0,
  `state` int(1) NULL DEFAULT NULL COMMENT &#39;事务状态，0:try，1:confirm，2:cancel&#39;,
  PRIMARY KEY (`xid`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = COMPACT;

-- ----------------------------
-- Records of account_freeze_tbl
-- ----------------------------
</code></pre>
<ul>
<li>Try业务<ul>
<li>记录冻结金额和事务状态到account_freeze表</li>
<li>扣减account表可用金额</li>
</ul>
</li>
<li>Confirm业务<ul>
<li>根据xid删除account_freeze表的冻结记录</li>
</ul>
</li>
<li>Cancel业务<ul>
<li>修改account_freeze表冻结金额为0，state为2</li>
<li>修改account表，恢复可用金额</li>
</ul>
</li>
<li>如何判断是否空回滚<ul>
<li>cancel业务中，根据xid查询account_freeze如果为null则说明try还没做，需要空回滚</li>
</ul>
</li>
<li>如何避免业务悬挂<ul>
<li>try业务中，根据xid查询account_freeze ，如果已经存在则证明Cancel已经执行，拒绝执行try业务</li>
</ul>
</li>
</ul>
<p><strong>实现代码</strong>：</p>
<ol>
<li><p><code>cn.itcast.account.service.AccountTCCService</code></p>
<pre><code class="java">@LocalTCC
public interface AccountTCCService &#123;
    
    @TwoPhaseBusinessAction(name = &quot;deduct&quot;, commitMethod = &quot;confirm&quot;, rollbackMethod = &quot;cancel&quot;)
    void deduct(@BusinessActionContextParameter(paramName = &quot;userId&quot;) String userId,
                @BusinessActionContextParameter(paramName = &quot;money&quot;) int money);

    boolean confirm(BusinessActionContext ctx);

    boolean cancel(BusinessActionContext ctx);
&#125;
</code></pre>
</li>
<li><p><code>cn.itcast.account.service.impl.AccountTCCServiceImpl</code></p>
<pre><code class="java">/**
 * @version v1.0
 * @auther Bamboo
 * @create 2023/8/7 8:29
 */

@Slf4j
@Service
public class AccountTCCServiceImpl implements AccountTCCService &#123;

    @Autowired
    private AccountMapper accountMapper;

    @Autowired
    private AccountFreezeMapper freezeMapper;

    @Override
    public void deduct(String userId, int money) &#123;
        // 0.获取事务id
        String xid = RootContext.getXID();
        // 1.业务悬挂判断：判断freeze中是否由冻结记录，如果有，一定是CANCEL执行过，我要拒绝业务
        AccountFreeze oldFreeze = freezeMapper.selectById(xid);
        if (oldFreeze != null) &#123;
            // CANCEL执行过，拒绝业务
            return;
        &#125;
        // 2.扣减可用金额
        accountMapper.deduct(userId, money);
        // 3.记录冻结金额，事务状态
        AccountFreeze freeze = new AccountFreeze();
        freeze.setUserId(userId);
        freeze.setFreezeMoney(money);
        freeze.setState(AccountFreeze.State.TRY);
        freeze.setXid(xid);
        freezeMapper.insert(freeze);
    &#125;

    @Override
    public boolean confirm(BusinessActionContext ctx) &#123;
        // 1.获取事务id
        String xid = ctx.getXid();
        // 2.根据id删除冻结记录
        int count = freezeMapper.deleteById(xid);
        return count == 1;
    &#125;

    @Override
    public boolean cancel(BusinessActionContext ctx) &#123;
        // 0.查询冻结金额
        String xid = ctx.getXid();
        String userId = ctx.getActionContext(&quot;userId&quot;).toString();
        AccountFreeze freeze = freezeMapper.selectById(xid);
        // 2.空回滚判断，判断freeze是否为null，为null证明try没执行，需要空回滚
        if (freeze == null) &#123;
            // 证明try没执行，需要空回滚
            freeze = new AccountFreeze();
            freeze.setUserId(userId);
            freeze.setFreezeMoney(0);
            freeze.setState(AccountFreeze.State.CANCEL);
            freeze.setXid(xid);
            freezeMapper.insert(freeze);
        &#125;
        // 3. 幂等判断处理
        if (freeze.getState() == AccountFreeze.State.CANCEL) &#123;
            // 已经处理过一次CANCEL了，无需重复处理
            return true;
        &#125;
        // 4.恢复可用余额
        accountMapper.refund(freeze.getUserId(), freeze.getFreezeMoney());
        // 5.将冻结金额清零，状态改为CANCEL
        freeze.setFreezeMoney(0);
        freeze.setFreezeMoney(AccountFreeze.State.CANCEL);
        int count = freezeMapper.updateById(freeze);
        return count == 1;
    &#125;
&#125;
</code></pre>
</li>
<li><p>替换controller层注入</p>
<pre><code class="java">@RestController
@RequestMapping(&quot;account&quot;)
public class AccountController &#123;

    @Autowired
    private AccountTCCService accountService;

    @PutMapping(&quot;/&#123;userId&#125;/&#123;money&#125;&quot;)
    public ResponseEntity&lt;Void&gt; deduct(@PathVariable(&quot;userId&quot;) String userId, @PathVariable(&quot;money&quot;) Integer money)&#123;
        accountService.deduct(userId, money);
        return ResponseEntity.noContent().build();
    &#125;
&#125;
</code></pre>
</li>
<li><p>依赖mapper</p>
<ul>
<li><p>AccountFreezeMapper.java</p>
<pre><code class="java">@Repository
public interface AccountFreezeMapper extends BaseMapper&lt;AccountFreeze&gt; &#123;
&#125;
</code></pre>
</li>
<li><p>AccountMapper.java</p>
<pre><code class="java">@Repository
public interface AccountMapper extends BaseMapper&lt;Account&gt; &#123;

    @Update(&quot;update account_tbl set money = money - $&#123;money&#125; where user_id = #&#123;userId&#125;&quot;)
    int deduct(@Param(&quot;userId&quot;) String userId, @Param(&quot;money&quot;) int money);

    @Update(&quot;update account_tbl set money = money + $&#123;money&#125; where user_id = #&#123;userId&#125;&quot;)
    int refund(@Param(&quot;userId&quot;) String userId, @Param(&quot;money&quot;) int money);
&#125;
</code></pre>
</li>
</ul>
</li>
<li><p>依赖pojo</p>
<pre><code class="java">@Data
@TableName(&quot;account_freeze_tbl&quot;)
public class AccountFreeze &#123;
    @TableId(type = IdType.INPUT)
    private String xid;
    private String userId;
    private Integer freezeMoney;
    private Integer state;

    public static abstract class State &#123;
        public final static int TRY = 0;
        public final static int CONFIRM = 1;
        public final static int CANCEL = 2;
    &#125;
&#125;
</code></pre>
</li>
</ol>
<h4 id="③-TCC的空回滚和业务悬挂"><a href="#③-TCC的空回滚和业务悬挂" class="headerlink" title="③ TCC的空回滚和业务悬挂"></a>③ TCC的空回滚和业务悬挂</h4><p>当某分支事务的try阶段阻塞时，可能导致全局事务超时而触发二阶段的cancel操作。在未执行try操作时先执行了cancel操作，这时cancel不能做回滚，就是<strong>空回滚</strong>。</p>
<p>对于已经空回滚的业务，如果以后继续执行try，就永远不可能confirm或cancel，这就是<strong>业务悬挂</strong>。应当阻止执行空回滚后的try操作，避免悬挂。</p>
<h4 id="④-声明TCC接口"><a href="#④-声明TCC接口" class="headerlink" title="④ 声明TCC接口"></a>④ 声明TCC接口</h4><p>TCC的Try、Confirm、Cancel方法都需要在接口中基于注解来声明，语法如下：</p>
<pre><code class="java">@LocalTCC
public interface TCCService &#123;
    /**
     * Try逻辑，@TwoPhaseBusinessAction中的name属性要和当前方法名一致，用于指定Try逻辑对应的方法
     */
    @TwoPhaseBusinessAction(name = &quot;prepare&quot;, commitMethod = &quot;confirm&quot;, rollbackMethod = &quot;cancel&quot;)
    void prepare(@BusinessActionContextParameter(paramName = &quot;param&quot;) String param);
    /**
     * 二阶段confirm确认方法，可以另外命名，弹药保证与commitMethod一致
     * @param ctx 上下文，可以传递try方法的参数
     * @return boolean 执行是否成功
     */
    boolean confirm(BusinessActionContext ctx);
    /**
     * 二阶段回滚方法，可以另外命名，弹药保证与rollbackMethod一致
     * @param ctx 上下文，可以传递try方法的参数
     * @return boolean 执行是否成功
     */
    boolean cancel(BusinessActionContext ctx);
&#125;
</code></pre>
<h3 id="3-4-SAGA模式"><a href="#3-4-SAGA模式" class="headerlink" title="3.4 SAGA模式"></a>3.4 SAGA模式</h3><p>Saga模式是SEATA提供的长事务解决方案。也分为两个阶段：</p>
<ul>
<li>一阶段：直接提交本地事务</li>
<li>二阶段：成功则什么都不做；失败则通过编写补偿业务来回滚</li>
</ul>
<p>优点：</p>
<ul>
<li>事务参与者可以基于事件驱动实现异步调用，吞吐高</li>
<li>一阶段直接提交事务，无锁，性能好</li>
<li>不用编写TCC中的三个阶段，实现简单</li>
</ul>
<p>缺点：</p>
<ul>
<li>软状态持续时间不确定，时效性差</li>
<li>没有锁，没有事务隔离，会有脏写</li>
</ul>
<h2 id="12-4-TC服务的高可用和异地容灾"><a href="#12-4-TC服务的高可用和异地容灾" class="headerlink" title="12.4. TC服务的高可用和异地容灾"></a>12.4. TC服务的高可用和异地容灾</h2><h3 id="12-4-1-模拟异地容灾的TC集群"><a href="#12-4-1-模拟异地容灾的TC集群" class="headerlink" title="12.4.1 模拟异地容灾的TC集群"></a>12.4.1 模拟异地容灾的TC集群</h3><p>计划启动两台seata的tc服务节点：</p>
<table>
<thead>
<tr>
<th>节点名称</th>
<th>ip地址</th>
<th>端口号</th>
<th>集群名称</th>
</tr>
</thead>
<tbody><tr>
<td>seata</td>
<td>127.0.0.1</td>
<td>8091</td>
<td>SH</td>
</tr>
<tr>
<td>seata2</td>
<td>127.0.0.1</td>
<td>8092</td>
<td>HZ</td>
</tr>
</tbody></table>
<p>之前我们已经启动了一台seata服务，端口是8091，集群名为SH。</p>
<p>现在，将seata目录复制一份，起名为seata2</p>
<p>修改seata2&#x2F;conf&#x2F;registry.conf内容如下：</p>
<pre><code class="nginx">registry &#123;
  # tc服务的注册中心类，这里选择nacos，也可以是eureka、zookeeper等
  type = &quot;nacos&quot;

  nacos &#123;
    # seata tc 服务注册到 nacos的服务名称，可以自定义
    application = &quot;seata-tc-server&quot;
    serverAddr = &quot;127.0.0.1:8848&quot;
    group = &quot;DEFAULT_GROUP&quot;
    namespace = &quot;&quot;
    cluster = &quot;HZ&quot;
    username = &quot;nacos&quot;
    password = &quot;nacos&quot;
  &#125;
&#125;

config &#123;
  # 读取tc服务端的配置文件的方式，这里是从nacos配置中心读取，这样如果tc是集群，可以共享配置
  type = &quot;nacos&quot;
  # 配置nacos地址等信息
  nacos &#123;
    serverAddr = &quot;127.0.0.1:8848&quot;
    namespace = &quot;&quot;
    group = &quot;SEATA_GROUP&quot;
    username = &quot;nacos&quot;
    password = &quot;nacos&quot;
    dataId = &quot;seataServer.properties&quot;
  &#125;
&#125;
</code></pre>
<p>进入seata2&#x2F;bin目录，然后运行命令：</p>
<pre><code class="powershell">seata-server.bat -p 8092
</code></pre>
<h3 id="12-4-2-将事务组映射配置到nacos"><a href="#12-4-2-将事务组映射配置到nacos" class="headerlink" title="12.4.2 将事务组映射配置到nacos"></a>12.4.2 将事务组映射配置到nacos</h3><p>接下来，我们需要将tx-service-group与cluster的映射关系都配置到nacos配置中心。</p>
<p>新建一个配置：</p>
<ul>
<li><p>Data ID：client.properties</p>
</li>
<li><p>Group：SEATA_GROUP</p>
</li>
<li><p>配置格式：properties</p>
</li>
<li><p>配置内容：</p>
<pre><code class="properties"># 事务组映射关系
service.vgroupMapping.seata-demo=SH

service.enableDegrade=false
service.disableGlobalTransaction=false
# 与TC服务的通信配置
transport.type=TCP
transport.server=NIO
transport.heartbeat=true
transport.enableClientBatchSendRequest=false
transport.threadFactory.bossThreadPrefix=NettyBoss
transport.threadFactory.workerThreadPrefix=NettyServerNIOWorker
transport.threadFactory.serverExecutorThreadPrefix=NettyServerBizHandler
transport.threadFactory.shareBossWorker=false
transport.threadFactory.clientSelectorThreadPrefix=NettyClientSelector
transport.threadFactory.clientSelectorThreadSize=1
transport.threadFactory.clientWorkerThreadPrefix=NettyClientWorkerThread
transport.threadFactory.bossThreadSize=1
transport.threadFactory.workerThreadSize=default
transport.shutdown.wait=3
# RM配置
client.rm.asyncCommitBufferLimit=10000
client.rm.lock.retryInterval=10
client.rm.lock.retryTimes=30
client.rm.lock.retryPolicyBranchRollbackOnConflict=true
client.rm.reportRetryCount=5
client.rm.tableMetaCheckEnable=false
client.rm.tableMetaCheckerInterval=60000
client.rm.sqlParserType=druid
client.rm.reportSuccessEnable=false
client.rm.sagaBranchRegisterEnable=false
# TM配置
client.tm.commitRetryCount=5
client.tm.rollbackRetryCount=5
client.tm.defaultGlobalTransactionTimeout=60000
client.tm.degradeCheck=false
client.tm.degradeCheckAllowTimes=10
client.tm.degradeCheckPeriod=2000

# undo日志配置
client.undo.dataValidation=true
client.undo.logSerialization=jackson
client.undo.onlyCareUpdateColumns=true
client.undo.logTable=undo_log
client.undo.compress.enable=true
client.undo.compress.type=zip
client.undo.compress.threshold=64k
client.log.exceptionRate=100
</code></pre>
</li>
</ul>
<h3 id="12-4-3-微服务读取nacos配置"><a href="#12-4-3-微服务读取nacos配置" class="headerlink" title="12.4.3 微服务读取nacos配置"></a>12.4.3 微服务读取nacos配置</h3><p>接下来，需要修改每一个微服务的application.yml文件，让微服务读取nacos中的client.properties文件：</p>
<pre><code class="yaml">seata:
  config:
    type: nacos
    nacos:
      server-addr: 127.0.0.1:8848
      username: nacos
      password: nacos
      group: SEATA_GROUP
      data-id: client.properties
</code></pre>
<p>重启微服务，现在微服务到底是连接tc的SH集群，还是tc的HZ集群，都统一由nacos的client.properties来决定了。</p>
<h1 id="十三、Redis缓存【分布式缓存】"><a href="#十三、Redis缓存【分布式缓存】" class="headerlink" title="十三、Redis缓存【分布式缓存】"></a>十三、Redis缓存【分布式缓存】</h1><p>基于Redis集群解决单机Redis存在四大的问题</p>
<ul>
<li>数据丢失问题<ul>
<li>实现Redis数据持久化</li>
</ul>
</li>
<li>并发能力问题<ul>
<li>搭建主从集群，实现读写分离</li>
</ul>
</li>
<li>故障回复问题<ul>
<li>利用Redis哨兵，实现健康检测和自动恢复</li>
</ul>
</li>
<li>存储能力问题<ul>
<li>搭建分片集群，利用插槽机制实现动态扩容</li>
</ul>
</li>
</ul>
<h2 id="13-1-安装Redis"><a href="#13-1-安装Redis" class="headerlink" title="13.1. 安装Redis"></a>13.1. 安装Redis</h2><p>① 首先需要安装Redis所需要的依赖：</p>
<pre><code class="sh">yum install -y gcc tcl
</code></pre>
<p>② 下载redis.tar.gz到&#x2F;tmp目录下</p>
<p>③ 解压缩</p>
<pre><code class="sh">tar -xvf redis-6.2.4.tar.gz
</code></pre>
<p>④ 进入redis目录：</p>
<pre><code class="sh">cd redis-6.2.4
</code></pre>
<p>⑤ 运行编译命令：</p>
<pre><code class="sh">make &amp;&amp; make install
</code></pre>
<p>⑥ 修改redis.conf文件中的一些配置：</p>
<pre><code class="properties"># 绑定地址，默认是127.0.0.1，会导致只能在本地访问。修改为0.0.0.0则可以在任意IP访问
bind 0.0.0.0
# 数据库数量，设置为1
databases 1
</code></pre>
<p>⑦ 启动与停止</p>
<p>启动Redis：</p>
<pre><code class="sh">redis-server redis.conf
</code></pre>
<p>停止redis服务：</p>
<pre><code class="sh">redis-cli shutdown
</code></pre>
<h2 id="13-2-Redis持久化"><a href="#13-2-Redis持久化" class="headerlink" title="13.2. Redis持久化"></a>13.2. Redis持久化</h2><p>Redis有两种持久化方案：</p>
<ul>
<li>RDB持久化</li>
<li>AOF持久化</li>
</ul>
<p>RDB全称Redis Database Backup file（Redis数据备份文件），也被叫做Redis数据快照。简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。快照文件称为RDB文件，默认是保存在当前运行目录。</p>
<h3 id="13-2-1-RDB持久化"><a href="#13-2-1-RDB持久化" class="headerlink" title="13.2.1 RDB持久化"></a>13.2.1 RDB持久化</h3><h4 id="①-执行时机"><a href="#①-执行时机" class="headerlink" title="① 执行时机"></a>① 执行时机</h4><p>RDB持久化在四种情况下会执行：</p>
<ul>
<li>执行save命令</li>
<li>执行bgsave命令</li>
<li>Redis停机时</li>
<li>触发RDB条件时</li>
</ul>
<p><strong>save命令</strong></p>
<p>执行下面的命令，可以立即执行一次RDB：</p>
<pre><code class="sh">redis-cli # 进入redis

save # 由Redis主进程来执行RDB，会阻塞所有命令
</code></pre>
<p>save命令会导致主进程执行RDB，这个过程中其它所有命令都会被阻塞。只有在数据迁移时可能用到。</p>
<p><strong>bgsave命令</strong></p>
<p>下面的命令可以异步执行RDB：</p>
<pre><code class="sh">redis-cli # 进入redis

bgsave # 开启子进程执行RDB，避免主进程受到影响。
</code></pre>
<p>这个命令执行后会开启独立进程完成RDB，主进程可以持续处理用户请求，不受影响。</p>
<p><strong>停机时</strong></p>
<p>Redis停机时会执行一次save命令，实现RDB持久化。</p>
<p><strong>触发RDB条件</strong></p>
<p>Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下：</p>
<pre><code class="properties"># 900秒内，如果至少有1个key被修改，则执行bgsave ， 如果是save &quot;&quot; 则表示禁用RDB
save 900 1  
save 300 10  
save 60 10000 
</code></pre>
<p>注：禁用RDB则添加<code>save &quot;&quot;</code></p>
<p>RDB的其它配置也可以在redis.conf文件中设置：</p>
<pre><code class="properties"># 是否压缩 ,建议不开启，压缩也会消耗cpu，磁盘的话不值钱
rdbcompression yes

# RDB文件名称
dbfilename dump.rdb  

# 文件保存的路径目录
dir ./ 
</code></pre>
<h4 id="②-RDB原理"><a href="#②-RDB原理" class="headerlink" title="② RDB原理"></a>② RDB原理</h4><p>bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 RDB 文件。</p>
<p>fork采用的是copy-on-write技术：</p>
<ul>
<li>当主进程执行读操作时，访问共享内存；</li>
<li>当主进程执行写操作时，则会拷贝一份数据，执行写操作。</li>
</ul>
<h4 id="③-小结"><a href="#③-小结" class="headerlink" title="③ 小结"></a>③ 小结</h4><p>RDB方式bgsave的基本流程？</p>
<ul>
<li>fork主进程得到一个子进程，共享内存空间</li>
<li>子进程读取内存数据并写入新的RDB文件</li>
<li>用新RDB文件替换旧的RDB文件</li>
</ul>
<p>RDB会在什么时候执行？save 60 1000代表什么含义？</p>
<ul>
<li>默认是服务停止时</li>
<li>代表60秒内至少执行1000次修改则触发RDB</li>
</ul>
<p>RDB的缺点？</p>
<ul>
<li>RDB执行间隔时间长，两次RDB之间写入数据有丢失的风险</li>
<li>fork子进程、压缩、写出RDB文件都比较耗时</li>
</ul>
<h3 id="13-2-2-AOF持久化"><a href="#13-2-2-AOF持久化" class="headerlink" title="13.2.2 AOF持久化"></a>13.2.2 AOF持久化</h3><h4 id="①-AOF原理"><a href="#①-AOF原理" class="headerlink" title="① AOF原理"></a>① AOF原理</h4><p>AOF全称为Append Only File（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件。</p>
<h4 id="②-AOF配置"><a href="#②-AOF配置" class="headerlink" title="② AOF配置"></a>② AOF配置</h4><p>AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF：</p>
<pre><code class="properties"># 关闭RDB
save &quot;&quot;
# 是否开启AOF功能，默认是no
appendonly yes
# AOF文件的名称
appendfilename &quot;appendonly.aof&quot;
</code></pre>
<p>AOF的命令记录的频率也可以通过redis.conf文件来配：</p>
<pre><code class="properties"># 表示每执行一次写命令，立即记录到AOF文件
appendfsync always 
# 写命令执行完先放入AOF缓冲区，然后表示每隔1秒将缓冲区数据写到AOF文件，是默认方案
appendfsync everysec 
# 写命令执行完先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘
appendfsync no
</code></pre>
<p>三种策略对比：</p>
<table>
<thead>
<tr>
<th align="center">配置项</th>
<th align="center">刷盘时机</th>
<th align="center">优点</th>
<th align="center">缺点</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Always</td>
<td align="center">同步刷盘</td>
<td align="center">可靠性高，几乎不丢数据</td>
<td align="center">性能影响大</td>
</tr>
<tr>
<td align="center">everysec</td>
<td align="center">每秒刷盘</td>
<td align="center">性能始终</td>
<td align="center">最多丢失1秒数据</td>
</tr>
<tr>
<td align="center">no</td>
<td align="center">操作系统控制</td>
<td align="center">性能最好</td>
<td align="center">可靠性较差，可能丢失大量数据</td>
</tr>
</tbody></table>
<h4 id="③-AOF文件重写"><a href="#③-AOF文件重写" class="headerlink" title="③ AOF文件重写"></a>③ AOF文件重写</h4><p>因为是记录命令，AOF文件会比RDB文件大的多。而且AOF会记录对同一个key的多次写操作，但只有最后一次写操作才有意义。通过执行bgrewriteaof命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果。</p>
<p>例如，AOF原本有三个命令<code>set num 123;set name jack;set num 666</code>，但是<code>set num 123 和 set num 666</code>都是对num的操作，第二次会覆盖第一次的值，因此第一个命令记录下来没有意义。</p>
<p>所以重写命令后，AOF文件内容就是：<code>mset name jack num 666</code></p>
<p>Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置：</p>
<pre><code class="properties"># AOF文件比上次文件 增长超过多少百分比则触发重写
auto-aof-rewrite-percentage 100
# AOF文件体积最小多大以上才触发重写 
auto-aof-rewrite-min-size 64mb 
</code></pre>
<h3 id="13-2-3-RDB与AOF对比"><a href="#13-2-3-RDB与AOF对比" class="headerlink" title="13.2.3 RDB与AOF对比"></a>13.2.3 RDB与AOF对比</h3><p>RDB和AOF各有自己的优缺点，如果对数据安全性要求较高，在实际开发中往往会<strong>结合</strong>两者来使用。</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">RDB</th>
<th align="center">AOF</th>
</tr>
</thead>
<tbody><tr>
<td align="center">持久化方式</td>
<td align="center">定时对整个内存做快照</td>
<td align="center">记录每一次执行的命令</td>
</tr>
<tr>
<td align="center">数据完整性</td>
<td align="center">不完整，两次备份之间会丢失</td>
<td align="center">相对完整，取决于刷盘策略</td>
</tr>
<tr>
<td align="center">文件大小</td>
<td align="center">会有压缩，文件体积小</td>
<td align="center">记录命令，文件体积很大</td>
</tr>
<tr>
<td align="center">宕机恢复速度</td>
<td align="center">很快</td>
<td align="center">慢</td>
</tr>
<tr>
<td align="center">数据恢复优先级</td>
<td align="center">低，因为数据完整性不如AOF</td>
<td align="center">高，因为数据完整性更高</td>
</tr>
<tr>
<td align="center">系统资源占用</td>
<td align="center">高，大量CPU和内存消耗</td>
<td align="center">低，主要是磁盘IO资源，但AOF重写时会占用大量CPU和内存资源</td>
</tr>
<tr>
<td align="center">使用场景</td>
<td align="center">可以容忍分钟的数据丢失，追求更快的启动速度</td>
<td align="center">对数据安全性要求较高时常见</td>
</tr>
</tbody></table>
<h2 id="13-3-Redis主从"><a href="#13-3-Redis主从" class="headerlink" title="13.3. Redis主从"></a>13.3. Redis主从</h2><h3 id="13-3-1-搭建主从架构"><a href="#13-3-1-搭建主从架构" class="headerlink" title="13.3.1 搭建主从架构"></a>13.3.1 搭建主从架构</h3><p>单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，就需要搭建主从集群，实现读写分离。</p>
<h4 id="①-集群架构"><a href="#①-集群架构" class="headerlink" title="① 集群架构"></a>① 集群架构</h4><p>共包含三个节点，一个主节点，两个从节点。</p>
<p>这里我们会在同一台虚拟机中开启3个redis实例，模拟主从集群，信息如下：</p>
<table>
<thead>
<tr>
<th align="center">IP</th>
<th align="center">PORT</th>
<th align="center">角色</th>
</tr>
</thead>
<tbody><tr>
<td align="center">192.168.150.101</td>
<td align="center">7001</td>
<td align="center">master</td>
</tr>
<tr>
<td align="center">192.168.150.101</td>
<td align="center">7002</td>
<td align="center">slave</td>
</tr>
<tr>
<td align="center">192.168.150.101</td>
<td align="center">7003</td>
<td align="center">slave</td>
</tr>
</tbody></table>
<h4 id="②-准备实例和配置"><a href="#②-准备实例和配置" class="headerlink" title="② 准备实例和配置"></a>② 准备实例和配置</h4><p>要在同一台虚拟机开启3个实例，必须准备三份不同的配置文件和目录，配置文件所在目录也就是工作目录。</p>
<p>1）创建目录</p>
<p>我们创建三个文件夹，名字分别叫7001、7002、7003：</p>
<pre><code class="sh"># 进入/tmp目录
cd /tmp
# 创建目录
mkdir 7001 7002 7003
</code></pre>
<p>2）恢复原始配置</p>
<p>修改redis-6.2.4&#x2F;redis.conf文件，将其中的持久化模式改为默认的RDB模式，AOF保持关闭状态。</p>
<pre><code class="properties"># 开启RDB
# save &quot;&quot;
save 3600 1
save 300 100
save 60 10000

# 关闭AOF
appendonly no
</code></pre>
<p>3）拷贝配置文件到每个实例目录</p>
<p>然后将redis-6.2.4&#x2F;redis.conf文件拷贝到三个目录中（在&#x2F;tmp目录执行下列命令）：</p>
<pre><code class="sh"># 方式一：逐个拷贝
cp redis-6.2.4/redis.conf 7001
cp redis-6.2.4/redis.conf 7002
cp redis-6.2.4/redis.conf 7003
# 方式二：管道组合命令，一键拷贝
echo 7001 7002 7003 | xargs -t -n 1 cp redis-6.2.4/redis.conf
</code></pre>
<p>4）修改每个实例的端口、工作目录</p>
<p>修改每个文件夹内的配置文件，将端口分别修改为7001、7002、7003，将rdb文件保存位置都修改为自己所在目录（在&#x2F;tmp目录执行下列命令）：</p>
<pre><code class="sh">sed -i -e &#39;s/6379/7001/g&#39; -e &#39;s/dir .\//dir \/tmp\/7001\//g&#39; 7001/redis.conf
sed -i -e &#39;s/6379/7002/g&#39; -e &#39;s/dir .\//dir \/tmp\/7002\//g&#39; 7002/redis.conf
sed -i -e &#39;s/6379/7003/g&#39; -e &#39;s/dir .\//dir \/tmp\/7003\//g&#39; 7003/redis.conf
</code></pre>
<p>5）修改每个实例的声明IP</p>
<p>虚拟机本身有多个IP，为了避免将来混乱，我们需要在redis.conf文件中指定每一个实例的绑定ip信息，格式如下：</p>
<pre><code class="properties"># redis实例的声明 IP
replica-announce-ip 192.168.150.101
</code></pre>
<p>每个目录都要改，我们一键完成修改（在&#x2F;tmp目录执行下列命令）：</p>
<pre><code class="sh"># 逐一执行
sed -i &#39;1a replica-announce-ip 192.168.150.101&#39; 7001/redis.conf
sed -i &#39;1a replica-announce-ip 192.168.150.101&#39; 7002/redis.conf
sed -i &#39;1a replica-announce-ip 192.168.150.101&#39; 7003/redis.conf

# 或者一键修改
printf &#39;%s\n&#39; 7001 7002 7003 | xargs -I&#123;&#125; -t sed -i &#39;1a replica-announce-ip 192.168.150.101&#39; &#123;&#125;/redis.conf
</code></pre>
<h4 id="③-启动"><a href="#③-启动" class="headerlink" title="③ 启动"></a>③ 启动</h4><p>为了方便查看日志，我们打开3个ssh窗口，分别启动3个redis实例，启动命令：</p>
<pre><code class="sh"># 第1个
redis-server 7001/redis.conf
# 第2个
redis-server 7002/redis.conf
# 第3个
redis-server 7003/redis.conf
</code></pre>
<p>如果要一键停止，可以运行下面命令：</p>
<pre><code class="sh">printf &#39;%s\n&#39; 7001 7002 7003 | xargs -I&#123;&#125; -t redis-cli -p &#123;&#125; shutdown
</code></pre>
<h4 id="④-开启主从关系"><a href="#④-开启主从关系" class="headerlink" title="④ 开启主从关系"></a>④ 开启主从关系</h4><p>现在三个实例还没有任何关系，要配置主从可以使用replicaof 或者slaveof（5.0以前）命令。</p>
<p>有临时和永久两种模式：</p>
<ul>
<li><p>修改配置文件（永久生效）</p>
<ul>
<li>在redis.conf中添加一行配置：<code>slaveof &lt;masterip&gt; &lt;masterport&gt;</code></li>
</ul>
</li>
<li><p>使用redis-cli客户端连接到redis服务，执行slaveof命令（重启后失效）：</p>
<pre><code class="sh">slaveof &lt;masterip&gt; &lt;masterport&gt;
</code></pre>
</li>
</ul>
<p><strong>注意</strong>：在5.0以后新增命令replicaof，与salveof效果一致。</p>
<p>这里我们为了演示方便，使用方式二。</p>
<p>通过redis-cli命令连接7002，执行下面命令：</p>
<pre><code class="sh"># 连接 7002
redis-cli -p 7002
# 执行slaveof
slaveof 192.168.150.101 7001
</code></pre>
<p>通过redis-cli命令连接7003，执行下面命令：</p>
<pre><code class="sh"># 连接 7003
redis-cli -p 7003
# 执行slaveof
slaveof 192.168.150.101 7001
</code></pre>
<p>然后连接 7001节点，查看集群状态：</p>
<pre><code class="sh"># 连接 7001
redis-cli -p 7001
# 查看状态
info replication
</code></pre>
<h4 id="⑤-测试"><a href="#⑤-测试" class="headerlink" title="⑤ 测试"></a>⑤ 测试</h4><p>执行下列操作以测试：</p>
<ul>
<li>利用redis-cli连接7001，执行<code>set num 123</code></li>
<li>利用redis-cli连接7002，执行<code>get num</code>，再执行<code>set num 666</code></li>
<li>利用redis-cli连接7003，执行<code>get num</code>，再执行<code>set num 888</code></li>
</ul>
<p>可以发现，只有在7001这个master节点上可以执行写操作，7002和7003这两个slave节点只能执行读操作。</p>
<h3 id="13-3-2-主从数据同步原理"><a href="#13-3-2-主从数据同步原理" class="headerlink" title="13.3.2 主从数据同步原理"></a>13.3.2 主从数据同步原理</h3><h4 id="①-全量同步"><a href="#①-全量同步" class="headerlink" title="① 全量同步"></a>① 全量同步</h4><p>主从第一次建立连接时，会执行<strong>全量同步</strong>，将master节点的所有数据都拷贝给slave节点</p>
<p>这里有一个问题，master如何得知salve是第一次来连接呢？？</p>
<p>有几个概念，可以作为判断依据：</p>
<ul>
<li><strong>Replication Id</strong>：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid</li>
<li><strong>offset</strong>：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。</li>
</ul>
<p>因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据。</p>
<p>因为slave原本也是一个master，有自己的replid和offset，当第一次变成slave，与master建立连接时，发送的replid和offset是自己的replid和offset。</p>
<p>master判断发现slave发送来的replid与自己的不一致，说明这是一个全新的slave，就知道要做全量同步了。</p>
<p>master会将自己的replid和offset都发送给这个slave，slave保存这些信息。以后slave的replid就与master一致了。</p>
<p>因此，<strong>master判断一个节点是否是第一次同步的依据，就是看replid是否一致</strong>。</p>
<p><strong>完整流程</strong>描述：</p>
<ul>
<li>slave节点请求增量同步</li>
<li>master节点判断replid，发现不一致，拒绝增量同步</li>
<li>master将完整内存数据生成RDB，发送RDB到slave</li>
<li>slave清空本地数据，加载master的RDB</li>
<li>master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave</li>
<li>slave执行接收到的命令，保持与master之间的同步</li>
</ul>
<h4 id="②-增量同步"><a href="#②-增量同步" class="headerlink" title="② 增量同步"></a>② 增量同步</h4><p>全量同步需要先做RDB，然后将RDB文件通过网络传输个slave，成本太高了。因此除了第一次做全量同步，其它大多数时候slave与master都是做<strong>增量同步</strong>。</p>
<p>什么是增量同步？就是只更新slave与master存在差异的部分数据。</p>
<h4 id="③-repl-backlog原理"><a href="#③-repl-backlog原理" class="headerlink" title="③ repl_backlog原理"></a>③ repl_backlog原理</h4><p>master怎么知道slave与自己的数据差异在哪里呢?</p>
<p>这就要说到全量同步时的repl_baklog文件了。</p>
<p>这个文件是一个固定大小的数组，只不过数组是环形，也就是说<strong>角标到达数组末尾后，会再次从0开始读写</strong>，这样数组头部的数据就会被覆盖。</p>
<p>注：repl_baklog大小有上限，写满后会覆盖最早的数据。如果slave断开时间过久，导致尚未备份的数据被覆盖，则无法基于log做增量同步，只能再次全量同步。</p>
<h3 id="13-3-3-主从同步优化"><a href="#13-3-3-主从同步优化" class="headerlink" title="13.3.3 主从同步优化"></a>13.3.3 主从同步优化</h3><p>主从同步可以保证主从数据的一致性，非常重要。</p>
<p>可以从以下几个方面来优化Redis主从就集群：</p>
<ul>
<li>在master中配置<code>repl-diskless-sync yes</code>启用无磁盘复制，避免全量同步时的磁盘IO。</li>
<li>Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO</li>
<li>适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步</li>
<li>限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力</li>
</ul>
<h3 id="13-3-4-小结"><a href="#13-3-4-小结" class="headerlink" title="13.3.4 小结"></a>13.3.4 小结</h3><p>简述全量同步和增量同步区别？</p>
<ul>
<li>全量同步：master将完整内存数据生成RDB，发送RDB到slave。后续命令则记录在repl_baklog，逐个发送给slave。</li>
<li>增量同步：slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave</li>
</ul>
<p>什么时候执行全量同步？</p>
<ul>
<li>slave节点第一次连接master节点时</li>
<li>slave节点断开时间太久，repl_baklog中的offset已经被覆盖时</li>
</ul>
<p>什么时候执行增量同步？</p>
<ul>
<li>slave节点断开又恢复，并且在repl_baklog中能找到offset时</li>
</ul>
<h2 id="13-4-Redis哨兵"><a href="#13-4-Redis哨兵" class="headerlink" title="13.4. Redis哨兵"></a>13.4. Redis哨兵</h2><p>Redis提供了哨兵（Sentinel）机制来实现主从集群的自动故障恢复。</p>
<h3 id="13-4-1-哨兵原理"><a href="#13-4-1-哨兵原理" class="headerlink" title="13.4.1 哨兵原理"></a>13.4.1 哨兵原理</h3><h4 id="①-集群结构和作用"><a href="#①-集群结构和作用" class="headerlink" title="① 集群结构和作用"></a>① 集群结构和作用</h4><ul>
<li>RedisClient</li>
<li>Sentinel若干，给RedisClient发送服务状态变更通知，同时监控redis集群状态</li>
<li>Redis【master单个，slave若干】，master将数据同步给slave</li>
</ul>
<p>哨兵的作用如下：</p>
<ul>
<li><strong>监控</strong>：Sentinel 会不断检查您的master和slave是否按预期工作</li>
<li><strong>自动故障恢复</strong>：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主</li>
<li><strong>通知</strong>：Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端</li>
</ul>
<h4 id="②-集群监控原理"><a href="#②-集群监控原理" class="headerlink" title="② 集群监控原理"></a>② 集群监控原理</h4><p>Sentinel基于心跳机制监测服务状态，每隔1秒向集群的每个实例发送ping命令：</p>
<p>•主观下线：如果某sentinel节点发现某实例未在规定时间响应，则认为该实例<strong>主观下线</strong>。</p>
<p>•客观下线：若超过指定数量（quorum）的sentinel都认为该实例主观下线，则该实例<strong>客观下线</strong>。quorum值最好超过Sentinel实例数量的一半。</p>
<h4 id="③-集群故障恢复原理"><a href="#③-集群故障恢复原理" class="headerlink" title="③ 集群故障恢复原理"></a>③ 集群故障恢复原理</h4><p>一旦发现master故障，sentinel需要在salve中选择一个作为新的master，选择依据是这样的：</p>
<ul>
<li>首先会判断slave节点与master节点断开时间长短，如果超过指定值（down-after-milliseconds * 10）则会排除该slave节点</li>
<li>然后判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举</li>
<li>如果slave-prority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高</li>
<li>最后是判断slave节点的运行id大小，越小优先级越高。</li>
</ul>
<p>当选出一个新的master后，该如何实现切换呢？</p>
<p>流程如下：</p>
<ul>
<li>sentinel给备选的slave1节点发送slaveof no one命令，让该节点成为master</li>
<li>sentinel给所有其它slave发送slaveof 192.168.150.101 7002 命令，让这些slave成为新master的从节点，开始从新的master上同步数据。</li>
<li>最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点</li>
</ul>
<h4 id="④-小结"><a href="#④-小结" class="headerlink" title="④ 小结"></a>④ 小结</h4><p>Sentinel的三个作用是什么？</p>
<ul>
<li>监控</li>
<li>故障转移</li>
<li>通知</li>
</ul>
<p>Sentinel如何判断一个redis实例是否健康？</p>
<ul>
<li>每隔1秒发送一次ping命令，如果超过一定时间没有相向则认为是主观下线</li>
<li>如果大多数sentinel都认为实例主观下线，则判定服务下线</li>
</ul>
<p>故障转移步骤有哪些？</p>
<ul>
<li>首先选定一个slave作为新的master，执行slaveof no one</li>
<li>然后让所有节点都执行slaveof 新master</li>
<li>修改故障节点配置，添加slaveof 新master</li>
</ul>
<h3 id="13-4-2-搭建哨兵集群"><a href="#13-4-2-搭建哨兵集群" class="headerlink" title="13.4.2 搭建哨兵集群"></a>13.4.2 搭建哨兵集群</h3><h4 id="①-集群结构"><a href="#①-集群结构" class="headerlink" title="① 集群结构"></a>① 集群结构</h4><p>这里我们搭建一个三节点形成的Sentinel集群，来监管之前的Redis【7001,7002,7003】主从集群。</p>
<p>三个sentinel实例信息如下：</p>
<table>
<thead>
<tr>
<th>节点</th>
<th align="center">IP</th>
<th align="center">PORT</th>
</tr>
</thead>
<tbody><tr>
<td>s1</td>
<td align="center">192.168.150.101</td>
<td align="center">27001</td>
</tr>
<tr>
<td>s2</td>
<td align="center">192.168.150.101</td>
<td align="center">27002</td>
</tr>
<tr>
<td>s3</td>
<td align="center">192.168.150.101</td>
<td align="center">27003</td>
</tr>
</tbody></table>
<h4 id="②-准备实例和配置-1"><a href="#②-准备实例和配置-1" class="headerlink" title="② 准备实例和配置"></a>② 准备实例和配置</h4><p>要在同一台虚拟机开启3个实例，必须准备三份不同的配置文件和目录，配置文件所在目录也就是工作目录。</p>
<p>我们创建三个文件夹，名字分别叫s1、s2、s3：</p>
<pre><code class="sh"># 进入/tmp目录
cd /tmp
# 创建目录
mkdir s1 s2 s3
</code></pre>
<p>在s1目录创建一个sentinel.conf文件，添加下面的内容：</p>
<pre><code class="ini">port 27001
sentinel announce-ip 192.168.150.101
sentinel monitor mymaster 192.168.150.101 7001 2
sentinel down-after-milliseconds mymaster 5000
sentinel failover-timeout mymaster 60000
dir &quot;/tmp/s1&quot;
</code></pre>
<p>解读：</p>
<ul>
<li><code>port 27001</code>：是当前sentinel实例的端口</li>
<li><code>sentinel monitor mymaster 192.168.150.101 7001 2</code>：指定主节点信息<ul>
<li><code>mymaster</code>：主节点名称，自定义，任意写</li>
<li><code>192.168.150.101 7001</code>：主节点的ip和端口</li>
<li><code>2</code>：选举master时的quorum值</li>
</ul>
</li>
</ul>
<p>然后将s1&#x2F;sentinel.conf文件拷贝到s2、s3两个目录中（在&#x2F;tmp目录执行下列命令）：</p>
<pre><code class="sh"># 方式一：逐个拷贝
cp s1/sentinel.conf s2
cp s1/sentinel.conf s3
# 方式二：管道组合命令，一键拷贝
echo s2 s3 | xargs -t -n 1 cp s1/sentinel.conf
</code></pre>
<p>修改s2、s3两个文件夹内的配置文件，将端口分别修改为27002、27003：</p>
<pre><code class="sh">sed -i -e &#39;s/27001/27002/g&#39; -e &#39;s/s1/s2/g&#39; s2/sentinel.conf
sed -i -e &#39;s/27001/27003/g&#39; -e &#39;s/s1/s3/g&#39; s3/sentinel.conf
</code></pre>
<h4 id="③-启动-1"><a href="#③-启动-1" class="headerlink" title="③ 启动"></a>③ 启动</h4><p>为了方便查看日志，我们打开3个ssh窗口，分别启动3个redis实例，启动命令：</p>
<pre><code class="sh"># 第1个
redis-sentinel s1/sentinel.conf
# 第2个
redis-sentinel s2/sentinel.conf
# 第3个
redis-sentinel s3/sentinel.conf
</code></pre>
<h4 id="④-测试"><a href="#④-测试" class="headerlink" title="④ 测试"></a>④ 测试</h4><ul>
<li>尝试让master节点7001宕机，查看sentinel日志</li>
</ul>
<h3 id="13-4-3-RedisTemplate"><a href="#13-4-3-RedisTemplate" class="headerlink" title="13.4.3 RedisTemplate"></a>13.4.3 RedisTemplate</h3><p>在Sentinel集群监管下的Redis主从集群，其节点会因为自动故障转移而发生变化，Redis的客户端必须感知这种变化，及时更新连接信息。Spring的RedisTemplate底层利用lettuce实现了节点的感知和自动切换。</p>
<p>下面，我们通过一个测试来实现RedisTemplate集成哨兵机制。</p>
<h4 id="①-引入依赖"><a href="#①-引入依赖" class="headerlink" title="① 引入依赖"></a>① 引入依赖</h4><p>在项目的pom文件中引入依赖：</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<h4 id="②-配置Redis地址"><a href="#②-配置Redis地址" class="headerlink" title="② 配置Redis地址"></a>② 配置Redis地址</h4><p>在配置文件application.yml中指定redis的sentinel相关信息：</p>
<pre><code class="java">spring:
  redis:
    sentinel:
      master: mymaster
      nodes:
        - 192.168.150.101:27001
        - 192.168.150.101:27002
        - 192.168.150.101:27003
</code></pre>
<h4 id="③-配置读写分离"><a href="#③-配置读写分离" class="headerlink" title="③ 配置读写分离"></a>③ 配置读写分离</h4><p>在项目的启动类中，添加一个新的bean：</p>
<pre><code class="java">@Bean
public LettuceClientConfigurationBuilderCustomizer clientConfigurationBuilderCustomizer()&#123;
    return clientConfigurationBuilder -&gt; clientConfigurationBuilder.readFrom(ReadFrom.REPLICA_PREFERRED);
&#125;
</code></pre>
<p>这个bean中配置的就是读写策略，包括四种：</p>
<ul>
<li>MASTER：从主节点读取</li>
<li>MASTER_PREFERRED：优先从master节点读取，master不可用才读取replica</li>
<li>REPLICA：从slave（replica）节点读取</li>
<li>REPLICA _PREFERRED：优先从slave（replica）节点读取，所有的slave都不可用才读取master</li>
</ul>
<h2 id="13-5-Redis分片集群"><a href="#13-5-Redis分片集群" class="headerlink" title="13.5. Redis分片集群"></a>13.5. Redis分片集群</h2><h3 id="13-5-1-搭建分片集群"><a href="#13-5-1-搭建分片集群" class="headerlink" title="13.5.1 搭建分片集群"></a>13.5.1 搭建分片集群</h3><p>主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决：</p>
<ul>
<li>海量数据存储问题</li>
<li>高并发写的问题</li>
</ul>
<p>使用分片集群可以解决上述问题。</p>
<p><strong>分片集群特征</strong>：</p>
<ul>
<li>集群中有多个master，每个master保存不同数据</li>
<li>每个master都可以有多个slave节点</li>
<li>master之间通过ping监测彼此健康状态</li>
<li>客户端请求可以访问集群任意节点，最终都会被转发到正确节点</li>
</ul>
<h4 id="①-集群结构-1"><a href="#①-集群结构-1" class="headerlink" title="① 集群结构"></a>① 集群结构</h4><p>分片集群需要的节点数量较多，这里我们搭建一个最小的分片集群，包含3个master节点，每个master包含一个slave节点</p>
<p>在同一台虚拟机中开启6个redis实例，模拟分片集群，信息如下：</p>
<table>
<thead>
<tr>
<th align="center">IP</th>
<th align="center">PORT</th>
<th align="center">角色</th>
</tr>
</thead>
<tbody><tr>
<td align="center">192.168.150.101</td>
<td align="center">7001</td>
<td align="center">master</td>
</tr>
<tr>
<td align="center">192.168.150.101</td>
<td align="center">7002</td>
<td align="center">master</td>
</tr>
<tr>
<td align="center">192.168.150.101</td>
<td align="center">7003</td>
<td align="center">master</td>
</tr>
<tr>
<td align="center">192.168.150.101</td>
<td align="center">8001</td>
<td align="center">slave</td>
</tr>
<tr>
<td align="center">192.168.150.101</td>
<td align="center">8002</td>
<td align="center">slave</td>
</tr>
<tr>
<td align="center">192.168.150.101</td>
<td align="center">8003</td>
<td align="center">slave</td>
</tr>
</tbody></table>
<h4 id="②-准备实例和配置-2"><a href="#②-准备实例和配置-2" class="headerlink" title="② 准备实例和配置"></a>② 准备实例和配置</h4><p>删除之前的7001、7002、7003这几个目录，重新创建出7001、7002、7003、8001、8002、8003目录：</p>
<pre><code class="sh"># 进入/tmp目录
cd /tmp
# 删除旧的，避免配置干扰
rm -rf 7001 7002 7003
# 创建目录
mkdir 7001 7002 7003 8001 8002 8003
</code></pre>
<p>在&#x2F;tmp下准备一个新的redis.conf文件，内容如下：</p>
<pre><code class="ini">port 6379
# 开启集群功能
cluster-enabled yes
# 集群的配置文件名称，不需要我们创建，由redis自己维护
cluster-config-file /tmp/6379/nodes.conf
# 节点心跳失败的超时时间
cluster-node-timeout 5000
# 持久化文件存放目录
dir /tmp/6379
# 绑定地址
bind 0.0.0.0
# 让redis后台运行
daemonize yes
# 注册的实例ip
replica-announce-ip 192.168.150.101
# 保护模式
protected-mode no
# 数据库数量
databases 1
# 日志
logfile /tmp/6379/run.log
</code></pre>
<p>将这个文件拷贝到每个目录下：</p>
<pre><code class="sh"># 进入/tmp目录
cd /tmp
# 执行拷贝
echo 7001 7002 7003 8001 8002 8003 | xargs -t -n 1 cp redis.conf
</code></pre>
<p>修改每个目录下的redis.conf，将其中的6379修改为与所在目录一致：</p>
<pre><code class="sh"># 进入/tmp目录
cd /tmp
# 修改配置文件
printf &#39;%s\n&#39; 7001 7002 7003 8001 8002 8003 | xargs -I&#123;&#125; -t sed -i &#39;s/6379/&#123;&#125;/g&#39; &#123;&#125;/redis.conf
</code></pre>
<h4 id="③-启动-2"><a href="#③-启动-2" class="headerlink" title="③ 启动"></a>③ 启动</h4><p>因为已经配置了后台启动模式，所以可以直接启动服务：</p>
<pre><code class="sh"># 进入/tmp目录
cd /tmp
# 一键启动所有服务
printf &#39;%s\n&#39; 7001 7002 7003 8001 8002 8003 | xargs -I&#123;&#125; -t redis-server &#123;&#125;/redis.conf
</code></pre>
<p>通过ps查看状态：</p>
<pre><code class="sh">ps -ef | grep redis
</code></pre>
<p>如果要关闭所有进程，可以执行命令：</p>
<pre><code class="sh">ps -ef | grep redis | awk &#39;&#123;print $2&#125;&#39; | xargs kill
</code></pre>
<p>或者（推荐这种方式）：</p>
<pre><code class="sh">printf &#39;%s\n&#39; 7001 7002 7003 8001 8002 8003 | xargs -I&#123;&#125; -t redis-cli -p &#123;&#125; shutdown
</code></pre>
<h4 id="④-创建集群"><a href="#④-创建集群" class="headerlink" title="④ 创建集群"></a>④ 创建集群</h4><p>虽然服务启动了，但是目前每个服务之间都是独立的，没有任何关联。</p>
<p>我们需要执行命令来创建集群，在Redis5.0之前创建集群比较麻烦，5.0之后集群管理命令都集成到了redis-cli中。</p>
<p>1）Redis5.0之前</p>
<p>Redis5.0之前集群命令都是用redis安装包下的src&#x2F;redis-trib.rb来实现的。因为redis-trib.rb是有ruby语言编写的所以需要安装ruby环境。</p>
<pre><code class="sh"># 安装依赖
yum -y install zlib ruby rubygems
gem install redis
</code></pre>
<p>然后通过命令来管理集群：</p>
<pre><code class="sh"># 进入redis的src目录
cd /tmp/redis-6.2.4/src
# 创建集群
./redis-trib.rb create --replicas 1 192.168.150.101:7001 192.168.150.101:7002 192.168.150.101:7003 192.168.150.101:8001 192.168.150.101:8002 192.168.150.101:8003
</code></pre>
<p>2）Redis5.0以后</p>
<p>我们使用的是Redis6.2.4版本，集群管理以及集成到了redis-cli中，格式如下：</p>
<pre><code class="sh">redis-cli --cluster create --cluster-replicas 1 192.168.150.101:7001 192.168.150.101:7002 192.168.150.101:7003 192.168.150.101:8001 192.168.150.101:8002 192.168.150.101:8003
</code></pre>
<p>命令说明：</p>
<ul>
<li><code>redis-cli --cluster</code>或者<code>./redis-trib.rb</code>：代表集群操作命令</li>
<li><code>create</code>：代表是创建集群</li>
<li><code>--replicas 1</code>或者<code>--cluster-replicas 1</code> ：指定集群中每个master的副本个数为1，此时<code>节点总数 ÷ (replicas + 1)</code> 得到的就是master的数量。因此节点列表中的前n个就是master，其它节点都是slave节点，随机分配到不同master</li>
</ul>
<p>运行后：<strong>输入yes，开始创建集群</strong></p>
<p>通过命令可以查看集群状态：</p>
<pre><code class="sh">redis-cli -p 7001 cluster nodes
</code></pre>
<h4 id="⑤-测试-1"><a href="#⑤-测试-1" class="headerlink" title="⑤ 测试"></a>⑤ 测试</h4><p>尝试连接7001节点，存储一个数据：</p>
<pre><code class="sh"># 连接
redis-cli -p 7001
# 存储数据
set num 123
# 读取数据
get num
# 再次存储
set a 1
</code></pre>
<p>结果悲剧了，<code>(error) MOVED 15495 192.168.150.101:7003</code></p>
<p>集群操作时，需要给<code>redis-cli</code>加上<code>-c</code>参数才可以：</p>
<pre><code class="sh">redis-cli -c -p 7001
</code></pre>
<h3 id="13-5-2-散列插槽"><a href="#13-5-2-散列插槽" class="headerlink" title="13.5.2 散列插槽"></a>13.5.2 散列插槽</h3><h4 id="①-插槽原理"><a href="#①-插槽原理" class="headerlink" title="① 插槽原理"></a>① 插槽原理</h4><p>Redis会把每一个master节点映射到0~16383共16384个插槽（hash slot）上，查看集群信息时就能看到：<code>slots:[0-5460] (5461 slots) master</code></p>
<p><strong>数据key不是与节点绑定，而是与插槽绑定</strong>。redis会根据key的有效部分计算插槽值，分两种情况：</p>
<ul>
<li>key中包含”{}”，且“{}”中至少包含1个字符，“{}”中的部分是有效部分</li>
<li>key中不包含“{}”，整个key都是有效部分</li>
</ul>
<p>例如：key是num，那么就根据num计算，如果是{itcast}num，则根据itcast计算。计算方式是利用CRC16算法得到一个hash值，然后对16384取余，得到的结果就是slot值。</p>
<pre><code>set a 1

get num
</code></pre>
<p>如上述代码，在7001这个节点执行<code>set a 1</code>时，对a做hash运算，对16384取余，得到的结果是15495，因此要存储到103节点。</p>
<p>到了7003后，执行<code>get num</code>时，对num做hash运算，对16384取余，得到的结果是2765，因此需要切换到7001节点</p>
<h4 id="②-小结"><a href="#②-小结" class="headerlink" title="② 小结"></a>② 小结</h4><p>Redis如何判断某个key应该在哪个实例？</p>
<ul>
<li>将16384个插槽分配到不同的实例</li>
<li>根据key的有效部分计算哈希值，对16384取余</li>
<li>余数作为插槽，寻找插槽所在实例即可</li>
</ul>
<p>如何将同一类数据固定的保存在同一个Redis实例？</p>
<ul>
<li>这一类数据使用相同的有效部分，例如key都以{typeId}为前缀</li>
</ul>
<h3 id="13-5-3-集群伸缩"><a href="#13-5-3-集群伸缩" class="headerlink" title="13.5.3 集群伸缩"></a>13.5.3 集群伸缩</h3><p>redis-cli –cluster提供了很多操作集群的命令，可以通过下面方式查看：</p>
<pre><code class="sh">redis-cli --cluster help
</code></pre>
<p>比如，添加节点的命令：</p>
<pre><code class="sh">reids-cli --cluster add-node new_host:new_port existing_host:existing_port
    --cluster-slave
    --cluster-master-id &lt;arg&gt;
</code></pre>
<h4 id="①-需求分析"><a href="#①-需求分析" class="headerlink" title="① 需求分析"></a>① 需求分析</h4><p>需求：向集群中添加一个新的master节点，并向其中存储 num &#x3D; 10</p>
<ul>
<li>启动一个新的redis实例，端口为7004</li>
<li>添加7004到之前的集群，并作为一个master节点</li>
<li>给7004节点分配插槽，使得num这个key可以存储到7004实例</li>
</ul>
<p>这里需要两个新的功能：</p>
<ul>
<li>添加一个节点到集群中</li>
<li>将部分插槽分配到新插槽</li>
</ul>
<h4 id="②-创建新的redis实例"><a href="#②-创建新的redis实例" class="headerlink" title="② 创建新的redis实例"></a>② 创建新的redis实例</h4><p>创建一个文件夹：</p>
<pre><code class="sh">mkdir 7004
</code></pre>
<p>拷贝配置文件：</p>
<pre><code class="sh">cp redis.conf /7004
</code></pre>
<p>修改配置文件：</p>
<pre><code class="sh">sed /s/6379/7004/g 7004/redis.conf
</code></pre>
<p>启动</p>
<pre><code class="sh">redis-server 7004/redis.conf
</code></pre>
<h4 id="③-添加新的节点到redis"><a href="#③-添加新的节点到redis" class="headerlink" title="③ 添加新的节点到redis"></a>③ 添加新的节点到redis</h4><p>执行命令：</p>
<pre><code class="sh">redis-cli --cluster add-node  192.168.150.101:7004 192.168.150.101:7001
</code></pre>
<p>通过命令查看集群状态：</p>
<pre><code class="sh">redis-cli -p 7001 cluster nodes
</code></pre>
<p>7004加入了集群，并且默认是一个master节点，但是，可以看到7004节点的插槽数量为0，因此没有任何数据可以存储到7004上。</p>
<h4 id="④-转移插槽"><a href="#④-转移插槽" class="headerlink" title="④ 转移插槽"></a>④ 转移插槽</h4><p>我们要将num存储到7004节点，因此需要先看看num的插槽是多少：</p>
<pre><code class="sh">get num
</code></pre>
<p>查到num的插槽为2765，将0~3000的插槽从7001转移到7004，命令格式如下：</p>
<pre><code class="sh">redis-cli --cluster reshard 192.168.150.101:7001
</code></pre>
<p>得到反馈：<strong>How many slots do you want to move (from 1 to 16384)?</strong></p>
<p>询问要移动多少个插槽，我们计划是3000个</p>
<p>得到反馈：<strong>What is the receiving node ID?</strong></p>
<p>使用哪个Node来接收这些插槽？</p>
<p>显然是7004，那么7004节点的id是多少呢，复制代码中id，然后拷贝到刚才的控制台后，这里询问，你的插槽是从哪里移动过来的？</p>
<ul>
<li>all：代表全部，也就是三个节点各转移一部分</li>
<li>具体的id：目标节点的id</li>
<li>done：没有了</li>
</ul>
<p>这里我们要从7001获取，因此填写7001的id</p>
<p>填完后，点击done，这样插槽转移就准备好了</p>
<p>确认要转移吗？输入yes</p>
<p>然后，通过命令查看结果：</p>
<pre><code class="sh">redis-cli -p 7001 cluster node
</code></pre>
<h3 id="13-5-4-故障转移"><a href="#13-5-4-故障转移" class="headerlink" title="13.5.4 故障转移"></a>13.5.4 故障转移</h3><h4 id="①-自动故障转移"><a href="#①-自动故障转移" class="headerlink" title="① 自动故障转移"></a>① 自动故障转移</h4><p>当集群中有一个master宕机会发生什么呢？</p>
<p>直接停止一个redis实例，例如7002：</p>
<pre><code class="sh">redis-cli -p 7002 shutdown
</code></pre>
<p>1）首先是该实例与其它实例失去连接</p>
<p>2）然后是疑似宕机</p>
<p>3）最后是确定下线，自动提升一个slave为新的master</p>
<p>4）当7002再次启动，就会变为一个slave节点了</p>
<h4 id="②-手动故障转移"><a href="#②-手动故障转移" class="headerlink" title="② 手动故障转移"></a>② 手动故障转移</h4><p>利用cluster failover命令可以手动让集群中的某个master宕机，切换到执行cluster failover命令的这个slave节点，实现无感知的数据迁移。</p>
<p>这种failover命令可以指定三种模式：</p>
<ul>
<li>缺省：默认的流程，如图1~6歩</li>
<li>force：省略了对offset的一致性校验</li>
<li>takeover：直接执行第5歩，忽略数据一致性、忽略master状态和其它master的意见</li>
</ul>
<p><strong>案例需求</strong>：在7002这个slave节点执行手动故障转移，重新夺回master地位</p>
<p>步骤如下：</p>
<p>1）利用redis-cli连接7002这个节点</p>
<p>2）执行cluster failover命令</p>
<pre><code class="sh">redis-cli -p 7002
CLUSTER FAILOVER
</code></pre>
<h3 id="13-5-5-RedisTemplate访问分片集群"><a href="#13-5-5-RedisTemplate访问分片集群" class="headerlink" title="13.5.5 RedisTemplate访问分片集群"></a>13.5.5 RedisTemplate访问分片集群</h3><p>RedisTemplate底层同样基于lettuce实现了分片集群的支持，而使用的步骤与哨兵模式基本一致：</p>
<p>1）引入redis的starter依赖</p>
<p>2）配置分片集群地址</p>
<p>3）配置读写分离</p>
<p>与哨兵模式相比，其中只有分片集群的配置方式略有差异，如下：</p>
<pre><code class="yaml">spring:
  redis:
    cluster:
      nodes:
        - 192.168.150.101:7001
        - 192.168.150.101:7002
        - 192.168.150.101:7003
        - 192.168.150.101:8001
        - 192.168.150.101:8002
        - 192.168.150.101:8003
</code></pre>
<h1 id="十四、多级缓存"><a href="#十四、多级缓存" class="headerlink" title="十四、多级缓存"></a>十四、多级缓存</h1><p>传统的缓存策略一般是请求到达Tomcat后，先查询Redis，如果未命中则查询数据库</p>
<p>存在下面的问题：</p>
<ul>
<li><p>请求要经过Tomcat处理，Tomcat的性能成为整个系统的瓶颈</p>
</li>
<li><p>Redis缓存失效时，会对数据库产生冲击</p>
</li>
</ul>
<p><strong>多级缓存</strong>就是充分利用请求处理的每个环节，分别添加缓存，减轻Tomcat压力，提升服务性能：</p>
<ul>
<li>浏览器访问静态资源时，优先<strong>读取浏览器本地缓存</strong></li>
<li>访问非静态资源（ajax查询数据）时，访问服务端</li>
<li>请求到达Nginx后，优先<strong>读取Nginx本地缓存</strong></li>
<li>如果Nginx本地缓存未命中，则去直接<strong>查询Redis</strong>（不经过Tomcat）</li>
<li>如果Redis查询未命中，则查询Tomcat</li>
<li>请求进入Tomcat后，优先<strong>查询JVM进程缓存</strong></li>
<li>如果JVM进程缓存未命中，则<strong>查询数据库</strong></li>
</ul>
<p>在多级缓存架构中，Nginx内部需要编写本地缓存查询、Redis查询、Tomcat查询的业务逻辑，因此这样的nginx服务不再是一个<strong>反向代理服务器</strong>，而是一个编写<strong>业务的Web服务器了</strong>。</p>
<p>因此这样的业务Nginx服务也需要搭建集群来提高并发，再有专门的nginx服务来做反向代理。</p>
<p>另外，我们的Tomcat服务将来也会部署为集群模式。</p>
<p>可见，多级缓存的关键有两个：</p>
<ul>
<li>一个是在nginx中编写业务，实现nginx本地缓存、Redis、Tomcat的查询</li>
<li>另一个就是在Tomcat中实现JVM进程缓存</li>
</ul>
<p>其中Nginx编程则会用到OpenResty框架结合Lua这样的语言。</p>
<h2 id="14-1-JVM进程缓存"><a href="#14-1-JVM进程缓存" class="headerlink" title="14.1 JVM进程缓存"></a>14.1 JVM进程缓存</h2><h3 id="14-1-1-案例引入"><a href="#14-1-1-案例引入" class="headerlink" title="14.1.1 案例引入"></a>14.1.1 案例引入</h3><h4 id="①-安装MySQL"><a href="#①-安装MySQL" class="headerlink" title="① 安装MySQL"></a>① 安装MySQL</h4><p>后期做数据同步需要用到MySQL的主从功能，所以需要在虚拟机中，利用Docker来运行一个MySQL容器。</p>
<p>1）为了方便后期配置MySQL，我们先准备两个目录，用于挂载容器的数据和配置文件目录：</p>
<pre><code class="sh"># 进入/tmp目录
cd /tmp
# 创建文件夹
mkdir mysql
# 进入mysql目录
cd mysql
</code></pre>
<p>2）运行命令</p>
<p>进入mysql目录后，执行下面的Docker命令：</p>
<pre><code class="sh">docker run \
 -p 3306:3306 \
 --name mysql \
 -v $PWD/conf:/etc/mysql/conf.d \
 -v $PWD/logs:/logs \
 -v $PWD/data:/var/lib/mysql \
 -e MYSQL_ROOT_PASSWORD=root \
 --privileged \
 -d \
 mysql:5.7.25
</code></pre>
<p>3）修改配置</p>
<p>在&#x2F;tmp&#x2F;mysql&#x2F;conf目录添加一个my.cnf文件，作为mysql的配置文件：</p>
<pre><code class="sh"># 创建文件
touch /tmp/mysql/conf/my.cnf
</code></pre>
<p>文件的内容如下：</p>
<pre><code class="ini">[mysqld]
skip-name-resolve
character_set_server=utf8
datadir=/var/lib/mysql
server-id=1000
</code></pre>
<p>4）重启</p>
<p>配置修改后，必须重启容器：</p>
<pre><code class="sh">docker restart mysql
</code></pre>
<h4 id="②-导入SQL"><a href="#②-导入SQL" class="headerlink" title="② 导入SQL"></a>② 导入SQL</h4><p>接下来，利用Navicat客户端连接MySQL，然后导入sql文件： </p>
<p>其中包含两张表：</p>
<ul>
<li>tb_item：商品表，包含商品的基本信息</li>
<li>tb_item_stock：商品库存表，包含商品的库存信息</li>
</ul>
<p>之所以将库存分离出来，是因为库存是更新比较频繁的信息，写操作较多。而其他信息修改的频率非常低。</p>
<h4 id="③-导入Demo工程"><a href="#③-导入Demo工程" class="headerlink" title="③ 导入Demo工程"></a>③ 导入Demo工程</h4><p>其中的业务包括：</p>
<ul>
<li>分页查询商品</li>
<li>新增商品</li>
<li>修改商品</li>
<li>修改库存</li>
<li>删除商品</li>
<li>根据id查询商品</li>
<li>根据id查询库存</li>
</ul>
<p>业务全部使用mybatis-plus来实现，如有需要请自行修改业务逻辑。</p>
<h3 id="14-1-2-初识Caffeine"><a href="#14-1-2-初识Caffeine" class="headerlink" title="14.1.2 初识Caffeine"></a>14.1.2 初识Caffeine</h3><p>缓存在日常开发中启动至关重要的作用，由于是存储在内存中，数据的读取速度是非常快的，能大量减少对数据库的访问，减少数据库的压力。缓存分为两类：</p>
<ul>
<li>分布式缓存，例如Redis：<ul>
<li>优点：存储容量更大、可靠性更好、可以在集群间共享</li>
<li>缺点：访问缓存有网络开销</li>
<li>场景：缓存数据量较大、可靠性要求较高、需要在集群间共享</li>
</ul>
</li>
<li>进程本地缓存，例如HashMap、GuavaCache：<ul>
<li>优点：读取本地内存，没有网络开销，速度更快</li>
<li>缺点：存储容量有限、可靠性较低、无法共享</li>
<li>场景：性能要求较高，缓存数据量较小</li>
</ul>
</li>
</ul>
<p>利用Caffeine框架来实现JVM进程缓存。</p>
<p><strong>Caffeine</strong>是一个基于Java8开发的，提供了近乎最佳命中率的高性能的本地缓存库。目前Spring内部的缓存使用的就是Caffeine。GitHub地址：<a target="_blank" rel="noopener" href="https://github.com/ben-manes/caffeine">https://github.com/ben-manes/caffeine</a></p>
<p>pom依赖</p>
<pre><code class="xml">        &lt;dependency&gt;
            &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt;
            &lt;artifactId&gt;caffeine&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>
<p>缓存使用的基本API：</p>
<pre><code class="java">@Test
void testBasicOps() &#123;
    // 构建cache对象
    Cache&lt;String, String&gt; cache = Caffeine.newBuilder().build();

    // 存数据
    cache.put(&quot;gf&quot;, &quot;迪丽热巴&quot;);

    // 取数据
    String gf = cache.getIfPresent(&quot;gf&quot;);
    System.out.println(&quot;gf = &quot; + gf);

    // 取数据，包含两个参数：
    // 参数一：缓存的key
    // 参数二：Lambda表达式，表达式参数就是缓存的key，方法体是查询数据库的逻辑
    // 优先根据key查询JVM缓存，如果未命中，则执行参数二的Lambda表达式
    String defaultGF = cache.get(&quot;defaultGF&quot;, key -&gt; &#123;
        // 根据key去数据库查询数据
        return &quot;柳岩&quot;;
    &#125;);
    System.out.println(&quot;defaultGF = &quot; + defaultGF);
&#125;
</code></pre>
<p>Caffeine既然是缓存的一种，肯定需要有缓存的清除策略，不然的话内存总会有耗尽的时候。</p>
<p>Caffeine提供了三种缓存驱逐策略：</p>
<ul>
<li><p><strong>基于容量</strong>：设置缓存的数量上限</p>
<pre><code class="java">// 创建缓存对象
Cache&lt;String, String&gt; cache = Caffeine.newBuilder()
    .maximumSize(1) // 设置缓存大小上限为 1
    .build();
</code></pre>
</li>
<li><p><strong>基于时间</strong>：设置缓存的有效时间</p>
<pre><code class="java">// 创建缓存对象
Cache&lt;String, String&gt; cache = Caffeine.newBuilder()
    // 设置缓存有效期为 10 秒，从最后一次写入开始计时 
    .expireAfterWrite(Duration.ofSeconds(10)) 
    .build();
</code></pre>
</li>
<li><p><strong>基于引用</strong>：设置缓存为软引用或弱引用，利用GC来回收缓存数据。性能较差，不建议使用。</p>
</li>
</ul>
<blockquote>
<p><strong>注意</strong>：在默认情况下，当一个缓存元素过期的时候，Caffeine不会自动立即将其清理和驱逐。而是在一次读或写操作后，或者在空闲时间完成对失效数据的驱逐。</p>
</blockquote>
<h3 id="14-1-3-实现JVM进程缓存"><a href="#14-1-3-实现JVM进程缓存" class="headerlink" title="14.1.3 实现JVM进程缓存"></a>14.1.3 实现JVM进程缓存</h3><h4 id="①-需求"><a href="#①-需求" class="headerlink" title="① 需求"></a>① 需求</h4><p>利用Caffeine实现下列需求：</p>
<ul>
<li>给根据id查询商品的业务添加缓存，缓存未命中时查询数据库</li>
<li>给根据id查询商品库存的业务添加缓存，缓存未命中时查询数据库</li>
<li>缓存初始大小为100</li>
<li>缓存上限为10000</li>
</ul>
<h4 id="②-实现"><a href="#②-实现" class="headerlink" title="② 实现"></a>② 实现</h4><p>首先，我们需要定义两个Caffeine的缓存对象，分别保存商品、库存的缓存数据。</p>
<p>在item-service的<code>com.heima.item.config</code>包下定义<code>CaffeineConfig</code>类：</p>
<pre><code class="java">package com.heima.item.config;

import com.github.benmanes.caffeine.cache.Cache;
import com.github.benmanes.caffeine.cache.Caffeine;
import com.heima.item.pojo.Item;
import com.heima.item.pojo.ItemStock;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class CaffeineConfig &#123;

    @Bean
    public Cache&lt;Long, Item&gt; itemCache()&#123;
        return Caffeine.newBuilder()
                .initialCapacity(100)
                .maximumSize(10_000)
                .build();
    &#125;

    @Bean
    public Cache&lt;Long, ItemStock&gt; stockCache()&#123;
        return Caffeine.newBuilder()
                .initialCapacity(100)
                .maximumSize(10_000)
                .build();
    &#125;
&#125;
</code></pre>
<p>然后，修改item-service中的<code>com.heima.item.web</code>包下的ItemController类，添加缓存逻辑：</p>
<pre><code class="java">@RestController
@RequestMapping(&quot;item&quot;)
public class ItemController &#123;

    @Autowired
    private IItemService itemService;
    @Autowired
    private IItemStockService stockService;

    @Autowired
    private Cache&lt;Long, Item&gt; itemCache;
    @Autowired
    private Cache&lt;Long, ItemStock&gt; stockCache;
    
    // ...其它略
    
    @GetMapping(&quot;/&#123;id&#125;&quot;)
    public Item findById(@PathVariable(&quot;id&quot;) Long id) &#123;
        return itemCache.get(id, key -&gt; itemService.query()
                .ne(&quot;status&quot;, 3).eq(&quot;id&quot;, key)
                .one()
        );
    &#125;

    @GetMapping(&quot;/stock/&#123;id&#125;&quot;)
    public ItemStock findStockById(@PathVariable(&quot;id&quot;) Long id) &#123;
        return stockCache.get(id, key -&gt; stockService.getById(key));
    &#125;
&#125;
</code></pre>
<h2 id="14-2-Lua语法入门"><a href="#14-2-Lua语法入门" class="headerlink" title="14.2 Lua语法入门"></a>14.2 Lua语法入门</h2><p>Nginx编程需要用到Lua语言，因此我们必须先入门Lua的基本语法。</p>
<h3 id="14-2-1-初识Lua"><a href="#14-2-1-初识Lua" class="headerlink" title="14.2.1 初识Lua"></a>14.2.1 初识Lua</h3><p>Lua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。官网：<a target="_blank" rel="noopener" href="https://www.lua.org/">https://www.lua.org/</a></p>
<p>Lua经常嵌入到C语言开发的程序中，例如游戏开发、游戏插件等。</p>
<p>Nginx本身也是C语言开发，因此也允许基于Lua做拓展。</p>
<h3 id="14-2-2-HelloWorld"><a href="#14-2-2-HelloWorld" class="headerlink" title="14.2.2 HelloWorld"></a>14.2.2 HelloWorld</h3><p>CentOS7默认已经安装了Lua语言环境，所以可以直接运行Lua代码。</p>
<p>1）在Linux虚拟机的任意目录下，新建一个hello.lua文件</p>
<pre><code class="sh">touch hello.lua
</code></pre>
<p>2）添加下面的内容</p>
<pre><code class="lua">print(&quot;Hello World!&quot;)  
</code></pre>
<p>3）运行</p>
<pre><code class="sh">lua hello.lua
</code></pre>
<p>14.2.3 量和循环</p>
<p>学习任何语言必然离不开变量，而变量的声明必须先知道数据的类型。</p>
<h3 id="14-2-3-变量和循环"><a href="#14-2-3-变量和循环" class="headerlink" title="14.2.3 变量和循环"></a>14.2.3 变量和循环</h3><h4 id="①-Lua的数据类型"><a href="#①-Lua的数据类型" class="headerlink" title="① Lua的数据类型"></a>① Lua的数据类型</h4><p>Lua中支持的常见数据类型包括：</p>
<table>
<thead>
<tr>
<th>数据类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>nil</td>
<td>只有值nil属于该类，表示一个无效值（在条件表达式中相当于false）</td>
</tr>
<tr>
<td>boolean</td>
<td>包含两个值：false和true</td>
</tr>
<tr>
<td>number</td>
<td>表示双精度类型的实浮点数</td>
</tr>
<tr>
<td>string</td>
<td>字符串由一对双引号或单引号来表示</td>
</tr>
<tr>
<td>function</td>
<td>由 C 或 Lua 编写的函数</td>
</tr>
<tr>
<td>table</td>
<td>Lua中表（table）其实是一个”关联数组”(associative arrays)，数组的索引可以是数字、字符串或表类型。在Lua中，table的创建是通过”构造表达式”来完成，最简单的构造表达式是{ }，用来创建一个空表。</td>
</tr>
</tbody></table>
<p>另外，Lua提供了type()函数来判断一个变量的数据类型：</p>
<pre><code class="lua">print(type(10*3.4))
</code></pre>
<h4 id="②-声明变量"><a href="#②-声明变量" class="headerlink" title="② 声明变量"></a>② 声明变量</h4><p>Lua声明变量的时候无需指定数据类型，而是用local来声明变量为局部变量：</p>
<pre><code class="lua">-- 声明字符串，可以用单引号或双引号，
local str = &#39;hello&#39;
-- 字符串拼接可以使用 ..
local str2 = &#39;hello&#39; .. &#39;world&#39;
-- 声明数字
local num = 21
-- 声明布尔类型
local flag = true
</code></pre>
<p>Lua中的table类型既可以作为数组，又可以作为Java中的map来使用。数组就是特殊的table，key是数组角标而已：</p>
<pre><code class="lua">-- 声明数组 ，key为角标的 table
local arr = &#123;&#39;java&#39;, &#39;python&#39;, &#39;lua&#39;&#125;
-- 声明table，类似java的map
local map =  &#123;name=&#39;Jack&#39;, age=21&#125;
</code></pre>
<p>Lua中的数组角标是从1开始，访问的时候与Java中类似：</p>
<pre><code class="lua">-- 访问数组，lua数组的角标从1开始
print(arr[1])
</code></pre>
<p>Lua中的table可以用key来访问：</p>
<pre><code class="lua">-- 访问table
print(map[&#39;name&#39;])
print(map.name)
</code></pre>
<h4 id="③-循环"><a href="#③-循环" class="headerlink" title="③ 循环"></a>③ 循环</h4><p>对于table，我们可以利用for循环来遍历。不过数组和普通table遍历略有差异。</p>
<p>遍历数组：</p>
<pre><code class="lua">-- 声明数组 key为索引的 table
local arr = &#123;&#39;java&#39;, &#39;python&#39;, &#39;lua&#39;&#125;
-- 遍历数组
for index,value in ipairs(arr) do
    print(index, value) 
end
</code></pre>
<p>遍历普通table</p>
<pre><code class="lua">-- 声明map，也就是table
local map = &#123;name=&#39;Jack&#39;, age=21&#125;
-- 遍历table
for key,value in pairs(map) do
   print(key, value) 
end
</code></pre>
<h3 id="14-2-4-条件控制、函数"><a href="#14-2-4-条件控制、函数" class="headerlink" title="14.2.4 条件控制、函数"></a>14.2.4 条件控制、函数</h3><p>Lua中的条件控制和函数声明与Java类似。</p>
<h4 id="①-函数"><a href="#①-函数" class="headerlink" title="① 函数"></a>① 函数</h4><p>定义函数的语法：</p>
<pre><code class="lua">function 函数名( argument1, argument2..., argumentn)
    -- 函数体
    return 返回值
end
</code></pre>
<p>例如，定义一个函数，用来打印数组：</p>
<pre><code class="lua">function printArr(arr)
    for index, value in ipairs(arr) do
        print(value)
    end
end
</code></pre>
<h4 id="②-条件控制"><a href="#②-条件控制" class="headerlink" title="② 条件控制"></a>② 条件控制</h4><p>类似Java的条件控制，例如if、else语法：</p>
<pre><code class="lua">if(布尔表达式)
then
   --[ 布尔表达式为 true 时执行该语句块 --]
else
   --[ 布尔表达式为 false 时执行该语句块 --]
end
</code></pre>
<p>与java不同，布尔表达式中的逻辑运算是基于英文单词：</p>
<table>
<thead>
<tr>
<th>and</th>
<th>or</th>
<th>not</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h4 id="③-实例"><a href="#③-实例" class="headerlink" title="③ 实例"></a>③ 实例</h4><p>需求：自定义一个函数，可以打印table，当参数为nil时，打印错误信息</p>
<pre><code class="lua">function printArr(arr)
    if not arr then
        print(&#39;数组不能为空！&#39;)
    end
    for index, value in ipairs(arr) do
        print(value)
    end
end
</code></pre>
<h2 id="14-3-实现多级缓存"><a href="#14-3-实现多级缓存" class="headerlink" title="14.3 实现多级缓存"></a>14.3 实现多级缓存</h2><p>多级缓存的实现离不开Nginx编程，而Nginx编程又离不开OpenResty。</p>
<h3 id="14-3-1-安装OpenResty"><a href="#14-3-1-安装OpenResty" class="headerlink" title="14.3.1 安装OpenResty"></a>14.3.1 安装OpenResty</h3><p>OpenResty® 是一个基于 Nginx的高性能 Web 平台，用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。具备下列特点：</p>
<ul>
<li>具备Nginx的完整功能</li>
<li>基于Lua语言进行扩展，集成了大量精良的 Lua 库、第三方模块</li>
<li>允许使用Lua<strong>自定义业务逻辑</strong>、<strong>自定义库</strong></li>
</ul>
<p>官方网站： <a target="_blank" rel="noopener" href="https://openresty.org/cn/">https://openresty.org/cn/</a></p>
<h4 id="①-安装开发库"><a href="#①-安装开发库" class="headerlink" title="① 安装开发库"></a>① 安装开发库</h4><p>首先要安装OpenResty的依赖开发库，执行命令：</p>
<pre><code class="sh">yum install -y pcre-devel openssl-devel gcc --skip-broken
</code></pre>
<h4 id="②-安装OpenResty仓库"><a href="#②-安装OpenResty仓库" class="headerlink" title="② 安装OpenResty仓库"></a>② 安装OpenResty仓库</h4><p>可以在 CentOS 系统中添加 <code>openresty</code> 仓库，这样就可以便于未来安装或更新的软件包（通过 <code>yum check-update</code> 命令）。运行下面的命令就可以添加仓库：</p>
<pre><code>yum-config-manager --add-repo https://openresty.org/package/centos/openresty.repo
</code></pre>
<p>如果提示说命令不存在，则运行：</p>
<pre><code>yum install -y yum-utils 
</code></pre>
<p>然后再重复上面的命令</p>
<h4 id="③-安装OpenResty"><a href="#③-安装OpenResty" class="headerlink" title="③ 安装OpenResty"></a>③ 安装OpenResty</h4><p>安装软件包，比如 <code>openresty</code>：</p>
<pre><code class="bash">yum install -y openresty
</code></pre>
<h4 id="④-安装opm工具"><a href="#④-安装opm工具" class="headerlink" title="④ 安装opm工具"></a>④ 安装opm工具</h4><p>opm是OpenResty的一个管理工具，可以帮助我们安装一个第三方的Lua模块。</p>
<p>如果你想安装命令行工具 <code>opm</code>，那么可以像下面这样安装 <code>openresty-opm</code> 包：</p>
<pre><code class="bash">yum install -y openresty-opm
</code></pre>
<h4 id="⑤-配置nginx的环境变量"><a href="#⑤-配置nginx的环境变量" class="headerlink" title="⑤ 配置nginx的环境变量"></a>⑤ 配置nginx的环境变量</h4><p>默认情况下，OpenResty安装的目录是：<code>/usr/local/openresty</code>，OpenResty就是在Nginx基础上集成了一些Lua模块。</p>
<p><strong>配置后可在任意目录执行</strong></p>
<p>打开配置文件：</p>
<pre><code class="sh">vi /etc/profile
</code></pre>
<p>在最下面加入两行：</p>
<pre><code class="sh">export NGINX_HOME=/usr/local/openresty/nginx
export PATH=$&#123;NGINX_HOME&#125;/sbin:$PATH
</code></pre>
<p>NGINX_HOME：后面是OpenResty安装目录下的nginx的目录</p>
<p>然后让配置生效：</p>
<pre><code>source /etc/profile
</code></pre>
<h4 id="⑥-启动和运行"><a href="#⑥-启动和运行" class="headerlink" title="⑥ 启动和运行"></a>⑥ 启动和运行</h4><p>OpenResty底层是基于Nginx的，查看OpenResty目录的nginx目录，结构与windows中安装的nginx基本一致：</p>
<pre><code class="sh"># 启动nginx
nginx
# 重新加载配置
nginx -s reload
# 停止
nginx -s stop
</code></pre>
<p>nginx的默认配置文件注释太多，影响后续我们的编辑，这里将nginx.conf中的注释部分删除，保留有效部分。</p>
<p>修改<code>/usr/local/openresty/nginx/conf/nginx.conf</code>文件，内容如下：</p>
<pre><code class="nginx">#user  nobody;
worker_processes  1;
error_log  logs/error.log;

events &#123;
    worker_connections  1024;
&#125;

http &#123;
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;
    keepalive_timeout  65;

    server &#123;
        listen       8081;
        server_name  localhost;
        location / &#123;
            root   html;
            index  index.html index.htm;
        &#125;
        error_page   500 502 503 504  /50x.html;
        location = /50x.html &#123;
            root   html;
        &#125;
    &#125;
&#125;
</code></pre>
<p>在Linux的控制台输入命令以启动nginx：</p>
<pre><code class="sh">nginx
</code></pre>
<p>然后访问页面：<a target="_blank" rel="noopener" href="http://192.168.150.101:8081/">http://192.168.150.101:8081</a>，注意ip地址替换为你自己的虚拟机IP</p>
<h4 id="⑦-备注"><a href="#⑦-备注" class="headerlink" title="⑦ 备注"></a>⑦ 备注</h4><p>加载OpenResty的lua模块：</p>
<pre><code class="nginx">#lua 模块
lua_package_path &quot;/usr/local/openresty/lualib/?.lua;;&quot;;
#c模块     
lua_package_cpath &quot;/usr/local/openresty/lualib/?.so;;&quot;;  
</code></pre>
<p>common.lua</p>
<pre><code class="lua">-- 封装函数，发送http请求，并解析响应
local function read_http(path, params)
    local resp = ngx.location.capture(path,&#123;
        method = ngx.HTTP_GET,
        args = params,
    &#125;)
    if not resp then
        -- 记录错误信息，返回404
        ngx.log(ngx.ERR, &quot;http not found, path: &quot;, path , &quot;, args: &quot;, args)
        ngx.exit(404)
    end
    return resp.body
end
-- 将方法导出
local _M = &#123;  
    read_http = read_http
&#125;  
return _M
</code></pre>
<p>释放Redis连接API：</p>
<pre><code class="lua">-- 关闭redis连接的工具方法，其实是放入连接池
local function close_redis(red)
    local pool_max_idle_time = 10000 -- 连接的空闲时间，单位是毫秒
    local pool_size = 100 --连接池大小
    local ok, err = red:set_keepalive(pool_max_idle_time, pool_size)
    if not ok then
        ngx.log(ngx.ERR, &quot;放入redis连接池失败: &quot;, err)
    end
end
</code></pre>
<p>读取Redis数据的API：</p>
<pre><code class="lua">-- 查询redis的方法 ip和port是redis地址，key是查询的key
local function read_redis(ip, port, key)
    -- 获取一个连接
    local ok, err = red:connect(ip, port)
    if not ok then
        ngx.log(ngx.ERR, &quot;连接redis失败 : &quot;, err)
        return nil
    end
    -- 查询redis
    local resp, err = red:get(key)
    -- 查询失败处理
    if not resp then
        ngx.log(ngx.ERR, &quot;查询Redis失败: &quot;, err, &quot;, key = &quot; , key)
    end
    --得到的数据为空处理
    if resp == ngx.null then
        resp = nil
        ngx.log(ngx.ERR, &quot;查询Redis数据为空, key = &quot;, key)
    end
    close_redis(red)
    return resp
end
</code></pre>
<p>开启共享词典：</p>
<pre><code class="nginx"># 共享字典，也就是本地缓存，名称叫做：item_cache，大小150m
lua_shared_dict item_cache 150m; 
</code></pre>
<h3 id="14-3-2-OpenResty快速入门"><a href="#14-3-2-OpenResty快速入门" class="headerlink" title="14.3.2 OpenResty快速入门"></a>14.3.2 OpenResty快速入门</h3><h4 id="①-反向代理流程"><a href="#①-反向代理流程" class="headerlink" title="① 反向代理流程"></a>① 反向代理流程</h4><ul>
<li>windows上的nginx用来做反向代理服务，将前端的查询商品的ajax请求代理到OpenResty集群</li>
<li>OpenResty集群用来编写多级缓存业务</li>
</ul>
<p>页面有发起ajax请求查询真实商品数据</p>
<ul>
<li>Method：GET</li>
<li>URL：<a target="_blank" rel="noopener" href="http://localhost/api/item/1001">http://localhost/api/item/1001</a></li>
</ul>
<p>请求地址是localhost，端口是80，就被windows上安装的Nginx服务给接收到了。然后代理给了OpenResty集群</p>
<pre><code class="bash">    # OpenResty集群，在虚拟机中，实现多级缓存业务
    upstream nginx-cluster&#123;
        server 192.168.150.101:8081;
        server 192.168.150.101:8082;
    &#125;
    server &#123;
        listen       80;
        server_name  localhost;

    location /api &#123;
            proxy_pass http://nginx-cluster;
        &#125;
</code></pre>
<p>我们需要在OpenResty中编写业务，查询商品数据并返回到浏览器。</p>
<p>但是这次，我们先在OpenResty接收请求，返回假的商品数据。</p>
<h4 id="②-OpenResty监听请求【模拟数据，静态】"><a href="#②-OpenResty监听请求【模拟数据，静态】" class="headerlink" title="② OpenResty监听请求【模拟数据，静态】"></a>② OpenResty监听请求【模拟数据，静态】</h4><p>OpenResty的很多功能都依赖于其目录下的Lua库，需要在nginx.conf中指定依赖库的目录，并导入依赖：</p>
<p>1）添加对OpenResty的Lua模块的加载</p>
<p>修改<code>/usr/local/openresty/nginx/conf/nginx.conf</code>文件，在其中的http下面，添加下面代码：</p>
<pre><code class="nginx">#lua 模块
lua_package_path &quot;/usr/local/openresty/lualib/?.lua;;&quot;;
#c模块     
lua_package_cpath &quot;/usr/local/openresty/lualib/?.so;;&quot;;
</code></pre>
<p>2）监听&#x2F;api&#x2F;item路径</p>
<p>修改<code>/usr/local/openresty/nginx/conf/nginx.conf</code>文件，在nginx.conf的server下面，添加对&#x2F;api&#x2F;item这个路径的监听：</p>
<pre><code class="nginx">location  /api/item &#123;
    # 默认的响应类型
    default_type application/json;
    # 响应结果由lua/item.lua文件来决定
    content_by_lua_file lua/item.lua;
&#125;
</code></pre>
<p>这个监听，就类似于SpringMVC中的<code>@GetMapping(&quot;/api/item&quot;)</code>做路径映射。</p>
<p>而<code>content_by_lua_file lua/item.lua</code>则相当于调用item.lua这个文件，执行其中的业务，把结果返回给用户。相当于java中调用service。</p>
<p>③ 编写item.lua</p>
<p>1）在<code>/usr/loca/openresty/nginx</code>目录创建文件夹：lua</p>
<pre><code class="sh">mkdir lua
</code></pre>
<p>2）在<code>/usr/loca/openresty/nginx/lua</code>文件夹下，新建文件：item.lua</p>
<pre><code class="sh">touch item.lua
</code></pre>
<p>3）编写item.lua，返回假数据</p>
<p>item.lua中，利用ngx.say()函数返回数据到Response中</p>
<pre><code class="lua">ngx.say(&#39;&#123;&quot;id&quot;:10001,&quot;name&quot;:&quot;SALSA AIR&quot;,&quot;title&quot;:&quot;RIMOWA 21寸托运箱拉杆箱 SALSA AIR系列果绿色 820.70.36.4&quot;,&quot;price&quot;:17900,&quot;image&quot;:&quot;https://m.360buyimg.com/mobilecms/s720x720_jfs/t6934/364/1195375010/84676/e9f2c55f/597ece38N0ddcbc77.jpg!q70.jpg.webp&quot;,&quot;category&quot;:&quot;拉杆箱&quot;,&quot;brand&quot;:&quot;RIMOWA&quot;,&quot;spec&quot;:&quot;&quot;,&quot;status&quot;:1,&quot;createTime&quot;:&quot;2019-04-30T16:00:00.000+00:00&quot;,&quot;updateTime&quot;:&quot;2019-04-30T16:00:00.000+00:00&quot;,&quot;stock&quot;:2999,&quot;sold&quot;:31290&#125;&#39;)
</code></pre>
<p>4）重新加载配置</p>
<pre><code class="sh">nginx -s reload
</code></pre>
<p>刷新商品页面：<a target="_blank" rel="noopener" href="http://localhost/item.html?id=10001%EF%BC%8C%E5%8D%B3%E5%8F%AF%E7%9C%8B%E5%88%B0%E6%95%88%E6%9E%9C">http://localhost/item.html?id=10001，即可看到效果</a></p>
<h3 id="14-3-3-请求参数处理"><a href="#14-3-3-请求参数处理" class="headerlink" title="14.3.3 请求参数处理"></a>14.3.3 请求参数处理</h3><p>上一节中，我们在OpenResty接收前端请求，但是返回的是假数据。</p>
<p>要返回真实数据，必须根据前端传递来的商品id，查询商品信息才可以。</p>
<p>那么如何获取前端传递的商品参数呢？</p>
<h4 id="①-获取参数的API"><a href="#①-获取参数的API" class="headerlink" title="① 获取参数的API"></a>① 获取参数的API</h4><p>OpenResty中提供了一些API用来获取不同类型的前端请求参数：</p>
<table>
<thead>
<tr>
<th align="center">参数格式</th>
<th align="center">参数示例</th>
<th>参数解析代码示例</th>
</tr>
</thead>
<tbody><tr>
<td align="center">路径占位符</td>
<td align="center">&#x2F;item&#x2F;1001</td>
<td># 1.正则表达式匹配：<br />location ~ &#x2F;item&#x2F;(\d+) {<br />content_by_lua_file lua&#x2F;item.lua<br />}<br /># 2.匹配到的参数会存入ngx.var数组中，可以使用角标获取<br />local id &#x3D; ngx.var[1]</td>
</tr>
<tr>
<td align="center">请求头</td>
<td align="center">id:1001</td>
<td># 获取请求头，返回值是table类型<br />local headers &#x3D; ngx.req.get_headers()</td>
</tr>
<tr>
<td align="center">Get请求参数</td>
<td align="center">?id&#x3D;1001</td>
<td># 获取Get请求参数，返回值是table类型<br />local getParams &#x3D; ngx.req.get_uri_args()</td>
</tr>
<tr>
<td align="center">Post表单参数</td>
<td align="center">id&#x3D;1001</td>
<td># 读取请求体<br />ngx.req.read_body()<br /># 获取post表单参数，返回值是table类型<br />local postParams &#x3D; ngx.req.get_post_args()</td>
</tr>
<tr>
<td align="center">JSON参数</td>
<td align="center">{“id”:1001}</td>
<td># 读取请求体<br />ngx.req.read_body()<br /># 获取body中的json参数，返回值是string类型<br />local jsonBody &#x3D; ngx.req.get_body_data()</td>
</tr>
</tbody></table>
<h4 id="②-获取参数并返回"><a href="#②-获取参数并返回" class="headerlink" title="② 获取参数并返回"></a>② 获取参数并返回</h4><p>在前端发起的ajax请求：GET：<a target="_blank" rel="noopener" href="http://localhost/api/item/10001">http://localhost/api/item/10001</a></p>
<p>商品id是以路径占位符方式传递的，因此可以利用正则表达式匹配的方式来获取ID</p>
<p>1）获取商品id</p>
<p>修改<code>/usr/loca/openresty/nginx/nginx.conf</code>文件中监听&#x2F;api&#x2F;item的代码，利用正则表达式获取ID：</p>
<pre><code class="nginx">location ~ /api/item/(\d+) &#123;
    # 默认的响应类型
    default_type application/json;
    # 响应结果由lua/item.lua文件来决定
    content_by_lua_file lua/item.lua;
&#125;
</code></pre>
<p>2）拼接ID并返回</p>
<p>修改<code>/usr/loca/openresty/nginx/lua/item.lua</code>文件，获取id并拼接到结果中返回：</p>
<pre><code class="lua">-- 获取商品id
local id = ngx.var[1]
-- 拼接并返回
ngx.say(&#39;&#123;&quot;id&quot;:&#39; .. id .. &#39;,&quot;name&quot;:&quot;SALSA AIR&quot;,&quot;title&quot;:&quot;RIMOWA 21寸托运箱拉杆箱 SALSA AIR系列果绿色 820.70.36.4&quot;,&quot;price&quot;:17900,&quot;image&quot;:&quot;https://m.360buyimg.com/mobilecms/s720x720_jfs/t6934/364/1195375010/84676/e9f2c55f/597ece38N0ddcbc77.jpg!q70.jpg.webp&quot;,&quot;category&quot;:&quot;拉杆箱&quot;,&quot;brand&quot;:&quot;RIMOWA&quot;,&quot;spec&quot;:&quot;&quot;,&quot;status&quot;:1,&quot;createTime&quot;:&quot;2019-04-30T16:00:00.000+00:00&quot;,&quot;updateTime&quot;:&quot;2019-04-30T16:00:00.000+00:00&quot;,&quot;stock&quot;:2999,&quot;sold&quot;:31290&#125;&#39;)
</code></pre>
<p>3）重新加载并测试</p>
<p>运行命令以重新加载OpenResty配置：</p>
<pre><code class="sh">nginx -s reload
</code></pre>
<p>刷新页面可以看到结果中已经带上了ID</p>
<h3 id="14-3-4-查询Tomcat"><a href="#14-3-4-查询Tomcat" class="headerlink" title="14.3.4 查询Tomcat"></a>14.3.4 查询Tomcat</h3><p>拿到商品ID后，本应去缓存中查询商品信息，不过目前我们还未建立nginx、redis缓存。因此，这里我们先根据商品id去tomcat查询商品信息。</p>
<p>需要注意的是，我们的OpenResty是在虚拟机，Tomcat是在Windows电脑上。两者IP一定不要搞错了。</p>
<ul>
<li>OpenResty的ip是192.168.49.10</li>
<li>本机ip地址取前三位：192.168.150.1即可，需要关闭防火墙</li>
</ul>
<h4 id="①-发送http请求的API"><a href="#①-发送http请求的API" class="headerlink" title="① 发送http请求的API"></a>① 发送http请求的API</h4><p>nginx提供了内部API用以发送http请求：</p>
<pre><code class="lua">local resp = ngx.location.capture(&quot;/path&quot;,&#123;
    method = ngx.HTTP_GET,   -- 请求方式
    args = &#123;a=1,b=2&#125;,  -- get方式传参数
&#125;)
</code></pre>
<p>返回的响应内容包括：</p>
<ul>
<li>resp.status：响应状态码</li>
<li>resp.header：响应头，是一个table</li>
<li>resp.body：响应体，就是响应数据</li>
</ul>
<p>注意：这里的path是路径，并不包含IP和端口。这个请求会被nginx内部的server监听并处理。</p>
<p>但是我们希望这个请求发送到Tomcat服务器，所以还需要编写一个server来对这个路径做反向代理：</p>
<pre><code class="nginx"> location /path &#123;
     # 这里是windows电脑的ip和Java服务端口，需要确保windows防火墙处于关闭状态
     proxy_pass http://192.168.49.1:8081; 
 &#125;
</code></pre>
<h4 id="②-封装http工具"><a href="#②-封装http工具" class="headerlink" title="② 封装http工具"></a>② 封装http工具</h4><p>下面，我们封装一个发送Http请求的工具，基于ngx.location.capture来实现查询tomcat。</p>
<p>1）添加反向代理，到windows的Java服务</p>
<p>因为item-service中的接口都是&#x2F;item开头，所以我们监听&#x2F;item路径，代理到windows上的tomcat服务。</p>
<p>修改 <code>/usr/local/openresty/nginx/conf/nginx.conf</code>文件，添加一个location：</p>
<pre><code class="nginx">location /item &#123;
    proxy_pass http://192.168.49.1:8081;
&#125;
</code></pre>
<p>以后，只要我们调用<code>ngx.location.capture(&quot;/item&quot;)</code>，就一定能发送请求到windows的tomcat服务。</p>
<p>2）封装工具类</p>
<p>之前我们说过，OpenResty启动时会加载以下两个目录中的工具文件：</p>
<pre><code class="sh">#lua 模块
lua_package_path &quot;/usr/local/openresty/lualib/?.lua;;&quot;;
#c模块     
lua_package_cpath &quot;/usr/local/openresty/lualib/?.so;;&quot;;  
</code></pre>
<p>所以，自定义的http工具也需要放到这个目录下。</p>
<p>在<code>/usr/local/openresty/lualib</code>目录下，新建一个common.lua文件：</p>
<pre><code class="sh">vi /usr/local/openresty/lualib/common.lua
</code></pre>
<p>内容如下:</p>
<pre><code class="lua">-- 封装函数，发送http请求，并解析响应
local function read_http(path, params)
    local resp = ngx.location.capture(path,&#123;
        method = ngx.HTTP_GET,
        args = params,
    &#125;)
    if not resp then
        -- 记录错误信息，返回404
        ngx.log(ngx.ERR, &quot;http请求查询失败, path: &quot;, path , &quot;, args: &quot;, args)
        ngx.exit(404)
    end
    return resp.body
end
-- 将方法导出
local _M = &#123;  
    read_http = read_http
&#125;  
return _M
</code></pre>
<p>这个工具将read_http函数封装到_M这个table类型的变量中，并且返回，这类似于导出。</p>
<p>使用的时候，可以利用<code>require(&#39;common&#39;)</code>来导入该函数库，这里的common是函数库的文件名。</p>
<p>3）实现商品查询</p>
<p>最后，我们修改<code>/usr/local/openresty/lua/item.lua</code>文件，利用刚刚封装的函数库实现对tomcat的查询：</p>
<pre><code class="lua">-- 引入自定义common工具模块，返回值是common中返回的 _M
local common = require(&quot;common&quot;)
-- 从 common中获取read_http这个函数
local read_http = common.read_http
-- 获取路径参数
local id = ngx.var[1]
-- 根据id查询商品
local itemJSON = read_http(&quot;/item/&quot;.. id, nil)
-- 根据id查询商品库存
local itemStockJSON = read_http(&quot;/item/stock/&quot;.. id, nil)
</code></pre>
<p>这里查询到的结果是json字符串，并且包含商品、库存两个json字符串，页面最终需要的是把两个json拼接为一个json，这就需要我们先把JSON变为lua的table，完成数据整合后，再转为JSON。</p>
<h4 id="③-CJSON工具类"><a href="#③-CJSON工具类" class="headerlink" title="③ CJSON工具类"></a>③ CJSON工具类</h4><p>OpenResty提供了一个cjson的模块用来处理JSON的序列化和反序列化。</p>
<p>官方地址： <a target="_blank" rel="noopener" href="https://github.com/openresty/lua-cjson/">https://github.com/openresty/lua-cjson/</a></p>
<p>1）引入cjson模块：</p>
<pre><code class="lua">local cjson = require &quot;cjson&quot;
</code></pre>
<p>2）序列化：</p>
<pre><code class="lua">local obj = &#123;
    name = &#39;jack&#39;,
    age = 21
&#125;
-- 把 table 序列化为 json
local json = cjson.encode(obj)
</code></pre>
<p>3）反序列化：</p>
<pre><code class="lua">local json = &#39;&#123;&quot;name&quot;: &quot;jack&quot;, &quot;age&quot;: 21&#125;&#39;
-- 反序列化 json为 table
local obj = cjson.decode(json);
print(obj.name)
</code></pre>
<h4 id="④-实现Tomcat查询"><a href="#④-实现Tomcat查询" class="headerlink" title="④ 实现Tomcat查询"></a>④ 实现Tomcat查询</h4><p>下面，我们修改之前的item.lua中的业务，添加json处理功能：</p>
<pre><code class="lua">-- 导入common函数库
local common = require(&#39;common&#39;)
local read_http = common.read_http
-- 导入cjson库
local cjson = require(&#39;cjson&#39;)

-- 获取路径参数
local id = ngx.var[1]

-- 查询商品信息
local itemJSON = read_http(&quot;/item/&quot; .. id, nil)
-- 查询库存信息
local stockJSON = read_http(&quot;/item/stock/&quot; .. id, nil)

-- JSON转化为lua的table
local item = cjson.decode(itemJSON)
local stock = cjson.decode(stockJSON)

-- 组合数据
item.stock = stock.stock
item.sold = stock.sold

-- 把item序列化为json返回结果
ngx.say(cjson.encode(item))
</code></pre>
<h4 id="⑤-基于ID负载均衡"><a href="#⑤-基于ID负载均衡" class="headerlink" title="⑤ 基于ID负载均衡"></a>⑤ 基于ID负载均衡</h4><p>刚才的代码中，我们的tomcat是单机部署。而实际开发中，tomcat一定是集群模式：</p>
<p>因此，OpenResty需要对tomcat集群做负载均衡。</p>
<p>而默认的负载均衡规则是轮询模式，当我们查询&#x2F;item&#x2F;10001时：</p>
<ul>
<li>第一次会访问8081端口的tomcat服务，在该服务内部就形成了JVM进程缓存</li>
<li>第二次会访问8082端口的tomcat服务，该服务内部没有JVM缓存（因为JVM缓存无法共享），会查询数据库</li>
<li>…</li>
</ul>
<p>你看，因为轮询的原因，第一次查询8081形成的JVM缓存并未生效，直到下一次再次访问到8081时才可以生效，缓存命中率太低了。</p>
<p>怎么办？</p>
<p>如果能让同一个商品，每次查询时都访问同一个tomcat服务，那么JVM缓存就一定能生效了。</p>
<p>也就是说，我们需要根据商品id做负载均衡，而不是轮询。</p>
<p><strong>1）原理</strong></p>
<p>nginx提供了基于请求路径做负载均衡的算法：</p>
<p>nginx根据请求路径做hash运算，把得到的数值对tomcat服务的数量取余，余数是几，就访问第几个服务，实现负载均衡。</p>
<p>例如：</p>
<ul>
<li>我们的请求路径是 &#x2F;item&#x2F;10001</li>
<li>tomcat总数为2台（8081、8082）</li>
<li>对请求路径&#x2F;item&#x2F;1001做hash运算求余的结果为1</li>
<li>则访问第一个tomcat服务，也就是8081</li>
</ul>
<p>只要id不变，每次hash运算结果也不会变，那就可以保证同一个商品，一直访问同一个tomcat服务，确保JVM缓存生效。</p>
<p><strong>2）实现</strong></p>
<p>修改<code>/usr/local/openresty/nginx/conf/nginx.conf</code>文件，实现基于ID做负载均衡。</p>
<p>首先，定义tomcat集群，并设置基于路径做负载均衡：</p>
<pre><code class="nginx">upstream tomcat-cluster &#123;
    hash $request_uri;
    server 192.168.49.1:8081;
    server 192.168.49.1:8082;
&#125;
</code></pre>
<p>然后，修改对tomcat服务的反向代理，目标指向tomcat集群：</p>
<pre><code class="nginx">location /item &#123;
    proxy_pass http://tomcat-cluster;
&#125;
</code></pre>
<p>重新加载OpenResty</p>
<pre><code class="sh">nginx -s reload
</code></pre>
<p><strong>3）测试</strong></p>
<p>启动两台tomcat服务：8081,8082</p>
<h3 id="14-3-5-Redis缓存预热"><a href="#14-3-5-Redis缓存预热" class="headerlink" title="14.3.5 Redis缓存预热"></a>14.3.5 Redis缓存预热</h3><p>Redis缓存会面临冷启动问题：</p>
<p><strong>冷启动</strong>：服务刚刚启动时，Redis中并没有缓存，如果所有商品数据都在第一次查询时添加缓存，可能会给数据库带来较大压力。</p>
<p><strong>缓存预热</strong>：在实际开发中，我们可以利用大数据统计用户访问的热点数据，在项目启动时将这些热点数据提前查询并保存到Redis中。</p>
<p>我们数据量较少，并且没有数据统计相关功能，目前可以在启动时将所有数据都放入缓存中。</p>
<p>1）利用Docker安装Redis</p>
<pre><code class="sh">docker run --name redis -p 6379:6379 -d redis redis-server --appendonly yes
</code></pre>
<p>2）在item-service服务中引入Redis依赖</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>3）配置Redis地址</p>
<pre><code class="yaml">spring:
  redis:
    host: 192.168.49.10
</code></pre>
<p>4）编写初始化类</p>
<p>缓存预热需要在项目启动时完成，并且必须是拿到RedisTemplate之后。</p>
<p>这里我们利用InitializingBean接口来实现，因为InitializingBean可以在对象被Spring创建并且成员变量全部注入后执行。</p>
<pre><code class="java">package com.heima.item.config;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.heima.item.pojo.Item;
import com.heima.item.pojo.ItemStock;
import com.heima.item.service.IItemService;
import com.heima.item.service.IItemStockService;
import org.springframework.beans.factory.InitializingBean;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.stereotype.Component;

import java.util.List;

@Component
public class RedisHandler implements InitializingBean &#123;

    @Autowired
    private StringRedisTemplate redisTemplate;

    @Autowired
    private IItemService itemService;
    @Autowired
    private IItemStockService stockService;

    private static final ObjectMapper MAPPER = new ObjectMapper();

    @Override
    public void afterPropertiesSet() throws Exception &#123;
        // 初始化缓存
        // 1.查询商品信息
        List&lt;Item&gt; itemList = itemService.list();
        // 2.放入缓存
        for (Item item : itemList) &#123;
            // 2.1.item序列化为JSON
            String json = MAPPER.writeValueAsString(item);
            // 2.2.存入redis
            redisTemplate.opsForValue().set(&quot;item:id:&quot; + item.getId(), json);
        &#125;

        // 3.查询商品库存信息
        List&lt;ItemStock&gt; stockList = stockService.list();
        // 4.放入缓存
        for (ItemStock stock : stockList) &#123;
            // 2.1.item序列化为JSON
            String json = MAPPER.writeValueAsString(stock);
            // 2.2.存入redis
            redisTemplate.opsForValue().set(&quot;item:stock:id:&quot; + stock.getId(), json);
        &#125;
    &#125;
&#125;
</code></pre>
<h3 id="14-3-6-查询Redis缓存"><a href="#14-3-6-查询Redis缓存" class="headerlink" title="14.3.6 查询Redis缓存"></a>14.3.6 查询Redis缓存</h3><p>现在，Redis缓存已经准备就绪，我们可以再OpenResty中实现查询Redis的逻辑了。</p>
<p>当请求进入OpenResty之后：</p>
<ul>
<li>优先查询Redis缓存</li>
<li>如果Redis缓存未命中，再查询Tomcat</li>
</ul>
<h4 id="①-封装Redis工具"><a href="#①-封装Redis工具" class="headerlink" title="① 封装Redis工具"></a>① 封装Redis工具</h4><p>OpenResty提供了操作Redis的模块，我们只要引入该模块就能直接使用。但是为了方便，我们将Redis操作封装到之前的common.lua工具库中。</p>
<p>修改<code>/usr/local/openresty/lualib/common.lua</code>文件：</p>
<p>1）引入Redis模块，并初始化Redis对象</p>
<pre><code class="lua">-- 导入redis
local redis = require(&#39;resty.redis&#39;)
-- 初始化redis
local red = redis:new()
red:set_timeouts(1000, 1000, 1000)
</code></pre>
<p>2）封装函数，用来释放Redis连接，其实是放入连接池</p>
<pre><code class="lua">-- 关闭redis连接的工具方法，其实是放入连接池
local function close_redis(red)
    local pool_max_idle_time = 10000 -- 连接的空闲时间，单位是毫秒
    local pool_size = 100 --连接池大小
    local ok, err = red:set_keepalive(pool_max_idle_time, pool_size)
    if not ok then
        ngx.log(ngx.ERR, &quot;放入redis连接池失败: &quot;, err)
    end
end
</code></pre>
<p>3）封装函数，根据key查询Redis数据</p>
<pre><code class="lua">-- 查询redis的方法 ip和port是redis地址，key是查询的key
local function read_redis(ip, port, key)
    -- 获取一个连接
    local ok, err = red:connect(ip, port)
    if not ok then
        ngx.log(ngx.ERR, &quot;连接redis失败 : &quot;, err)
        return nil
    end
    -- 查询redis
    local resp, err = red:get(key)
    -- 查询失败处理
    if not resp then
        ngx.log(ngx.ERR, &quot;查询Redis失败: &quot;, err, &quot;, key = &quot; , key)
    end
    --得到的数据为空处理
    if resp == ngx.null then
        resp = nil
        ngx.log(ngx.ERR, &quot;查询Redis数据为空, key = &quot;, key)
    end
    close_redis(red)
    return resp
end
</code></pre>
<p>4）导出</p>
<pre><code class="lua">-- 将方法导出
local _M = &#123;  
    read_http = read_http,
    read_redis = read_redis
&#125;  
return _M
</code></pre>
<p>完整的common.lua：</p>
<pre><code class="lua">-- 导入redis
local redis = require(&#39;resty.redis&#39;)
-- 初始化redis
local red = redis:new()
red:set_timeouts(1000, 1000, 1000)

-- 关闭redis连接的工具方法，其实是放入连接池
local function close_redis(red)
    local pool_max_idle_time = 10000 -- 连接的空闲时间，单位是毫秒
    local pool_size = 100 --连接池大小
    local ok, err = red:set_keepalive(pool_max_idle_time, pool_size)
    if not ok then
        ngx.log(ngx.ERR, &quot;放入redis连接池失败: &quot;, err)
    end
end

-- 查询redis的方法 ip和port是redis地址，key是查询的key
local function read_redis(ip, port, key)
    -- 获取一个连接
    local ok, err = red:connect(ip, port)
    if not ok then
        ngx.log(ngx.ERR, &quot;连接redis失败 : &quot;, err)
        return nil
    end
    -- 查询redis
    local resp, err = red:get(key)
    -- 查询失败处理
    if not resp then
        ngx.log(ngx.ERR, &quot;查询Redis失败: &quot;, err, &quot;, key = &quot; , key)
    end
    --得到的数据为空处理
    if resp == ngx.null then
        resp = nil
        ngx.log(ngx.ERR, &quot;查询Redis数据为空, key = &quot;, key)
    end
    close_redis(red)
    return resp
end

-- 封装函数，发送http请求，并解析响应
local function read_http(path, params)
    local resp = ngx.location.capture(path,&#123;
        method = ngx.HTTP_GET,
        args = params,
    &#125;)
    if not resp then
        -- 记录错误信息，返回404
        ngx.log(ngx.ERR, &quot;http查询失败, path: &quot;, path , &quot;, args: &quot;, args)
        ngx.exit(404)
    end
    return resp.body
end
-- 将方法导出
local _M = &#123;  
    read_http = read_http,
    read_redis = read_redis
&#125;  
return _M
</code></pre>
<h4 id="②-实现Redis查询"><a href="#②-实现Redis查询" class="headerlink" title="② 实现Redis查询"></a>② 实现Redis查询</h4><p>接下来，我们就可以去修改item.lua文件，实现对Redis的查询了。</p>
<p>查询逻辑是：</p>
<ul>
<li>根据id查询Redis</li>
<li>如果查询失败则继续查询Tomcat</li>
<li>将查询结果返回</li>
</ul>
<p>1）修改<code>/usr/local/openresty/lua/item.lua</code>文件，添加一个查询函数：</p>
<pre><code class="lua">-- 导入common函数库
local common = require(&#39;common&#39;)
local read_http = common.read_http
local read_redis = common.read_redis
-- 封装查询函数
function read_data(key, path, params)
    -- 查询本地缓存
    local val = read_redis(&quot;127.0.0.1&quot;, 6379, key)
    -- 判断查询结果
    if not val then
        ngx.log(ngx.ERR, &quot;redis查询失败，尝试查询http， key: &quot;, key)
        -- redis查询失败，去查询http
        val = read_http(path, params)
    end
    -- 返回数据
    return val
end
</code></pre>
<p>2）而后修改商品查询、库存查询的业务</p>
<pre><code class="lua">-- 获取路径参数
local id = ngx.var[1]

-- 查询商品信息
local itemJSON = read_data(&quot;item:id:&quot; .. id,  &quot;/item/&quot; .. id, nil)
-- 查询库存信息
local stockJSON = read_data(&quot;item:stock:id:&quot; .. id, &quot;/item/stock/&quot; .. id, nil)
</code></pre>
<p>3）完整的item.lua代码：</p>
<pre><code class="lua">-- 导入common函数库
local common = require(&#39;common&#39;)
local read_http = common.read_http
local read_redis = common.read_redis
-- 导入cjson库
local cjson = require(&#39;cjson&#39;)

-- 封装查询函数
function read_data(key, path, params)
    -- 查询本地缓存
    local val = read_redis(&quot;127.0.0.1&quot;, 6379, key)
    -- 判断查询结果
    if not val then
        ngx.log(ngx.ERR, &quot;redis查询失败，尝试查询http， key: &quot;, key)
        -- redis查询失败，去查询http
        val = read_http(path, params)
    end
    -- 返回数据
    return val
end

-- 获取路径参数
local id = ngx.var[1]

-- 查询商品信息
local itemJSON = read_data(&quot;item:id:&quot; .. id,  &quot;/item/&quot; .. id, nil)
-- 查询库存信息
local stockJSON = read_data(&quot;item:stock:id:&quot; .. id, &quot;/item/stock/&quot; .. id, nil)

-- JSON转化为lua的table
local item = cjson.decode(itemJSON)
local stock = cjson.decode(stockJSON)
-- 组合数据
item.stock = stock.stock
item.sold = stock.sold

-- 把item序列化为json 返回结果
ngx.say(cjson.encode(item))
</code></pre>
<h3 id="14-3-7-Nginx本地缓存"><a href="#14-3-7-Nginx本地缓存" class="headerlink" title="14.3.7 Nginx本地缓存"></a>14.3.7 Nginx本地缓存</h3><p>现在，整个多级缓存中只差最后一环，也就是nginx的本地缓存了。</p>
<h4 id="①-本地缓存API"><a href="#①-本地缓存API" class="headerlink" title="① 本地缓存API"></a>① 本地缓存API</h4><p>OpenResty为Nginx提供了<strong>shard dict</strong>的功能，可以在nginx的多个worker之间共享数据，实现缓存功能。</p>
<p>1）开启共享字典，在nginx.conf的http下添加配置：</p>
<pre><code class="nginx"> # 共享字典，也就是本地缓存，名称叫做：item_cache，大小150m
 lua_shared_dict item_cache 150m; 
</code></pre>
<p>2）操作共享字典：</p>
<pre><code class="lua">-- 获取本地缓存对象
local item_cache = ngx.shared.item_cache
-- 存储, 指定key、value、过期时间，单位s，默认为0代表永不过期
item_cache:set(&#39;key&#39;, &#39;value&#39;, 1000)
-- 读取
local val = item_cache:get(&#39;key&#39;)
</code></pre>
<h4 id="②-实现本地缓存查询"><a href="#②-实现本地缓存查询" class="headerlink" title="② 实现本地缓存查询"></a>② 实现本地缓存查询</h4><p>1）修改<code>/usr/local/openresty/lua/item.lua</code>文件，修改read_data查询函数，添加本地缓存逻辑：</p>
<pre><code class="lua">-- 导入共享词典，本地缓存
local item_cache = ngx.shared.item_cache

-- 封装查询函数
function read_data(key, expire, path, params)
    -- 查询本地缓存
    local val = item_cache:get(key)
    if not val then
        ngx.log(ngx.ERR, &quot;本地缓存查询失败，尝试查询Redis， key: &quot;, key)
        -- 查询redis
        val = read_redis(&quot;127.0.0.1&quot;, 6379, key)
        -- 判断查询结果
        if not val then
            ngx.log(ngx.ERR, &quot;redis查询失败，尝试查询http， key: &quot;, key)
            -- redis查询失败，去查询http
            val = read_http(path, params)
        end
    end
    -- 查询成功，把数据写入本地缓存
    item_cache:set(key, val, expire)
    -- 返回数据
    return val
end
</code></pre>
<p>2）修改item.lua中查询商品和库存的业务，实现最新的read_data函数：</p>
<pre><code class="lua">-- 查询商品信息
local itemJSON = read_data(&quot;item:id:&quot; .. id, 1800,  &quot;/item/&quot; .. id, nil)
-- 查询库存信息
local stockJSON = read_data(&quot;item:stock:id:&quot; .. id, 60, &quot;/item/stock/&quot; .. id, nil)
</code></pre>
<p>其实就是多了缓存时间参数，过期后nginx缓存会自动删除，下次访问即可更新缓存。</p>
<p>这里给商品基本信息设置超时时间为30分钟，库存为1分钟。</p>
<p>因为库存更新频率较高，如果缓存时间过长，可能与数据库差异较大。</p>
<p>3）完整的item.lua文件：</p>
<pre><code class="lua">-- 导入common函数库
local common = require(&#39;common&#39;)
local read_http = common.read_http
local read_redis = common.read_redis
-- 导入cjson库
local cjson = require(&#39;cjson&#39;)
-- 导入共享词典，本地缓存
local item_cache = ngx.shared.item_cache

-- 封装查询函数
function read_data(key, expire, path, params)
    -- 查询本地缓存
    local val = item_cache:get(key)
    if not val then
        ngx.log(ngx.ERR, &quot;本地缓存查询失败，尝试查询Redis， key: &quot;, key)
        -- 查询redis
        val = read_redis(&quot;127.0.0.1&quot;, 6379, key)
        -- 判断查询结果
        if not val then
            ngx.log(ngx.ERR, &quot;redis查询失败，尝试查询http， key: &quot;, key)
            -- redis查询失败，去查询http
            val = read_http(path, params)
        end
    end
    -- 查询成功，把数据写入本地缓存
    item_cache:set(key, val, expire)
    -- 返回数据
    return val
end

-- 获取路径参数
local id = ngx.var[1]

-- 查询商品信息
local itemJSON = read_data(&quot;item:id:&quot; .. id, 1800,  &quot;/item/&quot; .. id, nil)
-- 查询库存信息
local stockJSON = read_data(&quot;item:stock:id:&quot; .. id, 60, &quot;/item/stock/&quot; .. id, nil)

-- JSON转化为lua的table
local item = cjson.decode(itemJSON)
local stock = cjson.decode(stockJSON)
-- 组合数据
item.stock = stock.stock
item.sold = stock.sold

-- 把item序列化为json 返回结果
ngx.say(cjson.encode(item))
</code></pre>
<h2 id="14-4-缓存同步【bug，待解决】"><a href="#14-4-缓存同步【bug，待解决】" class="headerlink" title="14.4 缓存同步【bug，待解决】"></a>14.4 缓存同步【bug，待解决】</h2><p>大多数情况下，浏览器查询到的都是缓存数据，如果缓存数据与数据库数据存在较大差异，可能会产生比较严重的后果。</p>
<p>所以我们必须保证数据库数据、缓存数据的一致性，这就是缓存与数据库的同步。</p>
<h3 id="14-4-1-数据同步策略"><a href="#14-4-1-数据同步策略" class="headerlink" title="14.4.1 数据同步策略"></a>14.4.1 数据同步策略</h3><p>缓存数据同步的常见方式有三种：</p>
<p><strong>设置有效期</strong>：给缓存设置有效期，到期后自动删除。再次查询时更新</p>
<ul>
<li>优势：简单、方便</li>
<li>缺点：时效性差，缓存过期之前可能不一致</li>
<li>场景：更新频率较低，时效性要求低的业务</li>
</ul>
<p><strong>同步双写</strong>：在修改数据库的同时，直接修改缓存</p>
<ul>
<li>优势：时效性强，缓存与数据库强一致</li>
<li>缺点：有代码侵入，耦合度高；</li>
<li>场景：对一致性、时效性要求较高的缓存数据</li>
</ul>
<p><strong>异步通知：</strong>修改数据库时发送事件通知，相关服务监听到通知后修改缓存数据</p>
<ul>
<li>优势：低耦合，可以同时通知多个缓存服务</li>
<li>缺点：时效性一般，可能存在中间不一致状态</li>
<li>场景：时效性要求一般，有多个服务需要同步</li>
</ul>
<p>而异步实现又可以基于MQ或者Canal来实现：</p>
<p>1）基于MQ的异步通知：</p>
<ul>
<li>商品服务完成对数据的修改后，只需要发送一条消息到MQ中。</li>
<li>缓存服务监听MQ消息，然后完成对缓存的更新</li>
</ul>
<p>依然有少量的代码侵入。</p>
<p>2）基于Canal的通知：</p>
<ul>
<li>商品服务完成商品修改后，业务直接结束，没有任何代码侵入</li>
<li>Canal监听MySQL变化，当发现变化后，立即通知缓存服务</li>
<li>缓存服务接收到canal通知，更新缓存</li>
</ul>
<p>代码零侵入</p>
<h3 id="14-4-2-Canal"><a href="#14-4-2-Canal" class="headerlink" title="14.4.2 Canal"></a>14.4.2 Canal</h3><h4 id="①-认识Canal"><a href="#①-认识Canal" class="headerlink" title="① 认识Canal"></a>① 认识Canal</h4><p>**Canal [kə’næl]**，译意为水道&#x2F;管道&#x2F;沟渠，canal是阿里巴巴旗下的一款开源项目，基于Java开发。基于数据库增量日志解析，提供增量数据订阅&amp;消费。GitHub的地址：<a target="_blank" rel="noopener" href="https://github.com/alibaba/canal">https://github.com/alibaba/canal</a></p>
<p>Canal是基于mysql的主从同步来实现的</p>
<ul>
<li>1）MySQL master 将数据变更写入二进制日志( binary log），其中记录的数据叫做binary log events</li>
<li>2）MySQL slave 将 master 的 binary log events拷贝到它的中继日志(relay log)</li>
<li>3）MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据</li>
</ul>
<p>而Canal就是把自己伪装成MySQL的一个slave节点，从而监听master的binary log变化。再把得到的变化信息通知给Canal的客户端，进而完成对其它数据库的同步。</p>
<h4 id="②-安装Canal"><a href="#②-安装Canal" class="headerlink" title="② 安装Canal"></a>② 安装Canal</h4><p>1）开启MySQL主从</p>
<p>Canal是基于MySQL的主从同步功能，因此必须先开启MySQL的主从功能才可以。</p>
<p>这里以之前用Docker运行的mysql为例：</p>
<ol>
<li><p>开启binlog</p>
<p>打开mysql容器挂载的日志文件，我的在<code>/tmp/mysql/conf</code>目录</p>
<p>修改文件：</p>
<pre><code class="sh">vi /tmp/mysql/conf/my.cnf
</code></pre>
<p>添加内容：</p>
<pre><code class="ini">log-bin=/var/lib/mysql/mysql-bin
binlog-do-db=heima
</code></pre>
<p>配置解读：</p>
<ul>
<li><code>log-bin=/var/lib/mysql/mysql-bin</code>：设置binary log文件的存放地址和文件名，叫做mysql-bin</li>
<li><code>binlog-do-db=heima</code>：指定对哪个database记录binary log events，这里记录heima这个库</li>
</ul>
<p>最终效果：</p>
<pre><code class="ini">[mysqld]
skip-name-resolve
character_set_server=utf8
datadir=/var/lib/mysql
server-id=1000
log-bin=/var/lib/mysql/mysql-bin
binlog-do-db=heima
</code></pre>
</li>
<li><p>设置用户权限</p>
<p>接下来添加一个仅用于数据同步的账户，出于安全考虑，这里仅提供对heima这个库的操作权限。</p>
<pre><code class="mysql">create user canal@&#39;%&#39; IDENTIFIED by &#39;canal&#39;;
GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT,SUPER ON *.* TO &#39;canal&#39;@&#39;%&#39; identified by &#39;canal&#39;;
FLUSH PRIVILEGES;
</code></pre>
<p>重启mysql容器即可</p>
<pre><code>docker restart mysql
</code></pre>
<p>测试设置是否成功：在mysql控制台，或者Navicat中，输入命令：</p>
<pre><code>show master status;
</code></pre>
</li>
</ol>
<p>2）安装Canal</p>
<ol>
<li><p>创建网络</p>
<p>我们需要创建一个网络，将MySQL、Canal、MQ放到同一个Docker网络中：</p>
<pre><code class="sh">docker network create heima
</code></pre>
<p>让mysql加入这个网络：</p>
<pre><code class="sh">docker network connect heima mysql
</code></pre>
</li>
<li><p>安装</p>
<p>上传到虚拟机，然后通过命令导入：</p>
<pre><code>docker load -i canal.tar
</code></pre>
<p>然后运行命令创建Canal容器：</p>
<pre><code class="sh">docker run -p 11111:11111 --name canal \
-e canal.destinations=heima \
-e canal.instance.master.address=mysql:3306  \
-e canal.instance.dbUsername=canal  \
-e canal.instance.dbPassword=canal  \
-e canal.instance.connectionCharset=UTF-8 \
-e canal.instance.tsdb.enable=true \
-e canal.instance.gtidon=false  \
-e canal.instance.filter.regex=heima\\..* \
--network heima \
-d canal/canal-server:v1.1.5
</code></pre>
<p>说明:</p>
<ul>
<li><code>-p 11111:11111</code>：这是canal的默认监听端口</li>
<li><code>-e canal.instance.master.address=mysql:3306</code>：数据库地址和端口，如果不知道mysql容器地址，可以通过<code>docker inspect 容器id</code>来查看</li>
<li><code>-e canal.instance.dbUsername=canal</code>：数据库用户名</li>
<li><code>-e canal.instance.dbPassword=canal</code> ：数据库密码</li>
<li><code>-e canal.instance.filter.regex=</code>：要监听的表名称</li>
</ul>
<p>表名称监听支持的语法：</p>
<pre><code>mysql 数据解析关注的表，Perl正则表达式.
多个正则之间以逗号(,)分隔，转义符需要双斜杠(\\) 
常见例子：
1.  所有表：.*   or  .*\\..*
2.  canal schema下所有表： canal\\..*
3.  canal下的以canal打头的表：canal\\.canal.*
4.  canal schema下的一张表：canal.test1
5.  多个规则组合使用然后以逗号隔开：canal\\..*,mysql.test1,mysql.test2 
</code></pre>
</li>
</ol>
<h4 id="③-监听Canal"><a href="#③-监听Canal" class="headerlink" title="③ 监听Canal"></a>③ 监听Canal</h4><p>Canal提供了各种语言的客户端，当Canal监听到binlog变化时，会通知Canal的客户端。</p>
<p>利用Canal提供的Java客户端，监听Canal通知消息。当收到变化的消息时，完成对缓存的更新。</p>
<p>不过这里我们会使用GitHub上的第三方开源的canal-starter客户端。地址：<a target="_blank" rel="noopener" href="https://github.com/NormanGyllenhaal/canal-client">https://github.com/NormanGyllenhaal/canal-client</a></p>
<p>与SpringBoot完美整合，自动装配，比官方客户端要简单好用很多。</p>
<p>1）引入依赖：</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;top.javatool&lt;/groupId&gt;
    &lt;artifactId&gt;canal-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;1.2.1-RELEASE&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>2）编写配置：</p>
<pre><code class="yaml">canal:
  destination: heima # canal的集群名字，要与安装canal时设置的名称一致
  server: 192.168.49.10:11111 # canal服务地址
</code></pre>
<p>3）修改Item实体类</p>
<p>通过@Id、@Column、等注解完成Item与数据库表字段的映射：</p>
<pre><code class="java">package com.heima.item.pojo;

import com.baomidou.mybatisplus.annotation.IdType;
import com.baomidou.mybatisplus.annotation.TableField;
import com.baomidou.mybatisplus.annotation.TableId;
import com.baomidou.mybatisplus.annotation.TableName;
import lombok.Data;
import org.springframework.data.annotation.Id;
import org.springframework.data.annotation.Transient;

import javax.persistence.Column;
import java.util.Date;

@Data
@TableName(&quot;tb_item&quot;)
public class Item &#123;
    @TableId(type = IdType.AUTO)
    @Id
    private Long id;//商品id
    @Column(name = &quot;name&quot;)
    private String name;//商品名称
    private String title;//商品标题
    private Long price;//价格（分）
    private String image;//商品图片
    private String category;//分类名称
    private String brand;//品牌名称
    private String spec;//规格
    private Integer status;//商品状态 1-正常，2-下架
    private Date createTime;//创建时间
    private Date updateTime;//更新时间
    @TableField(exist = false)
    @Transient
    private Integer stock;
    @TableField(exist = false)
    @Transient
    private Integer sold;
&#125;
</code></pre>
<p>4）编写监听器</p>
<p>通过实现<code>EntryHandler&lt;T&gt;</code>接口编写监听器，监听Canal消息。注意两点：</p>
<ul>
<li>实现类通过<code>@CanalTable(&quot;tb_item&quot;)</code>指定监听的表信息</li>
<li>EntryHandler的泛型是与表对应的实体类</li>
</ul>
<pre><code class="java">package com.heima.item.canal;

import com.github.benmanes.caffeine.cache.Cache;
import com.heima.item.config.RedisHandler;
import com.heima.item.pojo.Item;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
import top.javatool.canal.client.annotation.CanalTable;
import top.javatool.canal.client.handler.EntryHandler;

@CanalTable(&quot;tb_item&quot;)
@Component
public class ItemHandler implements EntryHandler&lt;Item&gt; &#123;

    @Autowired
    private RedisHandler redisHandler;
    @Autowired
    private Cache&lt;Long, Item&gt; itemCache;

    @Override
    public void insert(Item item) &#123;
        // 写数据到JVM进程缓存
        itemCache.put(item.getId(), item);
        // 写数据到redis
        redisHandler.saveItem(item);
    &#125;

    @Override
    public void update(Item before, Item after) &#123;
        // 写数据到JVM进程缓存
        itemCache.put(after.getId(), after);
        // 写数据到redis
        redisHandler.saveItem(after);
    &#125;

    @Override
    public void delete(Item item) &#123;
        // 删除数据到JVM进程缓存
        itemCache.invalidate(item.getId());
        // 删除数据到redis
        redisHandler.deleteItemById(item.getId());
    &#125;
&#125;
</code></pre>
<p>在这里对Redis的操作都封装到了RedisHandler这个对象中，是我们之前做缓存预热时编写的一个类，内容如下：</p>
<pre><code class="java">package com.heima.item.config;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.heima.item.pojo.Item;
import com.heima.item.pojo.ItemStock;
import com.heima.item.service.IItemService;
import com.heima.item.service.IItemStockService;
import org.springframework.beans.factory.InitializingBean;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.stereotype.Component;

import java.util.List;

@Component
public class RedisHandler implements InitializingBean &#123;

    @Autowired
    private StringRedisTemplate redisTemplate;

    @Autowired
    private IItemService itemService;
    @Autowired
    private IItemStockService stockService;

    private static final ObjectMapper MAPPER = new ObjectMapper();

    @Override
    public void afterPropertiesSet() throws Exception &#123;
        // 初始化缓存
        // 1.查询商品信息
        List&lt;Item&gt; itemList = itemService.list();
        // 2.放入缓存
        for (Item item : itemList) &#123;
            // 2.1.item序列化为JSON
            String json = MAPPER.writeValueAsString(item);
            // 2.2.存入redis
            redisTemplate.opsForValue().set(&quot;item:id:&quot; + item.getId(), json);
        &#125;

        // 3.查询商品库存信息
        List&lt;ItemStock&gt; stockList = stockService.list();
        // 4.放入缓存
        for (ItemStock stock : stockList) &#123;
            // 2.1.item序列化为JSON
            String json = MAPPER.writeValueAsString(stock);
            // 2.2.存入redis
            redisTemplate.opsForValue().set(&quot;item:stock:id:&quot; + stock.getId(), json);
        &#125;
    &#125;

    public void saveItem(Item item) &#123;
        try &#123;
            String json = MAPPER.writeValueAsString(item);
            redisTemplate.opsForValue().set(&quot;item:id:&quot; + item.getId(), json);
        &#125; catch (JsonProcessingException e) &#123;
            throw new RuntimeException(e);
        &#125;
    &#125;

    public void deleteItemById(Long id) &#123;
        redisTemplate.delete(&quot;item:id:&quot; + id);
    &#125;
&#125;
</code></pre>
<h1 id="十五、服务异步通信【MQ相关】"><a href="#十五、服务异步通信【MQ相关】" class="headerlink" title="十五、服务异步通信【MQ相关】"></a>十五、服务异步通信【MQ相关】</h1><p>消息队列在使用过程中，面临着很多实际问题需要思考：</p>
<ul>
<li>消息可靠性问题：如何确保发送的消息至少被消费一次</li>
<li>延迟消息问题：如何实现消息的延迟投递</li>
<li>消息堆积问题：如何解决是百万消息的总堆积，无法及时消费的问题</li>
<li>高可用问题：如何避免单点MQ故障导致的不可用问题</li>
</ul>
<h2 id="15-1-消息可靠性"><a href="#15-1-消息可靠性" class="headerlink" title="15.1 消息可靠性"></a>15.1 消息可靠性</h2><p>消息从发送，到消费者接收，会经历多个过程：</p>
<ul>
<li>publisher &#x3D;&gt; exchange &#x3D;&gt; 多个queue &#x3D;&gt; 每个queue对应的consumer</li>
</ul>
<p>其中的每一步都可能导致消息丢失，常见的<strong>丢失原因</strong>包括：</p>
<ul>
<li>发送时丢失：<ul>
<li>生产者发送的消息未送达exchange</li>
<li>消息到达exchange后未到达queue</li>
</ul>
</li>
<li>MQ宕机，queue将消息丢失</li>
<li>consumer接收到消息后未消费就宕机</li>
</ul>
<p>针对这些问题，RabbitMQ分别给出了<strong>解决方案</strong>：</p>
<ul>
<li>生产者确认机制</li>
<li>mq持久化</li>
<li>消费者确认机制</li>
<li>失败重试机制</li>
</ul>
<h3 id="15-1-1-生产者消息确认"><a href="#15-1-1-生产者消息确认" class="headerlink" title="15.1.1 生产者消息确认"></a>15.1.1 生产者消息确认</h3><p>RabbitMQ提供了publisher confirm机制来避免消息发送到MQ过程中丢失。这种机制必须给每个消息指定一个唯一ID。消息发送到MQ以后，会返回一个结果给发送者，表示消息是否处理成功。</p>
<p>返回结果有两种方式：</p>
<ul>
<li>publisher-confirm，发送者确认<ul>
<li>消息成功投递到交换机，返回ack</li>
<li>消息未投递到交换机，返回nack</li>
</ul>
</li>
<li>publisher-return，发送者回执<ul>
<li>消息投递到交换机了，但是没有路由到队列。返回ACK，及路由失败原因。</li>
</ul>
</li>
</ul>
<p>注：确认机制发送消息时，需要给每个消息设置一个全局唯一id，以区分不同消息，避免ack冲突</p>
<h4 id="①-修改配置"><a href="#①-修改配置" class="headerlink" title="① 修改配置"></a>① 修改配置</h4><p>首先，修改publisher服务中的application.yml文件，添加下面的内容：</p>
<pre><code class="yaml">spring:
  rabbitmq:
    publisher-confirm-type: correlated
    publisher-returns: true
    template:
      mandatory: true
</code></pre>
<p>说明：</p>
<ul>
<li><code>publish-confirm-type</code>：开启publisher-confirm，这里支持两种类型：<ul>
<li><code>simple</code>：同步等待confirm结果，直到超时</li>
<li><code>correlated</code>：异步回调，定义ConfirmCallback，MQ返回结果时会回调这个ConfirmCallback</li>
</ul>
</li>
<li><code>publish-returns</code>：开启publish-return功能，同样是基于callback机制，不过是定义ReturnCallback</li>
<li><code>template.mandatory</code>：定义消息路由失败时的策略。true，则调用ReturnCallback；false：则直接丢弃消息</li>
</ul>
<h4 id="②-定义Return回调"><a href="#②-定义Return回调" class="headerlink" title="② 定义Return回调"></a>② 定义Return回调</h4><p>每个RabbitTemplate只能配置一个ReturnCallback，因此需要在项目加载时配置：</p>
<p>修改publisher服务，添加一个：</p>
<pre><code class="java">package cn.itcast.mq.config;

import lombok.extern.slf4j.Slf4j;
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.beans.BeansException;
import org.springframework.context.ApplicationContext;
import org.springframework.context.ApplicationContextAware;
import org.springframework.context.annotation.Configuration;

@Slf4j
@Configuration
public class CommonConfig implements ApplicationContextAware &#123;
    @Override
    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123;
        // 获取RabbitTemplate
        RabbitTemplate rabbitTemplate = applicationContext.getBean(RabbitTemplate.class);
        // 设置ReturnCallback
        rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey) -&gt; &#123;
            // 投递失败，记录日志
            log.info(&quot;消息发送失败，应答码&#123;&#125;，原因&#123;&#125;，交换机&#123;&#125;，路由键&#123;&#125;,消息&#123;&#125;&quot;,
                     replyCode, replyText, exchange, routingKey, message.toString());
            // 如果有业务需要，可以重发消息
        &#125;);
    &#125;
&#125;
</code></pre>
<h4 id="③-定义ConfirmCallback"><a href="#③-定义ConfirmCallback" class="headerlink" title="③ 定义ConfirmCallback"></a>③ 定义ConfirmCallback</h4><p>ConfirmCallback可以在发送消息时指定，因为每个业务处理confirm成功或失败的逻辑不一定相同。</p>
<p>在publisher服务的cn.itcast.mq.spring.SpringAmqpTest类中，定义一个单元测试方法：</p>
<pre><code class="java">public void testSendMessage2SimpleQueue() throws InterruptedException &#123;
    // 1.消息体
    String message = &quot;hello, spring amqp!&quot;;
    // 2.全局唯一的消息ID，需要封装到CorrelationData中
    CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString());
    // 3.添加callback
    correlationData.getFuture().addCallback(
        result -&gt; &#123;
            if(result.isAck())&#123;
                // 3.1.ack，消息成功
                log.debug(&quot;消息发送成功, ID:&#123;&#125;&quot;, correlationData.getId());
            &#125;else&#123;
                // 3.2.nack，消息失败
                log.error(&quot;消息发送失败, ID:&#123;&#125;, 原因&#123;&#125;&quot;,correlationData.getId(), result.getReason());
            &#125;
        &#125;,
        ex -&gt; log.error(&quot;消息发送异常, ID:&#123;&#125;, 原因&#123;&#125;&quot;,correlationData.getId(),ex.getMessage())
    );
    // 4.发送消息
    rabbitTemplate.convertAndSend(&quot;task.direct&quot;, &quot;task&quot;, message, correlationData);

    // 休眠一会儿，等待ack回执
    Thread.sleep(2000);
&#125;
</code></pre>
<h3 id="15-1-2-消息持久化"><a href="#15-1-2-消息持久化" class="headerlink" title="15.1.2 消息持久化"></a>15.1.2 消息持久化</h3><p>生产者确认可以确保消息投递到RabbitMQ的队列中，但是消息发送到RabbitMQ以后，如果突然宕机，也可能导致消息丢失。</p>
<p>要想确保消息在RabbitMQ中安全保存，必须开启消息持久化机制。</p>
<ul>
<li>交换机持久化</li>
<li>队列持久化</li>
<li>消息持久化</li>
</ul>
<h4 id="①-交换机持久化"><a href="#①-交换机持久化" class="headerlink" title="① 交换机持久化"></a>① 交换机持久化</h4><p>RabbitMQ中交换机默认是非持久化的，mq重启后就丢失。</p>
<p>SpringAMQP中可以通过代码指定交换机持久化：</p>
<pre><code class="java">@Bean
public DirectExchange simpleExchange()&#123;
    // 三个参数：交换机名称、是否持久化、当没有queue与其绑定时是否自动删除
    return new DirectExchange(&quot;simple.direct&quot;, true, false);
&#125;
</code></pre>
<p>事实上，默认情况下，由SpringAMQP声明的交换机都是持久化的。</p>
<p>可以在RabbitMQ控制台看到持久化的交换机都会带上<code>D</code>的标示</p>
<h4 id="②-队列持久化"><a href="#②-队列持久化" class="headerlink" title="② 队列持久化"></a>② 队列持久化</h4><p>RabbitMQ中队列默认是非持久化的，mq重启后就丢失。</p>
<p>SpringAMQP中可以通过代码指定交换机持久化：</p>
<pre><code class="java">@Bean
public Queue simpleQueue()&#123;
    // 使用QueueBuilder构建队列，durable就是持久化的
    return QueueBuilder.durable(&quot;simple.queue&quot;).build();
&#125;
</code></pre>
<p>事实上，默认情况下，由SpringAMQP声明的队列都是持久化的。</p>
<p>可以在RabbitMQ控制台看到持久化的队列都会带上<code>D</code>的标示</p>
<h4 id="③-消息持久化"><a href="#③-消息持久化" class="headerlink" title="③ 消息持久化"></a>③ 消息持久化</h4><p>利用SpringAMQP发送消息时，可以设置消息的属性（MessageProperties），指定delivery-mode：</p>
<ul>
<li>1：非持久化</li>
<li>2：持久化</li>
</ul>
<p>用java代码指定：</p>
<pre><code class="java">@Test
public void testDurableMessage() &#123;
    // 准备消息
    Message message = MessageBuilder.withBody(&quot;hello,spring&quot;.getBytes(StandardCharsets.UTF_8))
        .setDeliveryMode(MessageDeliveryMode.PERSISTENT)
        .build();
    // correlationData可不指定
    CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString());
    // 发送消息
    rabbitTemplate.convertAndSend(&quot;simple.queue&quot;, message,correlationData);
&#125;
</code></pre>
<p>默认情况下，SpringAMQP发出的任何消息都是持久化的，不用特意指定。</p>
<h3 id="15-1-3-消费者消息确认"><a href="#15-1-3-消费者消息确认" class="headerlink" title="15.1.3 消费者消息确认"></a>15.1.3 消费者消息确认</h3><p>RabbitMQ是<strong>阅后即焚</strong>机制，RabbitMQ确认消息被消费者消费后会立刻删除。</p>
<p>而RabbitMQ是通过消费者回执来确认消费者是否成功处理消息的：消费者获取消息后，应该向RabbitMQ发送ACK回执，表明自己已经处理消息。</p>
<p>设想这样的场景：</p>
<ul>
<li>1）RabbitMQ投递消息给消费者</li>
<li>2）消费者获取消息后，返回ACK给RabbitMQ</li>
<li>3）RabbitMQ删除消息</li>
<li>4）消费者宕机，消息尚未处理</li>
</ul>
<p>这样，消息就丢失了。因此消费者返回ACK的时机非常重要。</p>
<p>而SpringAMQP则允许配置三种确认模式：</p>
<ul>
<li>manual：手动ack，需要在业务代码结束后，调用api发送ack。</li>
<li>auto：自动ack，由spring监测listener代码是否出现异常，没有异常则返回ack；抛出异常则返回nack</li>
<li>none：关闭ack，MQ假定消费者获取消息后会成功处理，因此消息投递后立即被删除</li>
</ul>
<p>由此可知：</p>
<ul>
<li>none模式下，消息投递是不可靠的，可能丢失</li>
<li>auto模式类似事务机制，出现异常时返回nack，消息回滚到mq；没有异常，返回ack</li>
<li>manual：自己根据业务情况，判断什么时候该ack</li>
</ul>
<p>一般，我们都是使用默认的auto即可。</p>
<h4 id="①-演示none模式"><a href="#①-演示none模式" class="headerlink" title="① 演示none模式"></a>① 演示none模式</h4><p>修改consumer服务的application.yml文件，添加下面内容：</p>
<pre><code class="yaml">spring:
  rabbitmq:
    listener:
      simple:
        acknowledge-mode: none # 关闭ack
</code></pre>
<p>修改consumer服务的SpringRabbitListener类中的方法，模拟一个消息处理异常：</p>
<pre><code class="java">@RabbitListener(queues = &quot;simple.queue&quot;)
public void listenSimpleQueue(String msg) &#123;
    log.info(&quot;消费者接收到simple.queue的消息：【&#123;&#125;】&quot;, msg);
    // 模拟异常
    System.out.println(1 / 0);
    log.debug(&quot;消息处理完成！&quot;);
&#125;
</code></pre>
<p>测试可以发现，当消息处理抛异常时，消息依然被RabbitMQ删除了。</p>
<h4 id="②-演示auto模式"><a href="#②-演示auto模式" class="headerlink" title="② 演示auto模式"></a>② 演示auto模式</h4><p>再次把确认机制修改为auto:</p>
<pre><code class="yaml">spring:
  rabbitmq:
    listener:
      simple:
        acknowledge-mode: auto # 关闭ack
</code></pre>
<p>在异常位置打断点，再次发送消息，程序卡在断点时，可以发现此时消息状态为unack（未确定状态）</p>
<h3 id="15-1-4-消费失败重试机制"><a href="#15-1-4-消费失败重试机制" class="headerlink" title="15.1.4 消费失败重试机制"></a>15.1.4 消费失败重试机制</h3><p>当消费者出现异常后，消息会不断requeue（重入队）到队列，再重新发送给消费者，然后再次异常，再次requeue，无限循环，导致mq的消息处理飙升，带来不必要的压力</p>
<h4 id="①-本地重试"><a href="#①-本地重试" class="headerlink" title="① 本地重试"></a>① 本地重试</h4><p>我们可以利用Spring的retry机制，在消费者出现异常时利用本地重试，而不是无限制的requeue到mq队列。</p>
<p>修改consumer服务的application.yml文件，添加内容：</p>
<pre><code class="yaml">spring:
  rabbitmq:
    listener:
      simple:
        retry:
          enabled: true # 开启消费者失败重试
          initial-interval: 1000 # 初识的失败等待时长为1秒
          multiplier: 1 # 失败的等待时长倍数，下次等待时长 = multiplier * last-interval
          max-attempts: 3 # 最大重试次数
          stateless: true # true无状态；false有状态。如果业务中包含事务，这里改为false
</code></pre>
<p>重启consumer服务，重复之前的测试。可以发现：</p>
<ul>
<li>在重试3次后，SpringAMQP会抛出异常AmqpRejectAndDontRequeueException，说明本地重试触发了</li>
<li>查看RabbitMQ控制台，发现消息被删除了，说明最后SpringAMQP返回的是ack，mq删除消息了</li>
</ul>
<p>结论：</p>
<ul>
<li>开启本地重试时，消息处理过程中抛出异常，不会requeue到队列，而是在消费者本地重试</li>
<li>重试达到最大次数后，Spring会返回ack，消息会被丢弃</li>
</ul>
<h4 id="②-失败策略"><a href="#②-失败策略" class="headerlink" title="② 失败策略"></a>② 失败策略</h4><p>在之前的测试中，达到最大重试次数后，消息会被丢弃，这是由Spring内部机制决定的。</p>
<p>在开启重试模式后，重试次数耗尽，如果消息依然失败，则需要有MessageRecovery接口来处理，它包含三种不同的实现：</p>
<ul>
<li>RejectAndDontRequeueRecoverer：重试耗尽后，直接reject，丢弃消息。默认就是这种方式</li>
<li>ImmediateRequeueMessageRecoverer：重试耗尽后，返回nack，消息重新入队</li>
<li>RepublishMessageRecoverer：重试耗尽后，将失败消息投递到指定的交换机</li>
</ul>
<p>比较优雅的一种处理方案是RepublishMessageRecoverer，失败后将消息投递到一个指定的，专门存放异常消息的队列，后续由人工集中处理。</p>
<p>1）在consumer服务中定义处理失败消息的交换机和队列</p>
<pre><code class="java">@Bean
public DirectExchange errorMessageExchange()&#123;
    return new DirectExchange(&quot;error.direct&quot;);
&#125;
@Bean
public Queue errorQueue()&#123;
    return new Queue(&quot;error.queue&quot;, true);
&#125;
@Bean
public Binding errorBinding(Queue errorQueue, DirectExchange errorMessageExchange)&#123;
    return BindingBuilder.bind(errorQueue).to(errorMessageExchange).with(&quot;error&quot;);
&#125;
</code></pre>
<p>2）定义一个RepublishMessageRecoverer，关联队列和交换机</p>
<pre><code class="java">@Bean
public MessageRecoverer republishMessageRecoverer(RabbitTemplate rabbitTemplate)&#123;
    return new RepublishMessageRecoverer(rabbitTemplate, &quot;error.direct&quot;, &quot;error&quot;);
&#125;
</code></pre>
<p>完整代码：</p>
<pre><code class="java">package cn.itcast.mq.config;

import org.springframework.amqp.core.Binding;
import org.springframework.amqp.core.BindingBuilder;
import org.springframework.amqp.core.DirectExchange;
import org.springframework.amqp.core.Queue;
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.amqp.rabbit.retry.MessageRecoverer;
import org.springframework.amqp.rabbit.retry.RepublishMessageRecoverer;
import org.springframework.context.annotation.Bean;

@Configuration
public class ErrorMessageConfig &#123;
    @Bean
    public DirectExchange errorMessageExchange()&#123;
        return new DirectExchange(&quot;error.direct&quot;);
    &#125;
    @Bean
    public Queue errorQueue()&#123;
        return new Queue(&quot;error.queue&quot;, true);
    &#125;
    @Bean
    public Binding errorBinding(Queue errorQueue, DirectExchange errorMessageExchange)&#123;
        return BindingBuilder.bind(errorQueue).to(errorMessageExchange).with(&quot;error&quot;);
    &#125;

    @Bean
    public MessageRecoverer republishMessageRecoverer(RabbitTemplate rabbitTemplate)&#123;
        return new RepublishMessageRecoverer(rabbitTemplate, &quot;error.direct&quot;, &quot;error&quot;);
    &#125;
&#125;
</code></pre>
<h3 id="15-1-5-总结"><a href="#15-1-5-总结" class="headerlink" title="15.1.5 总结"></a>15.1.5 总结</h3><p>如何确保RabbitMQ消息的可靠性？</p>
<ul>
<li>开启生产者确认机制，确保生产者的消息能到达队列</li>
<li>开启持久化功能，确保消息未消费前在队列中不会丢失</li>
<li>开启消费者确认机制为auto，由spring确认消息处理成功后完成ack</li>
<li>开启消费者失败重试机制，并设置MessageRecoverer，多次重试失败后将消息投递到异常交换机，交由人工处理</li>
</ul>
<h2 id="15-2-死信交换机"><a href="#15-2-死信交换机" class="headerlink" title="15.2 死信交换机"></a>15.2 死信交换机</h2><h3 id="15-2-1初识死信交换机"><a href="#15-2-1初识死信交换机" class="headerlink" title="15.2.1初识死信交换机"></a>15.2.1初识死信交换机</h3><h4 id="①-什么是死信交换机"><a href="#①-什么是死信交换机" class="headerlink" title="① 什么是死信交换机"></a>① 什么是死信交换机</h4><p>什么是死信？</p>
<p>当一个队列中的消息满足下列情况之一时，可以成为死信（dead letter）：</p>
<ul>
<li>消费者使用basic.reject或 basic.nack声明消费失败，并且消息的requeue参数设置为false</li>
<li>消息是一个过期消息，超时无人消费</li>
<li>要投递的队列消息满了，无法投递</li>
</ul>
<p>如果这个包含死信的队列配置了<code>dead-letter-exchange</code>属性，指定了一个交换机，那么队列中的死信就会投递到这个交换机中，而这个交换机称为<strong>死信交换机</strong>（Dead Letter Exchange，检查DLX）。</p>
<ol>
<li>一个消息被消费者拒绝了，变成了死信，即simple.queue</li>
<li>因为simple.queue绑定了死信交换机dl.direct，因此死信会投递给这个交换机</li>
<li>如果这个死信交换机也绑定了一个队列，则消息最终会进入这个存放死信的队列dl.queue</li>
</ol>
<p>另外，队列将死信投递给死信交换机时，必须知道两个信息：</p>
<ul>
<li>死信交换机名称</li>
<li>死信交换机与死信队列绑定的RoutingKey</li>
</ul>
<p>这样才能确保投递的消息能到达死信交换机，并且正确的路由到死信队列。</p>
<h4 id="②-利用死信交换机接收死信（拓展）"><a href="#②-利用死信交换机接收死信（拓展）" class="headerlink" title="② 利用死信交换机接收死信（拓展）"></a>② 利用死信交换机接收死信（拓展）</h4><p>在失败重试策略中，默认的RejectAndDontRequeueRecoverer会在本地重试次数耗尽后，发送reject给RabbitMQ，消息变成死信，被丢弃。</p>
<p>我们可以给simple.queue添加一个死信交换机，给死信交换机绑定一个队列。这样消息变成死信后也不会丢弃，而是最终投递到死信交换机，路由到与死信交换机绑定的队列。</p>
<p>我们在consumer服务中，定义一组死信交换机、死信队列：</p>
<pre><code class="java">// 声明普通的 simple.queue队列，并且为其指定死信交换机：dl.direct
@Bean
public Queue simpleQueue2()&#123;
    return QueueBuilder.durable(&quot;simple.queue&quot;) // 指定队列名称，并持久化
        .deadLetterExchange(&quot;dl.direct&quot;) // 指定死信交换机
        .build();
&#125;
// 声明死信交换机 dl.direct
@Bean
public DirectExchange dlExchange()&#123;
    return new DirectExchange(&quot;dl.direct&quot;, true, false);
&#125;
// 声明存储死信的队列 dl.queue
@Bean
public Queue dlQueue()&#123;
    return new Queue(&quot;dl.queue&quot;, true);
&#125;
// 将死信队列 与 死信交换机绑定
@Bean
public Binding dlBinding()&#123;
    return BindingBuilder.bind(dlQueue()).to(dlExchange()).with(&quot;simple&quot;);
&#125;
</code></pre>
<p>也可以一键注解：</p>
<pre><code class="java">package cn.itcast.mq.listener;

@Slf4j
@Component
public class SpringRabbitListener &#123;

    @RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = &quot;dl.queue&quot;, durable = &quot;true&quot;),
            exchange = @Exchange(name = &quot;dl.direct&quot;),
            key = &quot;dl&quot;
    ))
    public void listenDLQueue(String msg) &#123;
        log.info(&quot;消费者接收到了dl.queue的延迟消息&quot;);
    &#125;
    
&#125;
</code></pre>
<h4 id="③-总结"><a href="#③-总结" class="headerlink" title="③ 总结"></a>③ 总结</h4><p>什么样的消息会成为死信？</p>
<ul>
<li>消息被消费者reject或者返回nack</li>
<li>消息超时未消费</li>
<li>队列满了</li>
</ul>
<p>死信交换机的使用场景是什么？</p>
<ul>
<li>如果队列绑定了死信交换机，死信会投递到死信交换机；</li>
<li>可以利用死信交换机收集所有消费者处理失败的消息（死信），交由人工处理，进一步提高消息队列的可靠性。</li>
</ul>
<h3 id="15-2-2-TTL"><a href="#15-2-2-TTL" class="headerlink" title="15.2.2 TTL"></a>15.2.2 TTL</h3><p>一个队列中的消息如果超时未消费，则会变为死信，超时分为两种情况：</p>
<ul>
<li>消息所在的队列设置了超时时间</li>
<li>消息本身设置了超时时间</li>
</ul>
<h4 id="①-接收超时死信的死信交换机"><a href="#①-接收超时死信的死信交换机" class="headerlink" title="① 接收超时死信的死信交换机"></a>① 接收超时死信的死信交换机</h4><p>在consumer服务的SpringRabbitListener中，定义一个新的消费者，并且声明 死信交换机、死信队列：</p>
<pre><code class="java">@RabbitListener(bindings = @QueueBinding(
    value = @Queue(name = &quot;dl.ttl.queue&quot;, durable = &quot;true&quot;),
    exchange = @Exchange(name = &quot;dl.ttl.direct&quot;),
    key = &quot;ttl&quot;
))
public void listenDlQueue(String msg)&#123;
    log.info(&quot;接收到 dl.ttl.queue的延迟消息：&#123;&#125;&quot;, msg);
&#125;
</code></pre>
<h4 id="②-声明一个队列，并且指定TTL"><a href="#②-声明一个队列，并且指定TTL" class="headerlink" title="② 声明一个队列，并且指定TTL"></a>② 声明一个队列，并且指定TTL</h4><p>要给队列设置超时时间，需要在声明队列时配置x-message-ttl属性：</p>
<pre><code class="java">@Bean
public Queue ttlQueue()&#123;
    return QueueBuilder.durable(&quot;ttl.queue&quot;) // 指定队列名称，并持久化
        .ttl(10000) // 设置队列的超时时间，10秒
        .deadLetterExchange(&quot;dl.ttl.direct&quot;) // 指定死信交换机
        .build();
&#125;
</code></pre>
<p>注意，这个队列设定了死信交换机为<code>dl.ttl.direct</code></p>
<p>声明交换机，将ttl与交换机绑定：</p>
<pre><code class="java">@Bean
public DirectExchange ttlExchange()&#123;
    return new DirectExchange(&quot;ttl.direct&quot;);
&#125;
@Bean
public Binding ttlBinding()&#123;
    return BindingBuilder.bind(ttlQueue()).to(ttlExchange()).with(&quot;ttl&quot;);
&#125;
</code></pre>
<p>发送消息，但是不要指定TTL：</p>
<pre><code class="java">@Test
public void testTTLQueue() &#123;
    // 创建消息
    String message = &quot;hello, ttl queue&quot;;
    // 消息ID，需要封装到CorrelationData中
    CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString());
    // 发送消息
    rabbitTemplate.convertAndSend(&quot;ttl.direct&quot;, &quot;ttl&quot;, message, correlationData);
    // 记录日志
    log.debug(&quot;发送消息成功&quot;);
&#125;
</code></pre>
<p>因为队列的TTL值是10000ms，也就是10秒。所以消息发送与接收之间的时差刚好是10秒。</p>
<h4 id="③-发送消息时，设定TTL"><a href="#③-发送消息时，设定TTL" class="headerlink" title="③ 发送消息时，设定TTL"></a>③ 发送消息时，设定TTL</h4><p>在发送消息时，也可以指定TTL：</p>
<pre><code class="java">@Test
public void testTTLMsg() &#123;
    // 创建消息
    Message message = MessageBuilder
        .withBody(&quot;hello, ttl message&quot;.getBytes(StandardCharsets.UTF_8))
        .setExpiration(&quot;5000&quot;)
        .build();
    // 消息ID，需要封装到CorrelationData中
    CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString());
    // 发送消息
    rabbitTemplate.convertAndSend(&quot;ttl.direct&quot;, &quot;ttl&quot;, message, correlationData);
    log.debug(&quot;发送消息成功&quot;);
&#125;
</code></pre>
<p>发送与接收的延迟只有5秒。说明当队列、消息都设置了TTL时，任意一个到期就会成为死信。</p>
<h4 id="④-总结-1"><a href="#④-总结-1" class="headerlink" title="④ 总结"></a>④ 总结</h4><p>消息超时的两种方式是？</p>
<ul>
<li>给队列设置ttl属性，进入队列后超过ttl时间的消息变为死信</li>
<li>给消息设置ttl属性，队列接收到消息超过ttl时间后变为死信</li>
</ul>
<p>如何实现发送一个消息20秒后消费者才收到消息？</p>
<ul>
<li>给消息的目标队列指定死信交换机</li>
<li>将消费者监听的队列绑定到死信交换机</li>
<li>发送消息时给消息设置超时时间为20秒</li>
</ul>
<h3 id="15-2-3-延迟队列"><a href="#15-2-3-延迟队列" class="headerlink" title="15.2.3 延迟队列"></a>15.2.3 延迟队列</h3><p>利用TTL结合死信交换机，我们实现了消息发出后，消费者延迟收到消息的效果。这种消息模式就称为延迟队列（Delay Queue）模式。</p>
<p>延迟队列的使用场景包括：</p>
<ul>
<li>延迟发送短信</li>
<li>用户下单，如果用户在15 分钟内未支付，则自动取消</li>
<li>预约工作会议，20分钟后自动通知所有参会人员</li>
</ul>
<p>因为延迟队列的需求非常多，所以RabbitMQ的官方也推出了一个插件，原生支持延迟队列效果。</p>
<p>这个插件就是DelayExchange插件。参考RabbitMQ的插件列表页面：<a target="_blank" rel="noopener" href="https://www.rabbitmq.com/community-plugins.html">https://www.rabbitmq.com/community-plugins.html</a></p>
<p>使用方式可以参考官网地址：<a target="_blank" rel="noopener" href="https://blog.rabbitmq.com/posts/2015/04/scheduling-messages-with-rabbitmq">https://blog.rabbitmq.com/posts/2015/04/scheduling-messages-with-rabbitmq</a></p>
<h4 id="①-安装DelayExchange插件"><a href="#①-安装DelayExchange插件" class="headerlink" title="① 安装DelayExchange插件"></a>① 安装DelayExchange插件</h4><p><strong>1）安装MQ</strong></p>
<p>注：部署此插件需要把plugins挂载到磁盘中</p>
<pre><code class="sh">docker run \
 -e RABBITMQ_DEFAULT_USER=itcast \
 -e RABBITMQ_DEFAULT_PASS=123321 \
 -v mq-plugins:/plugins \
 --name mq \
 --hostname mq1 \
 -p 15672:15672 \
 -p 5672:5672 \
 -d \
 rabbitmq:3.8-management
</code></pre>
<p><strong>2）安装DelayExchange插件</strong></p>
<p>官方的安装指南地址为：<a target="_blank" rel="noopener" href="https://blog.rabbitmq.com/posts/2015/04/scheduling-messages-with-rabbitmq">https://blog.rabbitmq.com/posts/2015/04/scheduling-messages-with-rabbitmq</a></p>
<p>上述文档是基于linux原生安装RabbitMQ，然后安装插件。</p>
<p>因为我们之前是基于Docker安装RabbitMQ，所以下面我们会讲解基于Docker来安装RabbitMQ插件。</p>
<ol>
<li>下载插件：RabbitMQ有一个官方的插件社区，地址为：<a target="_blank" rel="noopener" href="https://www.rabbitmq.com/community-plugins.html">https://www.rabbitmq.com/community-plugins.html</a></li>
<li>去对应的GitHub页面下载3.8.9版本的插件，地址为<a target="_blank" rel="noopener" href="https://github.com/rabbitmq/rabbitmq-delayed-message-exchange/releases/tag/3.8.9%E8%BF%99%E4%B8%AA%E5%AF%B9%E5%BA%94RabbitMQ%E7%9A%843.8.5%E4%BB%A5%E4%B8%8A%E7%89%88%E6%9C%AC%E3%80%82">https://github.com/rabbitmq/rabbitmq-delayed-message-exchange/releases/tag/3.8.9这个对应RabbitMQ的3.8.5以上版本。</a></li>
</ol>
<p><strong>3）上传插件</strong></p>
<p>因为我们是基于Docker安装，所以需要先查看RabbitMQ的插件目录对应的数据卷。如果不是基于Docker的同学，请参考第一章部分，重新创建Docker容器。</p>
<p>我们之前设定的RabbitMQ的数据卷名称为<code>mq-plugins</code>，所以我们使用下面命令查看数据卷：</p>
<pre><code class="sh">docker volume inspect mq-plugins
</code></pre>
<p>将插件上传到这个目录即可</p>
<p><strong>4）安装插件</strong></p>
<p>最后就是安装了，需要进入MQ容器内部来执行安装。我的容器名为<code>mq</code>，所以执行下面命令：</p>
<pre><code class="sh">docker exec -it mq bash
</code></pre>
<p>执行时，请将其中的 <code>-it</code> 后面的<code>mq</code>替换为你自己的容器名.</p>
<p>进入容器内部后，执行下面命令开启插件：</p>
<pre><code class="sh">rabbitmq-plugins enable rabbitmq_delayed_message_exchange
</code></pre>
<h4 id="②-DelayExchange原理"><a href="#②-DelayExchange原理" class="headerlink" title="② DelayExchange原理"></a>② DelayExchange原理</h4><p>DelayExchange需要将一个交换机声明为delayed类型。当我们发送消息到delayExchange时，流程如下：</p>
<ul>
<li>接收消息</li>
<li>判断消息是否具备x-delay属性</li>
<li>如果有x-delay属性，说明是延迟消息，持久化到硬盘，读取x-delay值，作为延迟时间</li>
<li>返回routing not found结果给消息发送者</li>
<li>x-delay时间到期后，重新投递消息到指定队列</li>
</ul>
<h4 id="③-使用DelayExchange"><a href="#③-使用DelayExchange" class="headerlink" title="③ 使用DelayExchange"></a>③ 使用DelayExchange</h4><p>插件的使用也非常简单：声明一个交换机，交换机的类型可以是任意类型，只需要设定delayed属性为true即可，然后声明队列与其绑定即可。</p>
<p><strong>1）声明DelayExchange交换机</strong></p>
<p>基于注解方式（推荐）：</p>
<pre><code class="java">@Slf4j
@Component
public class SpringRabbitListener &#123;

    @RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = &quot;delay.queue&quot;, durable = &quot;true&quot;),
            exchange = @Exchange(name = &quot;delay.direct&quot;, delayed = &quot;true&quot;),
            key = &quot;delay&quot;
    ))
    public void listenDelayExchange(String msg) &#123;
        log.info(&quot;消费者接收到了delay.queue的延迟消息&quot;);
    &#125;
    
&#125;
</code></pre>
<p>也可以基于@Bean的方式：</p>
<pre><code class="java">@Bean
public DirectExchange delayedExchange()&#123;
    return ExchangeBuilder
        .directExchange(&quot;delay.direct&quot;) // 指定交换机类型和名称
        .delayed() // 设置delay属性为true
        .durable(true) // 持久化
        .build();
&#125;

@Bean
public Queue delayedQueue()&#123;
    return new Queue(&quot;delay.queue&quot;);
&#125;

@Bean
public Binding delayedBinding()&#123;
    return BindingBuilder.bind(delayedQueue()).to(delayedExchange()).with(&quot;delay&quot;);
&#125;
</code></pre>
<p><strong>2）发送消息</strong></p>
<p>发送消息时，一定要携带x-delay属性，指定延迟的时间：</p>
<pre><code class="java">    @Test
    public void testSendDelayMessage() throws InterruptedException &#123;
        // 1.准备消息
        Message message = MessageBuilder
                .withBody(&quot;hello,ttl message&quot;.getBytes(StandardCharsets.UTF_8))
                .setDeliveryMode(MessageDeliveryMode.PERSISTENT)
                .setHeader(&quot;x-delay&quot;, 5000)
                .build();
        // 2.准备CorrelationData
        CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString());
        // 3.发送消息
        rabbitTemplate.convertAndSend(&quot;delay.direct&quot;, &quot;delay&quot;, message, correlationData);
    &#125;
</code></pre>
<h4 id="④-总结-2"><a href="#④-总结-2" class="headerlink" title="④ 总结"></a>④ 总结</h4><p>延迟队列插件的使用步骤包括哪些？</p>
<ul>
<li>声明一个交换机，添加delayed属性为true</li>
<li>发送消息时，添加x-delay头，值为超时时间</li>
</ul>
<h2 id="15-3-惰性队列"><a href="#15-3-惰性队列" class="headerlink" title="15.3 惰性队列"></a>15.3 惰性队列</h2><h3 id="15-3-1-消息堆积问题"><a href="#15-3-1-消息堆积问题" class="headerlink" title="15.3.1 消息堆积问题"></a>15.3.1 消息堆积问题</h3><p>当生产者发送消息的速度超过了消费者处理消息的速度，就会导致队列中的消息堆积，直到队列存储消息达到上限。之后发送的消息就会成为死信，可能会被丢弃，这就是消息堆积问题。</p>
<p>解决消息堆积有两种思路：</p>
<ul>
<li>增加更多消费者，提高消费速度。也就是我们之前说的work queue模式</li>
<li>扩大队列容积，提高堆积上限</li>
</ul>
<p>要提升队列容积，把消息保存在内存中显然是不行的。</p>
<h3 id="15-3-2-惰性队列"><a href="#15-3-2-惰性队列" class="headerlink" title="15.3.2 惰性队列"></a>15.3.2 惰性队列</h3><p>从RabbitMQ的3.6.0版本开始，就增加了Lazy Queues的概念，也就是惰性队列。惰性队列的特征如下：</p>
<ul>
<li>接收到消息后直接存入磁盘而非内存</li>
<li>消费者要消费消息时才会从磁盘中读取并加载到内存</li>
<li>支持数百万条的消息存储</li>
</ul>
<h4 id="①-基于命令行设置lazy-queue"><a href="#①-基于命令行设置lazy-queue" class="headerlink" title="① 基于命令行设置lazy-queue"></a>① 基于命令行设置lazy-queue</h4><p>而要设置一个队列为惰性队列，只需要在声明队列时，指定x-queue-mode属性为lazy即可。可以通过命令行将一个运行中的队列修改为惰性队列：</p>
<pre><code class="sh">rabbitmqctl set_policy Lazy &quot;^lazy-queue$&quot; &#39;&#123;&quot;queue-mode&quot;:&quot;lazy&quot;&#125;&#39; --apply-to queues  
</code></pre>
<p>命令解读：</p>
<ul>
<li><code>rabbitmqctl</code> ：RabbitMQ的命令行工具</li>
<li><code>set_policy</code> ：添加一个策略</li>
<li><code>Lazy</code> ：策略名称，可以自定义</li>
<li><code>&quot;^lazy-queue$&quot;</code> ：用正则表达式匹配队列的名字</li>
<li><code>&#39;&#123;&quot;queue-mode&quot;:&quot;lazy&quot;&#125;&#39;</code> ：设置队列模式为lazy模式</li>
<li><code>--apply-to queues</code>：策略的作用对象，是所有的队列</li>
</ul>
<h4 id="②-基于-Bean声明lazy-queue"><a href="#②-基于-Bean声明lazy-queue" class="headerlink" title="② 基于@Bean声明lazy-queue"></a>② 基于@Bean声明lazy-queue</h4><pre><code class="java">@Configuration
public class LazyConfig &#123;
    @Bean
    public Queue lazyQueue() &#123;
        return QueueBuilder.durable(&quot;lazy.queue&quot;)
                .lazy()
                .build();
    &#125;
&#125;
</code></pre>
<h4 id="③-基于-RabbitListener声明LazyQueue"><a href="#③-基于-RabbitListener声明LazyQueue" class="headerlink" title="③ 基于@RabbitListener声明LazyQueue"></a>③ 基于@RabbitListener声明LazyQueue</h4><pre><code class="java">@RabbitListener(queuesToDeclare = @Queue(
    name = &quot;lazy.queue&quot;,
    durable = &quot;true&quot;,
    arguments = @Argument(name = &quot;x-queue-mode&quot;, value = &quot;lazy&quot;)
))
public void listenLazyQueue(String msg)&#123;
    log.info(&quot;接收到lazy.queue的消息:&#123;&#125;&quot;, msg);
&#125;
</code></pre>
<h3 id="15-3-3-总结"><a href="#15-3-3-总结" class="headerlink" title="15.3.3 总结"></a>15.3.3 总结</h3><p>消息堆积问题的解决方案？</p>
<ul>
<li>队列上绑定多个消费者，提高消费速度</li>
<li>使用惰性队列，可以再mq中保存更多消息</li>
</ul>
<p>惰性队列的优点有哪些？</p>
<ul>
<li>基于磁盘存储，消息上限高</li>
<li>没有间歇性的page-out，性能比较稳定</li>
</ul>
<p>惰性队列的缺点有哪些？</p>
<ul>
<li>基于磁盘存储，消息时效性会降低</li>
<li>性能受限于磁盘的IO</li>
</ul>
<h2 id="15-4-MQ集群"><a href="#15-4-MQ集群" class="headerlink" title="15.4 MQ集群"></a>15.4 MQ集群</h2><h3 id="15-4-1-集群分类"><a href="#15-4-1-集群分类" class="headerlink" title="15.4.1 集群分类"></a>15.4.1 集群分类</h3><p>RabbitMQ的是基于Erlang语言编写，而Erlang又是一个面向并发的语言，天然支持集群模式。RabbitMQ的集群有两种模式：</p>
<p>•<strong>普通集群</strong>：是一种分布式集群，将队列分散到集群的各个节点，从而提高整个集群的并发能力。</p>
<p>•<strong>镜像集群</strong>：是一种主从集群，普通集群的基础上，添加了主从备份功能，提高集群的数据可用性。</p>
<p>镜像集群虽然支持主从，但主从同步并不是强一致的，某些情况下可能有数据丢失的风险。因此在RabbitMQ的3.8版本以后，推出了新的功能：<strong>仲裁队列</strong>来代替镜像集群，底层采用Raft协议确保主从的数据一致性。</p>
<h3 id="15-4-2-普通集群"><a href="#15-4-2-普通集群" class="headerlink" title="15.4.2 普通集群"></a>15.4.2 普通集群</h3><h4 id="①-集群结构和特征"><a href="#①-集群结构和特征" class="headerlink" title="① 集群结构和特征"></a>① 集群结构和特征</h4><p>普通集群，或者叫标准集群（classic cluster），具备下列特征：</p>
<ul>
<li>会在集群的各个节点间共享部分数据，包括：交换机、队列元信息。不包含队列中的消息。</li>
<li>当访问集群某节点时，如果队列不在该节点，会从数据所在节点传递到当前节点并返回</li>
<li>队列所在节点宕机，队列中的消息就会丢失</li>
</ul>
<h4 id="②-部署"><a href="#②-部署" class="headerlink" title="② 部署"></a>② 部署</h4><p><strong>集群分类</strong></p>
<p>在RabbitMQ的官方文档中，讲述了两种集群的配置方式：</p>
<ul>
<li>普通模式：普通模式集群不进行数据同步，每个MQ都有自己的队列、数据信息（其它元数据信息如交换机等会同步）。例如我们有2个MQ：mq1，和mq2，如果你的消息在mq1，而你连接到了mq2，那么mq2会去mq1拉取消息，然后返回给你。如果mq1宕机，消息就会丢失。</li>
<li>镜像模式：与普通模式不同，队列会在各个mq的镜像节点之间同步，因此你连接到任何一个镜像节点，均可获取到消息。而且如果一个节点宕机，并不会导致数据丢失。不过，这种方式增加了数据同步的带宽消耗。</li>
</ul>
<p>我们先来看普通模式集群，我们的计划部署3节点的mq集群：</p>
<table>
<thead>
<tr>
<th>主机名</th>
<th>控制台端口</th>
<th>amqp通信端口</th>
</tr>
</thead>
<tbody><tr>
<td>mq1</td>
<td>8081 —&gt; 15672</td>
<td>8071 —&gt; 5672</td>
</tr>
<tr>
<td>mq2</td>
<td>8082 —&gt; 15672</td>
<td>8072 —&gt; 5672</td>
</tr>
<tr>
<td>mq3</td>
<td>8083 —&gt; 15672</td>
<td>8073  —&gt; 5672</td>
</tr>
</tbody></table>
<p>集群中的节点标示默认都是：<code>rabbit@[hostname]</code>，因此以上三个节点的名称分别为：</p>
<ul>
<li>rabbit@mq1</li>
<li>rabbit@mq2</li>
<li>rabbit@mq3</li>
</ul>
<p><strong>获取cookie</strong></p>
<p>RabbitMQ底层依赖于Erlang，而Erlang虚拟机就是一个面向分布式的语言，默认就支持集群模式。集群模式中的每个RabbitMQ 节点使用 cookie 来确定它们是否被允许相互通信。</p>
<p>要使两个节点能够通信，它们必须具有相同的共享秘密，称为<strong>Erlang cookie</strong>。cookie 只是一串最多 255 个字符的字母数字字符。</p>
<p>每个集群节点必须具有<strong>相同的 cookie</strong>。实例之间也需要它来相互通信。</p>
<p>我们先在之前启动的mq容器中获取一个cookie值，作为集群的cookie。执行下面的命令：</p>
<pre><code class="sh">docker exec -it mq cat /var/lib/rabbitmq/.erlang.cookie
</code></pre>
<p>可以看到cookie值如下：</p>
<pre><code class="sh">FXZMCVGLBIXZCDEMMVZQ
</code></pre>
<p>接下来，停止并删除当前的mq容器，我们重新搭建集群。</p>
<pre><code class="sh">docker rm -f mq
</code></pre>
<p><strong>准备集群配置</strong></p>
<p>在&#x2F;tmp目录新建一个配置文件 rabbitmq.conf：</p>
<pre><code class="sh">cd /tmp
# 创建文件
touch rabbitmq.conf
</code></pre>
<p>文件内容如下：</p>
<pre><code class="nginx">loopback_users.guest = false
listeners.tcp.default = 5672
cluster_formation.peer_discovery_backend = rabbit_peer_discovery_classic_config
cluster_formation.classic_config.nodes.1 = rabbit@mq1
cluster_formation.classic_config.nodes.2 = rabbit@mq2
cluster_formation.classic_config.nodes.3 = rabbit@mq3
</code></pre>
<p>再创建一个文件，记录cookie</p>
<pre><code class="sh">cd /tmp
# 创建cookie文件
touch .erlang.cookie
# 写入cookie
echo &quot;FXZMCVGLBIXZCDEMMVZQ&quot; &gt; .erlang.cookie
# 修改cookie文件的权限
chmod 600 .erlang.cookie
</code></pre>
<p>准备三个目录,mq1、mq2、mq3：</p>
<pre><code class="sh">cd /tmp
# 创建目录
mkdir mq1 mq2 mq3
</code></pre>
<p>然后拷贝rabbitmq.conf、cookie文件到mq1、mq2、mq3：</p>
<pre><code class="sh"># 进入/tmp
cd /tmp
# 拷贝
cp rabbitmq.conf mq1
cp rabbitmq.conf mq2
cp rabbitmq.conf mq3
cp .erlang.cookie mq1
cp .erlang.cookie mq2
cp .erlang.cookie mq3
</code></pre>
<p><strong>启动集群</strong></p>
<p>创建一个网络：</p>
<pre><code class="sh">docker network create mq-net
</code></pre>
<p>docker volume create </p>
<p>运行命令</p>
<pre><code class="sh">docker run -d --net mq-net \
-v $&#123;PWD&#125;/mq1/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \
-v $&#123;PWD&#125;/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \
-e RABBITMQ_DEFAULT_USER=itcast \
-e RABBITMQ_DEFAULT_PASS=123321 \
--name mq1 \
--hostname mq1 \
-p 8071:5672 \
-p 8081:15672 \
rabbitmq:3.8-management
</code></pre>
<pre><code class="sh">docker run -d --net mq-net \
-v $&#123;PWD&#125;/mq2/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \
-v $&#123;PWD&#125;/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \
-e RABBITMQ_DEFAULT_USER=itcast \
-e RABBITMQ_DEFAULT_PASS=123321 \
--name mq2 \
--hostname mq2 \
-p 8072:5672 \
-p 8082:15672 \
rabbitmq:3.8-management
</code></pre>
<pre><code class="sh">docker run -d --net mq-net \
-v $&#123;PWD&#125;/mq3/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \
-v $&#123;PWD&#125;/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \
-e RABBITMQ_DEFAULT_USER=itcast \
-e RABBITMQ_DEFAULT_PASS=123321 \
--name mq3 \
--hostname mq3 \
-p 8073:5672 \
-p 8083:15672 \
rabbitmq:3.8-management
</code></pre>
<p><strong>测试</strong></p>
<p>在mq1这个节点上添加一个队列：</p>
<ul>
<li>Name : simple.queue</li>
<li>Durability : Durable</li>
<li>Node : rabbit@mq1</li>
</ul>
<h3 id="15-4-3-镜像集群"><a href="#15-4-3-镜像集群" class="headerlink" title="15.4.3 镜像集群"></a>15.4.3 镜像集群</h3><h4 id="①-集群结构和特征-1"><a href="#①-集群结构和特征-1" class="headerlink" title="① 集群结构和特征"></a>① 集群结构和特征</h4><p>镜像集群：本质是主从模式，具备下面的特征：</p>
<ul>
<li>交换机、队列、队列中的消息会在各个mq的镜像节点之间同步备份。</li>
<li>创建队列的节点被称为该队列的<strong>主节点，</strong>备份到的其它节点叫做该队列的<strong>镜像</strong>节点。</li>
<li>一个队列的主节点可能是另一个队列的镜像节点</li>
<li>所有操作都是主节点完成，然后同步给镜像节点</li>
<li>主宕机后，镜像节点会替代成新的主</li>
</ul>
<h4 id="②-部署-1"><a href="#②-部署-1" class="headerlink" title="② 部署"></a>② 部署</h4><p>官方文档地址：<a target="_blank" rel="noopener" href="https://www.rabbitmq.com/ha.html">https://www.rabbitmq.com/ha.html</a></p>
<p><strong>镜像模式的特征</strong></p>
<p>默认情况下，队列只保存在创建该队列的节点上。而镜像模式下，创建队列的节点被称为该队列的<strong>主节点</strong>，队列还会拷贝到集群中的其它节点，也叫做该队列的<strong>镜像</strong>节点。</p>
<p>但是，不同队列可以在集群中的任意节点上创建，因此不同队列的主节点可以不同。甚至，<strong>一个队列的主节点可能是另一个队列的镜像节点</strong>。</p>
<p>用户发送给队列的一切请求，例如发送消息、消息回执默认都会在主节点完成，如果是从节点接收到请求，也会路由到主节点去完成。<strong>镜像节点仅仅起到备份数据作用</strong>。</p>
<p>当主节点接收到消费者的ACK时，所有镜像都会删除节点中的数据。</p>
<p>总结如下：</p>
<ul>
<li>镜像队列结构是一主多从（从就是镜像）</li>
<li>所有操作都是主节点完成，然后同步给镜像节点</li>
<li>主宕机后，镜像节点会替代成新的主（如果在主从同步完成前，主就已经宕机，可能出现数据丢失）</li>
<li>不具备负载均衡功能，因为所有操作都会有主节点完成（但是不同队列，其主节点可以不同，可以利用这个提高吞吐量）</li>
</ul>
<p><strong>镜像模式的配置</strong></p>
<p>镜像模式的配置有3种模式：</p>
<table>
<thead>
<tr>
<th align="left">ha-mode</th>
<th align="left">ha-params</th>
<th align="left">效果</th>
</tr>
</thead>
<tbody><tr>
<td align="left">准确模式exactly</td>
<td align="left">队列的副本量count</td>
<td align="left">集群中队列副本（主服务器和镜像服务器之和）的数量。count如果为1意味着单个副本：即队列主节点。count值为2表示2个副本：1个队列主和1个队列镜像。换句话说：count &#x3D; 镜像数量 + 1。如果群集中的节点数少于count，则该队列将镜像到所有节点。如果有集群总数大于count+1，并且包含镜像的节点出现故障，则将在另一个节点上创建一个新的镜像。</td>
</tr>
<tr>
<td align="left">all</td>
<td align="left">(none)</td>
<td align="left">队列在群集中的所有节点之间进行镜像。队列将镜像到任何新加入的节点。镜像到所有节点将对所有群集节点施加额外的压力，包括网络I &#x2F; O，磁盘I &#x2F; O和磁盘空间使用情况。推荐使用exactly，设置副本数为（N &#x2F; 2 +1）。</td>
</tr>
<tr>
<td align="left">nodes</td>
<td align="left"><em>node names</em></td>
<td align="left">指定队列创建到哪些节点，如果指定的节点全部不存在，则会出现异常。如果指定的节点在集群中存在，但是暂时不可用，会创建节点到当前客户端连接到的节点。</td>
</tr>
</tbody></table>
<p>这里我们以rabbitmqctl命令作为案例来讲解配置语法。</p>
<p>语法示例：</p>
<p><strong>exactly模式</strong></p>
<pre><code>rabbitmqctl set_policy ha-two &quot;^two\.&quot; &#39;&#123;&quot;ha-mode&quot;:&quot;exactly&quot;,&quot;ha-params&quot;:2,&quot;ha-sync-mode&quot;:&quot;automatic&quot;&#125;&#39;
</code></pre>
<ul>
<li><code>rabbitmqctl set_policy</code>：固定写法</li>
<li><code>ha-two</code>：策略名称，自定义</li>
<li><code>&quot;^two\.&quot;</code>：匹配队列的正则表达式，符合命名规则的队列才生效，这里是任何以<code>two.</code>开头的队列名称</li>
<li><code>&#39;&#123;&quot;ha-mode&quot;:&quot;exactly&quot;,&quot;ha-params&quot;:2,&quot;ha-sync-mode&quot;:&quot;automatic&quot;&#125;&#39;</code>: 策略内容<ul>
<li><code>&quot;ha-mode&quot;:&quot;exactly&quot;</code>：策略模式，此处是exactly模式，指定副本数量</li>
<li><code>&quot;ha-params&quot;:2</code>：策略参数，这里是2，就是副本数量为2，1主1镜像</li>
<li><code>&quot;ha-sync-mode&quot;:&quot;automatic&quot;</code>：同步策略，默认是manual，即新加入的镜像节点不会同步旧的消息。如果设置为automatic，则新加入的镜像节点会把主节点中所有消息都同步，会带来额外的网络开销</li>
</ul>
</li>
</ul>
<p><strong>all模式</strong></p>
<pre><code>rabbitmqctl set_policy ha-all &quot;^all\.&quot; &#39;&#123;&quot;ha-mode&quot;:&quot;all&quot;&#125;&#39;
</code></pre>
<ul>
<li><code>ha-all</code>：策略名称，自定义</li>
<li><code>&quot;^all\.&quot;</code>：匹配所有以<code>all.</code>开头的队列名</li>
<li><code>&#39;&#123;&quot;ha-mode&quot;:&quot;all&quot;&#125;&#39;</code>：策略内容<ul>
<li><code>&quot;ha-mode&quot;:&quot;all&quot;</code>：策略模式，此处是all模式，即所有节点都会称为镜像节点</li>
</ul>
</li>
</ul>
<p><strong>nodes模式</strong></p>
<pre><code>rabbitmqctl set_policy ha-nodes &quot;^nodes\.&quot; &#39;&#123;&quot;ha-mode&quot;:&quot;nodes&quot;,&quot;ha-params&quot;:[&quot;rabbit@nodeA&quot;, &quot;rabbit@nodeB&quot;]&#125;&#39;
</code></pre>
<ul>
<li><code>rabbitmqctl set_policy</code>：固定写法</li>
<li><code>ha-nodes</code>：策略名称，自定义</li>
<li><code>&quot;^nodes\.&quot;</code>：匹配队列的正则表达式，符合命名规则的队列才生效，这里是任何以<code>nodes.</code>开头的队列名称</li>
<li><code>&#39;&#123;&quot;ha-mode&quot;:&quot;nodes&quot;,&quot;ha-params&quot;:[&quot;rabbit@nodeA&quot;, &quot;rabbit@nodeB&quot;]&#125;&#39;</code>: 策略内容<ul>
<li><code>&quot;ha-mode&quot;:&quot;nodes&quot;</code>：策略模式，此处是nodes模式</li>
<li><code>&quot;ha-params&quot;:[&quot;rabbit@mq1&quot;, &quot;rabbit@mq2&quot;]</code>：策略参数，这里指定副本所在节点名称</li>
</ul>
</li>
</ul>
<p><strong>测试</strong></p>
<p>我们使用exactly模式的镜像，因为集群节点数量为3，因此镜像数量就设置为2.</p>
<p>运行下面的命令：</p>
<pre><code class="sh">docker exec -it mq1 rabbitmqctl set_policy ha-two &quot;^two\.&quot; &#39;&#123;&quot;ha-mode&quot;:&quot;exactly&quot;,&quot;ha-params&quot;:2,&quot;ha-sync-mode&quot;:&quot;automatic&quot;&#125;&#39;
</code></pre>
<h4 id="③-Java代码创建仲裁队列"><a href="#③-Java代码创建仲裁队列" class="headerlink" title="③ Java代码创建仲裁队列"></a>③ Java代码创建仲裁队列</h4><pre><code class="java">@Bean
public Queue quorumQueue() &#123;
    return QueueBuilder
        .durable(&quot;quorum.queue&quot;) // 持久化
        .quorum() // 仲裁队列
        .build();
&#125;
</code></pre>
<h3 id="15-4-4-SpringAMQP连接MQ集群"><a href="#15-4-4-SpringAMQP连接MQ集群" class="headerlink" title="15.4.4 SpringAMQP连接MQ集群"></a>15.4.4 SpringAMQP连接MQ集群</h3><p>注意，这里用address来代替host、port方式</p>
<pre><code class="java">spring:
  rabbitmq:
    addresses: 192.168.150.105:8071, 192.168.150.105:8072, 192.168.150.105:8073
    username: itcast
    password: 123321
    virtual-host: /
</code></pre>
<h3 id="15-4-5-集群扩容"><a href="#15-4-5-集群扩容" class="headerlink" title="15.4.5 集群扩容"></a>15.4.5 集群扩容</h3><h4 id="①-加入集群"><a href="#①-加入集群" class="headerlink" title="① 加入集群"></a>① 加入集群</h4><p>1）启动一个新的MQ容器：</p>
<pre><code class="sh">docker run -d --net mq-net \
-v $&#123;PWD&#125;/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \
-e RABBITMQ_DEFAULT_USER=itcast \
-e RABBITMQ_DEFAULT_PASS=123321 \
--name mq4 \
--hostname mq5 \
-p 8074:15672 \
-p 8084:15672 \
rabbitmq:3.8-management
</code></pre>
<p>2）进入容器控制台：</p>
<pre><code class="sh">docker exec -it mq4 bash
</code></pre>
<p>3）停止mq进程</p>
<pre><code class="sh">rabbitmqctl stop_app
</code></pre>
<p>4）重置RabbitMQ中的数据：</p>
<pre><code class="sh">rabbitmqctl reset
</code></pre>
<p>5）加入mq1：</p>
<pre><code class="sh">rabbitmqctl join_cluster rabbit@mq1
</code></pre>
<p>6）再次启动mq进程</p>
<pre><code class="sh">rabbitmqctl start_app
</code></pre>
<h4 id="②-增加仲裁队列副本"><a href="#②-增加仲裁队列副本" class="headerlink" title="② 增加仲裁队列副本"></a>② 增加仲裁队列副本</h4><p>我们先查看下quorum.queue这个队列目前的副本情况，进入mq1容器：</p>
<pre><code class="sh">docker exec -it mq1 bash
</code></pre>
<p>执行命令：</p>
<pre><code class="sh">rabbitmq-queues quorum_status &quot;quorum.queue&quot;
</code></pre>
<p>现在，我们让mq4也加入进来：</p>
<pre><code class="sh">rabbitmq-queues add_member &quot;quorum.queue&quot; &quot;rabbit@mq4&quot;
</code></pre>
<p>再次查看：</p>
<pre><code class="sh">rabbitmq-queues quorum_status &quot;quorum.queue&quot;
</code></pre>
<p>查看控制台，发现quorum.queue的镜像数量也从原来的 +2 变成了 +3</p>

            
        </div>
    </div>
    <div class="post-tags">
        
        
        
    </div>
    <a href="/2023/08/30/springcloud/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/08/29/hello-world/">
        <h2 class="post-title">Hello World</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/8/29
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="bash">$ hexo new &quot;My New Post&quot;
</code></pre>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="bash">$ hexo server
</code></pre>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="bash">$ hexo generate
</code></pre>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="bash">$ hexo deploy
</code></pre>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

            
        </div>
    </div>
    <div class="post-tags">
        
        
        
    </div>
    <a href="/2023/08/29/hello-world/" class="go-post">阅读全文</a>
</div>


        <div class="page-current">
    <div class="prev">
        
    </div>
    <div class="page-index">
        
        <span class="current">1</span>
        
    </div>
    <div class="next">
        
    </div>
</div>

    </div>
    
    <div id="home-card">
        <div id="card-style">
    <div id="card-div">
        <div class="avatar">
            <img src="/images/avatar.jpg" alt="avatar" />
        </div>
        <div class="name">Bamboo</div>
        <div class="description">
            <p>Description<br>…</p>

        </div>
        
        
        <div class="friend-links">
            
            <div class="friend-link">
                <a target="_blank" rel="noopener" href="https://argvchs.github.io">Argvchs</a>
            </div>
            
        </div>
        
    </div>
</div>

    </div>
    
</div>

                <footer id="footer">
    <div id="footer-wrap">
        <div>
            &copy;
            2022 - 2023 竹客
            <span id="footer-icon">
                <i class="fa-solid fa-font-awesome fa-fw"></i>
            </span>
            &commat;Bamboo
        </div>
        <div>
            Based on the <a target="_blank" rel="noopener" href="https://hexo.io">Hexo Engine</a> &amp;
            <a target="_blank" rel="noopener" href="https://github.com/theme-particlex/hexo-theme-particlex">ParticleX Theme</a>
        </div>
        
    </div>
</footer>

            </div>
            
            <transition name="fade">
                <div id="preview" ref="preview" v-show="previewShow">
                    <img id="preview-content" ref="previewContent" />
                </div>
            </transition>
            
        </div>
        <script src="/js/main.js"></script>
        
    </body>
</html>
